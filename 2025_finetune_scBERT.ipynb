{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.performer_pytorch.performer_pytorch' from '/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/src/performer_pytorch/performer_pytorch.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "import importlib\n",
    "import src.utils_BERT\n",
    "from src.performer_pytorch.performer_pytorch import PerformerLM\n",
    "importlib.reload(src.utils_BERT)\n",
    "importlib.reload(src.performer_pytorch.performer_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/processed_data'\n",
    "work_dir = '/data/lyx/scCHiP/scATAC/LDA/PBMC_10k'\n",
    "sc_count_file = os.path.join(data_dir,\"10k_PBMC_Multiome_filtered_gene_count.h5ad\")\n",
    "sc_anno_file = os.path.join(data_dir,\"MainCelltype.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_table(sc_anno_file, header=None,index_col=0)\n",
    "meta_data.columns = [\"Celltype\"]\n",
    "cell_type = list(set(meta_data.Celltype))\n",
    "ntopics_list = list(range(len(cell_type), 3*len(cell_type)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.read_h5ad(sc_count_file)\n",
    "gene_names = pd.read_table(os.path.join(work_dir,\"src/data_BERT/gene2vec_16906_names.txt\"),sep=\"\\t\",header=None)[0].to_list()\n",
    "data = data[:,data.var_names.isin(gene_names)].copy()\n",
    "indices = [index for index, element in enumerate(gene_names) if element in data.var_names] \n",
    "\n",
    "sc.pp.normalize_total(data, target_sum=1e4)\n",
    "sc.pp.log1p(data)\n",
    "\n",
    "data_csr = np.zeros((data.shape[0], len(gene_names)), dtype=np.float32) \n",
    "data_csr[:, indices]=np.array(data.X.todense())\n",
    "data_csr = csr_matrix(data_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names, label = np.unique(np.array(meta_data['Celltype']), return_inverse=True)  \n",
    "# Convert strings categorical to integrate categorical, and label_names[label] can be restored\n",
    "#store the label dict and label for prediction\n",
    "# with open('label_names', 'wb') as fp:\n",
    "#     pkl.dump(label_names, fp)\n",
    "# with open('label', 'wb') as fp:\n",
    "#     pkl.dump(label, fp)\n",
    "\n",
    "class_num = np.unique(label, return_counts=True)[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = torch.tensor([(1 - (x / sum(class_num))) ** 2 for x in class_num])\n",
    "label = torch.from_numpy(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# import argparse\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import random\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingWarmRestarts, CyclicLR\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCDataset(Dataset):\n",
    "    def __init__(self, data, label,CLASS,device):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.CLASS = CLASS\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rand_start = random.randint(0, self.data.shape[0]-1)\n",
    "        full_seq = self.data[rand_start].toarray()[0]\n",
    "        full_seq[full_seq > (self.CLASS - 2)] = self.CLASS - 2\n",
    "        full_seq = torch.from_numpy(full_seq).long()\n",
    "        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(self.device)\n",
    "        seq_label = self.label[rand_start]\n",
    "        return full_seq, seq_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self, dropout = 0., h_dim = 128, out_dim = 6,SEQ_LEN=16907):\n",
    "        super(Identity, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, (1, 200))\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=SEQ_LEN, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x[:,None,:,:]\n",
    "        # print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_f1 = -float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_f1):\n",
    "        if val_f1 > self.best_f1 + self.min_delta:\n",
    "            self.best_f1 = val_f1\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "        \n",
    "class GeneWiseAttention(nn.Module):\n",
    "    \"\"\"轻量型基因位置注意力\"\"\"\n",
    "    def __init__(self, in_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.position_bias = nn.Parameter(torch.randn(seq_len))\n",
    "        self.channel_scale = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim//4, in_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"输入形状: [batch, channels, seq_len]\"\"\"\n",
    "        # 通道缩放\n",
    "        channel_weights = self.channel_scale(x.mean(dim=-1))  # [24,256]\n",
    "        x = x * channel_weights.unsqueeze(-1)\n",
    "        \n",
    "        # 位置偏置\n",
    "        return x + self.position_bias.view(1,1,-1)  # [24,256,512]\n",
    "\n",
    "\n",
    "class BioClassifier(nn.Module):\n",
    "    def __init__(self, seq_len=16907, embed_dim=200, num_classes=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 修改后的维度对齐\n",
    "        self.proj = nn.Linear(200, 256)  # 输入200 → 输出256\n",
    "        \n",
    "        # 修正卷积层输入通道\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),  # 输入输出均为256\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm([256, seq_len]),  # 保持维度匹配\n",
    "            \n",
    "            nn.AdaptiveAvgPool1d(512),\n",
    "            GeneWiseAttention(256, 512)     # 同步调整输入维度\n",
    "        )\n",
    "        \n",
    "        # 分类器保持原结构\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)        # [24,16907,200] → [24,16907,256]\n",
    "        x = x.permute(0, 2, 1)  # [24,256,16907] → 正确匹配Conv1d输入格式\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features.view(features.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# first train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 24\n",
    "CLASS = 5+2 #Number of bins.'+2\n",
    "SEQ_LEN = len(gene_names)+1#gene_num\", type=int, default=16906\n",
    "POS_EMBED_USING = True #'Using Gene2vec encoding or not.'\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "GRADIENT_ACCUMULATION = 60\n",
    "VALIDATE_EVERY =1\n",
    "PATIENCE = 10\n",
    "UNASSIGN_THRES = 0.0\n",
    "path = \"/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/src/data_BERT/panglao_pretrain.pth\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "POS_EMBED_USING =True\n",
    "model_name = \"2025_finetune_PBMC_MainCelltype_scBert_0217\"\n",
    "ckpt_dir = os.path.join(work_dir,\"scBert_model\",\"scBert_PBMC_10k/\")\n",
    "# world_size = torch.distributed.get_world_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16906"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1 = []\n",
    "f1w = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "pred_list = pd.Series(['un'] * data_csr.shape[0])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for index_train, index_val in sss.split(data_csr, label):\n",
    "    data_train, label_train = data_csr[index_train], label[index_train]\n",
    "    data_val, label_val = data_csr[index_val], label[index_val]\n",
    "    train_dataset = SCDataset(data_train, label_train,CLASS,device)\n",
    "    val_dataset = SCDataset(data_val, label_val,CLASS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = src.utils_BERT.SimpleSampler(train_dataset)\n",
    "val_sampler = src.utils_BERT.SimpleSampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## run ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/src/performer_pytorch/performer_pytorch.py:175: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2416.)\n",
      "  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"
     ]
    }
   ],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560516/1144557707.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path,map_location=device)\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(path,map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_out = BioClassifier(seq_len=16907, embed_dim=200, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560516/2988717159.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "USE_AMP = True  # 启用混合精度\n",
    "MAX_GRAD_NORM = 1.0  # 梯度裁剪阈值\n",
    "\n",
    "# 初始化混合精度训练\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "# 改进的参数分组策略\n",
    "param_groups = [\n",
    "    {'params': model.performer.parameters(), 'lr': 1e-5, 'weight_decay': 0.001},\n",
    "    {'params': model.to_out.parameters(), 'lr': 1e-3, 'weight_decay': 0.01}\n",
    "]\n",
    "\n",
    "# 动态调整的优化器配置\n",
    "optimizer = torch.optim.AdamW(param_groups)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=[group['lr'] for group in param_groups],  # 分组学习率峰值\n",
    "    total_steps=1000,\n",
    "    pct_start=0.2\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopper(patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# 训练主循环（完整改进版）\n",
    "def train_model(model, optimizer, scheduler, train_loader, val_loader, \n",
    "                loss_fn, device, EPOCHS, GRADIENT_ACCUMULATION, \n",
    "                MAX_GRAD_NORM, VALIDATE_EVERY, UNASSIGN_THRES, \n",
    "                early_stopper, model_name, ckpt_dir):\n",
    "    # 初始化记录器\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_epoch_indices = []\n",
    "    lr_history = []\n",
    "    \n",
    "    # 显式确保模型在目标设备\n",
    "    model = model.to(device)\n",
    "    print(f\"[Init] 模型已加载到设备: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # 梯度缩放器\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "    \n",
    "    # 获取训练集总样本量（用于精确损失计算）\n",
    "    total_train_samples = len(train_loader.dataset)\n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # ================== 训练阶段 ==================\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader, 1):\n",
    "            # 确保数据与模型在同一设备\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            assert data.device == labels.device == device  # 设备一致性检查\n",
    "            \n",
    "            # ---- 混合精度前向 ----\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "                logits = model(data)\n",
    "                loss = loss_fn(logits, labels) / GRADIENT_ACCUMULATION\n",
    "                \n",
    "            # ---- 异常损失检测 ----\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                print(f\"[Epoch {epoch} Batch {batch_idx}] 检测到异常损失值: {loss.item():.4f}，跳过该batch\")\n",
    "                optimizer.zero_grad()\n",
    "                continue\n",
    "                \n",
    "            # ---- 梯度累积 ----\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # ---- 统计量计算 ----\n",
    "            with torch.no_grad():\n",
    "                preds = logits.detach().argmax(dim=-1)\n",
    "                correct_predictions += (preds == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                # 按样本比例计算损失（考虑梯度累积）\n",
    "                running_loss += loss.item() * (data.size(0) / total_train_samples)\n",
    "                \n",
    "            # ---- 参数更新 ----\n",
    "            if batch_idx % GRADIENT_ACCUMULATION == 0 or batch_idx == len(train_loader):\n",
    "                # 梯度裁剪与检查\n",
    "                scaler.unscale_(optimizer)\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "                \n",
    "                # 梯度异常处理\n",
    "                if torch.isnan(grad_norm) or torch.isinf(grad_norm):\n",
    "                    print(f\"[Epoch {epoch} Batch {batch_idx}] 检测到异常梯度范数: {grad_norm:.4f}，跳过更新\")\n",
    "                    optimizer.zero_grad()\n",
    "                    scaler.update()  # 必须更新scaler状态\n",
    "                    continue\n",
    "                    \n",
    "                # 优化器步进\n",
    "                try:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"[Epoch {epoch} Batch {batch_idx}] 优化器步进失败: {str(e)}\")\n",
    "                    optimizer.zero_grad()\n",
    "                    continue\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        # ================== 训练后处理 ==================\n",
    "        # 计算epoch指标\n",
    "        epoch_loss = running_loss * GRADIENT_ACCUMULATION  # 修正累积损失\n",
    "        epoch_acc = 100 * correct_predictions / total_samples\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Train Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")\n",
    "        \n",
    "        # ================== 验证阶段 ==================\n",
    "        if epoch % VALIDATE_EVERY == 0:\n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            val_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "                for data_v, labels_v in val_loader:\n",
    "                    data_v, labels_v = data_v.to(device), labels_v.to(device)\n",
    "                    logits = model(data_v)\n",
    "                    \n",
    "                    # 损失计算\n",
    "                    val_loss += loss_fn(logits, labels_v).item()\n",
    "                    \n",
    "                    # 预测处理\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    preds = probs.argmax(dim=-1)\n",
    "                    mask = probs.max(dim=-1).values >= UNASSIGN_THRES\n",
    "                    val_preds.append(preds[mask].cpu())\n",
    "                    val_labels.append(labels_v[mask].cpu())\n",
    "                    \n",
    "            # 合并结果\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_preds = torch.cat(val_preds) if len(val_preds) > 0 else torch.tensor([])\n",
    "            val_labels = torch.cat(val_labels) if len(val_labels) > 0 else torch.tensor([])\n",
    "            \n",
    "            # 空样本处理\n",
    "            if len(val_labels) == 0:\n",
    "                print(f\"[Epoch {epoch}] 警告：验证集无有效预测样本，跳过指标计算\")\n",
    "                val_f1 = 0.0\n",
    "                val_acc = 0.0\n",
    "            else:\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "                val_acc = accuracy_score(val_labels, val_preds)\n",
    "                print(f\"Epoch {epoch} | Val Loss: {val_loss:.4f} | F1: {val_f1:.4f} | Acc: {val_acc:.2f}%\")\n",
    "                \n",
    "                # 早停判断与模型保存\n",
    "                if val_f1 > early_stopper.best_f1:\n",
    "                    src.utils_BERT.save_best_ckpt(epoch, model, optimizer, scheduler, \n",
    "                                                val_loss, model_name, ckpt_dir)\n",
    "                \n",
    "                if early_stopper(val_f1):\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "            \n",
    "            val_loss_history.append(val_loss)\n",
    "            val_epoch_indices.append(epoch)\n",
    "            \n",
    "            # 学习率调度（示例：ReduceLROnPlateau）\n",
    "            if len(val_labels) > 0:\n",
    "                scheduler.step(val_loss)  # 根据验证损失调整\n",
    "            else:\n",
    "                scheduler.step()  # 无验证指标时使用默认调整\n",
    "        \n",
    "        # ================== 资源管理 ==================\n",
    "        # 每5个epoch清理一次显存\n",
    "        if epoch % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"[Memory] 已清理显存，当前使用量: {torch.cuda.memory_allocated(device)/1e9:.2f} GB\")\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": train_loss_history,\n",
    "        \"val_loss\": val_loss_history,\n",
    "        \"val_epochs\": val_epoch_indices,\n",
    "        \"lr_history\": lr_history\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] 模型已加载到设备: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560516/1415801169.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.6228 | Acc: 48.26%\n",
      "Epoch 1 | Val Loss: 1.2651 | F1: 0.2763 | Acc: 0.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.2197 | Acc: 63.79%\n",
      "Epoch 2 | Val Loss: 1.0157 | F1: 0.3324 | Acc: 0.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.9952 | Acc: 70.91%\n",
      "Epoch 3 | Val Loss: 0.8718 | F1: 0.4128 | Acc: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.7869 | Acc: 75.97%\n",
      "Epoch 4 | Val Loss: 0.7956 | F1: 0.4945 | Acc: 0.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.6651 | Acc: 80.74%\n",
      "Epoch 5 | Val Loss: 0.5232 | F1: 0.5894 | Acc: 0.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] 已清理显存，当前使用量: 1.79 GB\n",
      "Epoch 6 | Train Loss: 0.5250 | Acc: 85.07%\n",
      "Epoch 6 | Val Loss: 0.4829 | F1: 0.7035 | Acc: 0.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.4189 | Acc: 87.56%\n",
      "Epoch 7 | Val Loss: 0.4830 | F1: 0.7865 | Acc: 0.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.3423 | Acc: 89.30%\n",
      "Epoch 8 | Val Loss: 0.3760 | F1: 0.8318 | Acc: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.2826 | Acc: 91.50%\n",
      "Epoch 9 | Val Loss: 0.2895 | F1: 0.8848 | Acc: 0.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyx/.conda/envs/STED/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 调用训练函数\n",
    "training_stats = train_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    EPOCHS=EPOCHS,\n",
    "    GRADIENT_ACCUMULATION=GRADIENT_ACCUMULATION,\n",
    "    MAX_GRAD_NORM=MAX_GRAD_NORM,\n",
    "    VALIDATE_EVERY=VALIDATE_EVERY,\n",
    "    UNASSIGN_THRES=UNASSIGN_THRES,\n",
    "    early_stopper=early_stopper,\n",
    "    model_name=model_name,\n",
    "    ckpt_dir=ckpt_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 输出训练结果\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最终验证损失:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtraining_stats\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_stats' is not defined"
     ]
    }
   ],
   "source": [
    "# 输出训练结果\n",
    "print(\"最终验证损失:\", training_stats[\"val_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_orginal = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")\n",
    "model_orginal.to_out = Identity(dropout=0., h_dim=128, out_dim=label_names.shape[0])\n",
    "ckpt = torch.load(path,map_location=device)\n",
    "model_orginal.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399707/787624835.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path,\n"
     ]
    }
   ],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")\n",
    "model.to_out = BioClassifier(seq_len=16907, embed_dim=200, num_classes=6)\n",
    "path = \"/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/scBert_model/scBert_PBMC_10k/2025_finetune_PBMC_MainCelltype_scBert_best.pth\"\n",
    "ckpt = torch.load(path,\n",
    "                  map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 15,\n",
       " 'model_state_dict': OrderedDict([('token_emb.weight',\n",
       "               tensor([[-0.1452,  0.9744,  0.6024,  ...,  0.4889,  2.0647, -0.8933],\n",
       "                       [-0.2241,  0.3448, -1.1184,  ..., -0.5432,  1.2444, -0.3599],\n",
       "                       [ 0.4081,  0.7903, -0.0279,  ...,  1.5016,  0.0355,  1.9326],\n",
       "                       ...,\n",
       "                       [ 1.0149, -0.1577,  0.4978,  ..., -0.0950,  0.0377,  2.0287],\n",
       "                       [ 0.5613, -1.3282, -1.1925,  ..., -1.0829, -0.3204, -1.4388],\n",
       "                       [ 0.0143, -0.2468, -0.2419,  ..., -0.6327, -0.1281,  1.5485]])),\n",
       "              ('pos_emb.emb.weight',\n",
       "               tensor([[ 0.0990,  0.0662, -0.0348,  ...,  0.1936, -0.1781, -0.2365],\n",
       "                       [-0.0231, -0.2780,  0.0056,  ..., -0.0612, -0.3870, -0.2956],\n",
       "                       [ 0.0391,  0.1710,  0.2124,  ...,  0.2017, -0.2572, -0.1138],\n",
       "                       ...,\n",
       "                       [-0.1827,  0.0170, -0.0730,  ...,  0.3663,  0.2751, -0.1134],\n",
       "                       [-0.1533,  0.0142,  0.0104,  ..., -0.0753, -0.1725, -0.1576],\n",
       "                       [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "                      dtype=torch.float64)),\n",
       "              ('performer.calls_since_last_redraw', tensor(196)),\n",
       "              ('performer.net.layers.0.0.norm.weight',\n",
       "               tensor([0.9998, 0.9990, 1.0006, 0.9990, 0.9957, 1.0027, 0.9988, 0.9969, 1.0009,\n",
       "                       1.0004, 0.9984, 0.9997, 1.0005, 1.0016, 0.9986, 0.9983, 1.0003, 0.9985,\n",
       "                       0.9996, 0.9998, 0.9987, 0.9981, 1.0002, 0.9998, 0.9990, 0.9974, 1.0001,\n",
       "                       1.0000, 0.9972, 0.9992, 1.0018, 0.9962, 0.9959, 0.9992, 0.9977, 0.9979,\n",
       "                       1.0001, 1.0017, 0.9970, 1.0010, 0.9971, 0.9999, 0.9985, 0.9981, 1.0016,\n",
       "                       1.0009, 1.0012, 0.9997, 1.0020, 0.9987, 0.9989, 0.9981, 0.9995, 0.9998,\n",
       "                       1.0004, 0.9973, 0.9985, 1.0015, 0.9987, 0.9973, 1.0025, 1.0006, 0.9995,\n",
       "                       1.0003, 0.9975, 1.0015, 0.9999, 1.0004, 1.0010, 0.9932, 0.9987, 0.9995,\n",
       "                       1.0032, 0.9998, 1.0015, 0.9986, 1.0035, 1.0003, 0.9989, 1.0012, 0.9986,\n",
       "                       1.0010, 0.9991, 0.9989, 1.0015, 1.0049, 1.0021, 0.9971, 1.0025, 0.9923,\n",
       "                       0.9986, 0.9976, 0.9973, 1.0023, 0.9975, 0.9990, 0.9979, 0.9953, 0.9986,\n",
       "                       0.9987, 0.9984, 0.9998, 0.9992, 0.9999, 1.0002, 1.0005, 0.9989, 0.9997,\n",
       "                       0.9998, 0.9989, 0.9972, 0.9988, 0.9978, 0.9977, 0.9965, 0.9991, 0.9957,\n",
       "                       0.9980, 0.9973, 0.9980, 0.9975, 0.9973, 1.0003, 1.0032, 0.9976, 0.9975,\n",
       "                       0.9976, 0.9994, 0.9984, 1.0036, 1.0000, 0.9997, 0.9990, 1.0039, 0.9975,\n",
       "                       0.9998, 0.9999, 1.0007, 1.0026, 0.9997, 0.9969, 1.0029, 0.9980, 0.9998,\n",
       "                       1.0014, 1.0015, 0.9984, 0.9991, 0.9999, 0.9973, 1.0044, 0.9984, 1.0006,\n",
       "                       0.9984, 0.9990, 1.0007, 0.9979, 1.0001, 1.0008, 0.9992, 1.0000, 0.9978,\n",
       "                       1.0000, 0.9963, 0.9999, 0.9995, 0.9984, 0.9987, 0.9987, 1.0011, 0.9995,\n",
       "                       0.9985, 0.9978, 0.9993, 0.9988, 0.9980, 0.9974, 0.9978, 1.0005, 1.0015,\n",
       "                       0.9988, 0.9995, 0.9996, 0.9986, 0.9997, 0.9983, 0.9950, 0.9978, 1.0003,\n",
       "                       0.9984, 0.9982, 0.9988, 1.0011, 0.9965, 0.9990, 1.0000, 0.9986, 1.0006,\n",
       "                       0.9970, 1.0013])),\n",
       "              ('performer.net.layers.0.0.norm.bias',\n",
       "               tensor([ 3.2695e-04, -9.8439e-04, -2.7909e-04, -1.0769e-03, -2.5672e-03,\n",
       "                        1.2332e-04, -8.9191e-04,  1.3729e-03,  6.9303e-04,  2.2967e-05,\n",
       "                        5.2109e-04,  1.1029e-03,  7.2892e-06, -1.3902e-04,  6.0900e-04,\n",
       "                       -1.5962e-03,  6.5931e-04,  6.6833e-05,  1.6088e-04,  2.1899e-04,\n",
       "                       -5.6959e-04,  1.4525e-03, -1.4470e-04,  5.9503e-04, -3.8662e-03,\n",
       "                        4.2106e-04,  1.2455e-03, -2.6057e-04, -2.6909e-03, -9.5433e-04,\n",
       "                        3.6625e-03,  1.2045e-03,  2.2821e-03, -8.3332e-04,  6.4937e-04,\n",
       "                       -1.9789e-03,  7.8256e-04,  9.2022e-04,  9.0952e-04, -7.0253e-04,\n",
       "                        3.5151e-03,  9.0502e-04,  2.1904e-03, -2.3566e-03, -3.1289e-04,\n",
       "                       -6.3408e-04, -2.2470e-04,  3.4438e-04, -9.7467e-05,  3.5253e-04,\n",
       "                        5.5607e-04, -2.0463e-03, -5.9991e-04,  4.9031e-04,  2.0470e-04,\n",
       "                        2.0457e-04, -3.2430e-05,  6.6582e-04,  2.2164e-03,  2.8424e-03,\n",
       "                       -6.6250e-05,  1.1725e-03,  1.1686e-03, -1.7755e-03, -2.8006e-03,\n",
       "                       -1.7497e-04, -1.8721e-04,  8.9917e-04,  4.1659e-04,  6.3791e-04,\n",
       "                        5.2656e-04, -3.6087e-05,  2.6442e-03,  7.1574e-05,  7.8419e-04,\n",
       "                       -8.1734e-04,  1.4731e-04,  2.7874e-04,  2.5993e-03,  4.3894e-04,\n",
       "                        2.1503e-03,  8.9298e-04,  3.2394e-04,  5.1937e-05,  1.5919e-03,\n",
       "                       -7.8871e-04, -1.9302e-04, -3.6973e-04, -7.6134e-04,  3.1007e-03,\n",
       "                        1.1468e-03,  7.5475e-04,  1.4229e-03, -7.3836e-04,  1.8987e-03,\n",
       "                        2.5643e-04,  1.5846e-03,  1.6393e-03,  6.4465e-04, -3.6154e-04,\n",
       "                       -2.7460e-03, -3.4718e-04, -4.4898e-05,  1.2852e-03, -5.1385e-04,\n",
       "                        2.1182e-04,  1.3347e-03,  4.3852e-04,  1.1923e-03,  1.6963e-03,\n",
       "                       -5.0647e-03, -1.0925e-03,  2.0341e-03, -5.3103e-04, -3.6292e-03,\n",
       "                       -1.0300e-03, -3.8192e-03,  3.7343e-04,  9.6799e-04, -3.0270e-03,\n",
       "                       -2.6004e-03, -3.0628e-03, -1.9224e-03,  6.1249e-04,  1.2161e-03,\n",
       "                       -3.8929e-04,  4.4888e-04,  1.0425e-03, -7.6488e-04,  2.2716e-03,\n",
       "                        7.9182e-04, -8.5729e-04, -3.2345e-04,  9.6483e-04, -1.4505e-03,\n",
       "                       -6.9267e-04, -6.2534e-04, -3.9402e-04, -1.0892e-03,  4.4833e-04,\n",
       "                        5.0292e-04,  2.1599e-03, -2.1748e-03, -4.3256e-04, -1.1122e-03,\n",
       "                        3.1811e-04, -1.2516e-03,  1.3003e-03, -7.9824e-04,  2.3931e-03,\n",
       "                       -1.0445e-03,  2.3890e-03, -5.9732e-04, -2.3524e-03,  2.5352e-04,\n",
       "                       -2.8035e-04,  1.8010e-03, -2.3512e-03,  2.8682e-03, -1.1335e-03,\n",
       "                        2.4872e-04, -6.9004e-05,  8.9483e-04, -7.2402e-04,  6.3388e-04,\n",
       "                        1.2538e-03,  1.8391e-03,  5.7982e-04, -1.3022e-03, -4.3932e-04,\n",
       "                        1.6759e-04,  1.1309e-03,  3.6768e-03, -1.0819e-03,  2.4204e-04,\n",
       "                        2.0050e-03, -1.1322e-03, -3.1440e-03, -4.5066e-04,  7.1383e-04,\n",
       "                       -2.0625e-03,  7.2463e-04, -3.3529e-04,  3.3588e-04,  7.4613e-05,\n",
       "                       -1.7775e-03, -2.4851e-03, -1.4988e-03, -3.0959e-04,  1.4741e-03,\n",
       "                       -1.0358e-03,  6.4722e-04,  9.3774e-04,  4.5147e-03, -3.3268e-03,\n",
       "                        2.0087e-04,  6.0587e-05, -1.3219e-03, -1.7896e-03, -1.4778e-04])),\n",
       "              ('performer.net.layers.0.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-0.8086, -1.3164,  0.5093,  ..., -0.7646,  0.5464, -1.1953],\n",
       "                       [ 0.9312,  0.0406, -0.2101,  ..., -0.0887,  1.3027,  1.2783],\n",
       "                       [-0.5098, -0.9609, -0.5659,  ..., -0.5698, -1.5947, -0.3081],\n",
       "                       ...,\n",
       "                       [-0.3914,  0.6187, -0.2262,  ...,  0.5928, -1.0068,  0.3323],\n",
       "                       [ 0.9009,  0.5024,  1.9580,  ..., -0.1791, -0.0822, -0.1442],\n",
       "                       [ 0.9590, -0.6060, -0.7197,  ..., -0.6855, -1.2939, -1.3584]])),\n",
       "              ('performer.net.layers.0.0.fn.to_q.weight',\n",
       "               tensor([[-4.0608e-02, -7.4251e-02,  3.5811e-02,  ..., -3.2472e-02,\n",
       "                        -4.7891e-02,  4.0972e-02],\n",
       "                       [ 4.1601e-02, -4.3246e-02, -4.7747e-02,  ..., -6.2697e-02,\n",
       "                        -6.0407e-02,  1.3981e-02],\n",
       "                       [ 1.6546e-02,  4.5549e-02,  1.5636e-02,  ...,  5.3749e-02,\n",
       "                        -3.4362e-02,  3.2683e-02],\n",
       "                       ...,\n",
       "                       [ 6.5399e-05,  4.1048e-02,  6.3188e-02,  ..., -1.3496e-02,\n",
       "                         1.3873e-02, -1.4236e-02],\n",
       "                       [ 3.0116e-02,  6.5151e-02,  2.6465e-02,  ..., -6.7920e-02,\n",
       "                        -6.5346e-02,  5.4481e-02],\n",
       "                       [ 1.3972e-02,  6.2544e-02,  6.1752e-02,  ...,  4.3254e-02,\n",
       "                         2.9408e-02,  1.0605e-02]])),\n",
       "              ('performer.net.layers.0.0.fn.to_k.weight',\n",
       "               tensor([[ 6.8153e-03,  4.1454e-02,  4.6384e-02,  ...,  1.6533e-02,\n",
       "                        -2.8832e-02, -8.0135e-03],\n",
       "                       [-6.1654e-02, -6.1002e-02, -2.6602e-02,  ..., -5.1742e-02,\n",
       "                        -2.7814e-02, -4.6168e-02],\n",
       "                       [-3.9346e-02,  6.1462e-05,  4.1690e-02,  ..., -8.3663e-03,\n",
       "                        -1.7981e-02, -5.5927e-02],\n",
       "                       ...,\n",
       "                       [ 6.6298e-02,  3.8056e-02,  3.6791e-02,  ...,  2.0173e-02,\n",
       "                        -6.4144e-03, -6.1806e-02],\n",
       "                       [ 5.3530e-02, -1.4628e-02,  6.7459e-02,  ..., -3.5247e-02,\n",
       "                        -1.9773e-02, -3.9949e-02],\n",
       "                       [-5.8600e-02,  1.6552e-03, -2.1287e-02,  ...,  2.3117e-02,\n",
       "                         5.5538e-02,  7.8844e-04]])),\n",
       "              ('performer.net.layers.0.0.fn.to_v.weight',\n",
       "               tensor([[ 0.0651,  0.0301, -0.0497,  ...,  0.0062,  0.0499, -0.0545],\n",
       "                       [ 0.0501, -0.0446, -0.0582,  ..., -0.0173,  0.0068,  0.0165],\n",
       "                       [ 0.0582,  0.0153, -0.0286,  ..., -0.0485, -0.0300,  0.0127],\n",
       "                       ...,\n",
       "                       [ 0.0710, -0.0567, -0.0256,  ...,  0.0671,  0.0096, -0.0165],\n",
       "                       [ 0.0250,  0.0436,  0.0250,  ...,  0.0075,  0.0662, -0.0523],\n",
       "                       [ 0.0622, -0.0597,  0.0268,  ...,  0.0188,  0.0088,  0.0677]])),\n",
       "              ('performer.net.layers.0.0.fn.to_out.weight',\n",
       "               tensor([[-0.0139,  0.0231, -0.0309,  ...,  0.0313,  0.0177,  0.0094],\n",
       "                       [-0.0195, -0.0318, -0.0052,  ...,  0.0227,  0.0295, -0.0349],\n",
       "                       [ 0.0234, -0.0313, -0.0120,  ...,  0.0054,  0.0164, -0.0006],\n",
       "                       ...,\n",
       "                       [ 0.0350,  0.0236, -0.0085,  ..., -0.0109,  0.0277,  0.0182],\n",
       "                       [ 0.0359, -0.0245,  0.0332,  ..., -0.0181,  0.0104,  0.0384],\n",
       "                       [ 0.0191, -0.0010,  0.0328,  ...,  0.0311, -0.0353,  0.0116]])),\n",
       "              ('performer.net.layers.0.0.fn.to_out.bias',\n",
       "               tensor([ 2.3361e-03, -3.7484e-02, -3.9585e-03,  1.5490e-02, -9.5803e-03,\n",
       "                        2.0476e-02,  2.0863e-02,  2.8421e-02,  1.2102e-02,  2.2425e-02,\n",
       "                       -1.5642e-02, -2.9583e-02, -3.0306e-02, -1.3501e-02,  1.8162e-02,\n",
       "                       -3.7136e-02,  2.9612e-02, -1.2424e-02, -1.7787e-02, -3.5845e-02,\n",
       "                        2.5728e-02, -3.8813e-02, -2.7111e-04, -3.5092e-02, -3.3707e-02,\n",
       "                       -1.2006e-02, -3.8676e-02, -3.7167e-02,  1.9174e-02,  2.1065e-02,\n",
       "                        1.3478e-02, -1.0190e-02, -1.3227e-02, -5.9940e-03, -2.8485e-02,\n",
       "                       -2.0221e-02, -3.7096e-02,  1.8163e-02, -1.6607e-02,  1.1001e-02,\n",
       "                       -1.2425e-02, -2.1154e-02,  2.2274e-02,  1.4542e-02,  1.7826e-02,\n",
       "                        2.4798e-02,  2.4621e-02,  2.3784e-02,  3.2600e-02, -3.8270e-02,\n",
       "                        2.9631e-02, -3.4873e-02, -3.7975e-02,  1.6157e-02,  1.6769e-02,\n",
       "                       -6.6213e-03,  1.3832e-02,  3.5937e-02, -3.8412e-03, -2.0328e-02,\n",
       "                        1.2176e-02,  9.8680e-03, -2.9134e-03,  3.2718e-02,  2.0628e-02,\n",
       "                       -3.0159e-02,  6.8010e-03,  3.6239e-02, -1.9208e-02,  3.0871e-02,\n",
       "                        2.9291e-02,  2.6199e-02, -3.8709e-02, -2.6046e-02, -3.5859e-02,\n",
       "                       -1.9628e-02,  3.2493e-03,  3.0317e-02,  6.9477e-03,  3.9601e-02,\n",
       "                        2.7248e-02, -7.7220e-03,  6.4074e-03,  2.6022e-02,  3.7426e-02,\n",
       "                        2.2481e-02,  1.2036e-02, -3.5021e-02, -3.4176e-02,  2.0648e-02,\n",
       "                        2.7739e-02,  3.4255e-02, -3.4882e-03, -2.4145e-02, -1.4967e-02,\n",
       "                       -3.0357e-02,  7.8098e-04,  3.8458e-02, -1.5028e-02,  1.6005e-02,\n",
       "                       -2.9503e-02, -3.1215e-02,  1.1556e-02, -1.3236e-02, -3.7922e-02,\n",
       "                       -1.3236e-03, -6.0390e-03, -2.8118e-02, -3.4846e-02,  1.0752e-02,\n",
       "                       -2.1866e-02,  2.0688e-02, -2.2603e-02, -1.4237e-03, -5.2990e-03,\n",
       "                        3.5174e-02, -1.2724e-02,  3.6972e-02,  2.4887e-02, -3.6551e-02,\n",
       "                       -2.5324e-03, -6.9240e-03, -1.3188e-03, -3.8093e-03, -2.3006e-02,\n",
       "                       -5.9668e-03, -3.8273e-02, -7.2142e-03, -2.4074e-02, -1.5570e-02,\n",
       "                        3.1426e-03,  1.1710e-02, -1.1615e-02, -1.4164e-02, -2.8260e-02,\n",
       "                        1.4438e-02, -3.5432e-02, -1.7658e-02,  3.1049e-02, -2.5982e-02,\n",
       "                        3.4064e-02,  8.1321e-03,  2.9341e-02,  8.8243e-03, -1.6563e-02,\n",
       "                        3.9100e-02,  1.9826e-02, -3.8410e-02,  4.1258e-02, -2.3059e-02,\n",
       "                       -3.4032e-02, -3.1268e-02,  3.3982e-02,  2.0122e-02, -2.5568e-02,\n",
       "                        5.9633e-03, -2.3123e-04,  1.5848e-02, -2.2848e-02, -2.8567e-02,\n",
       "                       -1.5186e-02,  1.3289e-02,  2.9939e-02,  1.4184e-02, -3.5900e-02,\n",
       "                       -7.7115e-03,  3.7631e-03, -5.5051e-03, -1.4243e-02,  1.9137e-02,\n",
       "                        6.6620e-05,  3.1527e-02,  3.4509e-02,  3.0106e-02, -3.6303e-03,\n",
       "                       -3.1493e-02, -7.3289e-03,  2.6795e-02,  5.7091e-03, -2.1259e-02,\n",
       "                        1.3734e-02,  1.5561e-02,  2.4422e-02,  1.7283e-02, -7.2229e-03,\n",
       "                        3.0067e-02, -3.1763e-02, -1.1075e-02,  3.3624e-02, -2.1588e-02,\n",
       "                       -2.2290e-02, -2.6320e-02,  2.4848e-02, -3.7644e-02, -3.8758e-02,\n",
       "                       -3.4895e-02, -1.8723e-02, -2.4373e-02,  3.3059e-02, -2.4187e-03])),\n",
       "              ('performer.net.layers.0.1.norm.weight',\n",
       "               tensor([0.9991, 1.0019, 1.0060, 1.0034, 1.0009, 1.0008, 0.9993, 1.0013, 1.0022,\n",
       "                       1.0014, 1.0031, 1.0015, 0.9988, 1.0004, 1.0013, 0.9997, 1.0010, 1.0015,\n",
       "                       0.9999, 0.9992, 1.0018, 1.0042, 0.9993, 1.0020, 0.9995, 1.0089, 1.0019,\n",
       "                       1.0054, 1.0030, 0.9979, 1.0001, 0.9999, 1.0034, 1.0004, 1.0098, 1.0001,\n",
       "                       1.0046, 0.9979, 1.0013, 1.0029, 0.9999, 1.0020, 1.0011, 0.9989, 1.0028,\n",
       "                       0.9992, 0.9993, 1.0005, 1.0038, 1.0024, 1.0021, 1.0024, 1.0005, 0.9999,\n",
       "                       1.0021, 1.0010, 1.0001, 1.0023, 1.0006, 1.0009, 1.0008, 1.0020, 1.0014,\n",
       "                       1.0012, 0.9994, 1.0025, 1.0028, 0.9990, 1.0023, 0.9994, 1.0017, 1.0021,\n",
       "                       0.9985, 1.0023, 1.0021, 1.0042, 1.0053, 1.0024, 1.0025, 0.9993, 1.0041,\n",
       "                       1.0024, 0.9997, 1.0012, 1.0007, 1.0012, 1.0002, 1.0024, 0.9989, 1.0084,\n",
       "                       1.0042, 1.0053, 0.9988, 1.0024, 1.0011, 1.0039, 1.0021, 1.0004, 1.0015,\n",
       "                       0.9998, 1.0027, 1.0006, 1.0022, 1.0029, 1.0007, 0.9996, 0.9997, 1.0033,\n",
       "                       0.9999, 0.9988, 1.0020, 1.0035, 1.0008, 1.0022, 1.0004, 1.0022, 1.0032,\n",
       "                       1.0049, 0.9990, 0.9986, 1.0006, 1.0004, 1.0030, 1.0009, 1.0008, 1.0040,\n",
       "                       1.0016, 1.0005, 1.0012, 1.0020, 1.0063, 0.9980, 1.0030, 1.0028, 0.9993,\n",
       "                       1.0018, 1.0024, 1.0024, 1.0022, 0.9991, 1.0009, 1.0073, 0.9995, 1.0003,\n",
       "                       1.0048, 1.0024, 0.9992, 1.0030, 1.0012, 1.0000, 1.0013, 1.0000, 1.0010,\n",
       "                       1.0004, 1.0038, 1.0017, 0.9996, 1.0046, 0.9993, 1.0047, 1.0001, 0.9977,\n",
       "                       1.0004, 1.0012, 0.9982, 1.0011, 1.0007, 1.0048, 1.0021, 0.9990, 1.0046,\n",
       "                       0.9996, 0.9999, 1.0005, 0.9991, 0.9976, 0.9994, 1.0020, 1.0018, 0.9998,\n",
       "                       0.9994, 0.9976, 1.0029, 0.9994, 1.0007, 1.0000, 0.9992, 1.0008, 0.9990,\n",
       "                       0.9998, 1.0032, 0.9977, 1.0021, 1.0017, 1.0038, 1.0012, 1.0032, 1.0007,\n",
       "                       1.0006, 0.9989])),\n",
       "              ('performer.net.layers.0.1.norm.bias',\n",
       "               tensor([ 1.8149e-04,  8.1858e-04, -5.0403e-04, -1.1859e-03, -3.2137e-04,\n",
       "                        1.6147e-03, -3.6976e-04,  4.3935e-04, -5.0659e-04,  3.9890e-04,\n",
       "                        1.0993e-03,  2.2016e-04,  7.0988e-04, -1.9702e-03,  3.2729e-04,\n",
       "                        6.3936e-04, -8.6212e-04,  7.6008e-04,  2.5968e-04, -1.2179e-03,\n",
       "                        1.6122e-03,  1.3730e-03,  2.9052e-04,  1.4234e-04,  1.3313e-03,\n",
       "                       -1.0166e-03, -4.3583e-04, -6.5244e-04, -6.3647e-04, -2.1402e-03,\n",
       "                        6.5508e-04,  1.6639e-03,  1.0510e-03, -9.5790e-04,  9.9797e-04,\n",
       "                        9.4695e-04, -8.6068e-04, -1.5123e-03, -2.1539e-04, -8.7700e-04,\n",
       "                        6.0232e-04,  5.1486e-04, -7.3353e-04, -1.0652e-03,  1.1786e-03,\n",
       "                       -2.3338e-04, -2.1980e-03, -1.1495e-03,  1.6289e-03, -2.5035e-04,\n",
       "                        6.9006e-05,  1.9570e-03,  1.9712e-04,  4.5493e-04,  3.5612e-04,\n",
       "                       -4.0664e-04,  6.3197e-04, -7.6442e-04,  1.8660e-03,  5.1271e-04,\n",
       "                       -2.4148e-04, -1.4202e-04,  6.0023e-04,  3.7284e-03,  1.6686e-04,\n",
       "                        2.1898e-05,  7.3806e-04, -6.3455e-04,  6.1200e-04,  2.0791e-03,\n",
       "                        3.6093e-04, -2.2283e-03, -2.9813e-03,  6.5983e-04,  2.9542e-05,\n",
       "                       -1.5832e-04, -8.3752e-04, -7.1572e-05, -8.6201e-04,  2.2321e-03,\n",
       "                        1.3721e-03, -6.7941e-04, -1.1528e-03,  1.7767e-03, -3.9850e-05,\n",
       "                        7.1859e-04, -1.1574e-03,  1.0337e-03,  1.5782e-03, -3.0391e-03,\n",
       "                        6.4912e-04,  3.6319e-05,  2.2753e-03,  3.6423e-04,  1.4689e-03,\n",
       "                       -7.4179e-05,  1.0466e-03, -1.7618e-03,  1.1763e-03,  7.7069e-04,\n",
       "                       -6.5770e-04, -1.4918e-03,  7.1553e-05,  5.3948e-04, -3.2638e-04,\n",
       "                       -4.3375e-04,  3.4363e-04,  7.6030e-05,  1.3219e-05, -7.4063e-04,\n",
       "                       -1.4258e-03,  6.0734e-04,  1.0738e-03,  2.9511e-04, -8.0729e-04,\n",
       "                       -6.8633e-04, -2.2573e-03, -1.5329e-03,  9.6874e-04,  8.0477e-05,\n",
       "                        2.9825e-04,  1.3069e-04,  4.7950e-04,  1.9849e-04, -6.8370e-05,\n",
       "                        8.5148e-04,  3.9481e-04, -5.9925e-04, -8.4761e-04, -1.7141e-04,\n",
       "                        1.6322e-04, -2.2140e-04, -1.4197e-03, -1.5129e-03,  1.6119e-03,\n",
       "                        1.7563e-04,  7.3021e-04, -3.6807e-04,  5.4302e-05, -2.2523e-04,\n",
       "                       -6.5275e-04,  9.8130e-04, -4.5081e-04,  1.3387e-03, -1.6586e-03,\n",
       "                       -4.9740e-04, -5.8822e-05, -1.4512e-03, -4.7403e-04,  2.3368e-03,\n",
       "                        1.9008e-04, -2.6349e-04,  1.0850e-03, -1.6422e-03, -3.8283e-04,\n",
       "                       -5.3831e-04,  1.6469e-03, -7.5487e-04,  5.0274e-05, -2.3075e-03,\n",
       "                        5.3727e-04,  2.5433e-03, -9.7063e-04, -1.8341e-04,  1.7854e-03,\n",
       "                       -2.4741e-04,  3.6928e-04,  3.1211e-04, -1.3621e-03,  1.3217e-04,\n",
       "                       -5.4883e-04,  1.5432e-03,  4.1534e-04, -7.7788e-04,  1.3940e-03,\n",
       "                        2.7848e-03,  1.6521e-04, -6.6147e-04, -3.1855e-04,  1.0394e-03,\n",
       "                        1.7346e-04,  9.2685e-04,  1.0628e-04,  1.7508e-04,  7.0330e-04,\n",
       "                        2.1585e-04, -1.2357e-03, -6.5249e-05,  5.3520e-04,  1.6097e-03,\n",
       "                        1.2469e-03,  7.4994e-04, -2.3896e-06,  2.9057e-04,  1.9665e-04,\n",
       "                        2.0980e-04,  4.2779e-04, -2.4641e-05, -6.8086e-04, -1.9762e-03])),\n",
       "              ('performer.net.layers.0.1.fn.fn.w1.weight',\n",
       "               tensor([[ 0.0627, -0.0301,  0.0689,  ..., -0.0608, -0.0553,  0.0262],\n",
       "                       [ 0.0575,  0.0116,  0.0187,  ..., -0.0128, -0.0640,  0.0368],\n",
       "                       [-0.0025, -0.0176, -0.0014,  ..., -0.0182,  0.0633,  0.0031],\n",
       "                       ...,\n",
       "                       [-0.0462,  0.0562,  0.0607,  ..., -0.0394,  0.0363, -0.0655],\n",
       "                       [-0.0624,  0.0504,  0.0665,  ...,  0.0304,  0.0098,  0.0497],\n",
       "                       [ 0.0358,  0.0263, -0.0722,  ..., -0.0700,  0.0574, -0.0405]])),\n",
       "              ('performer.net.layers.0.1.fn.fn.w1.bias',\n",
       "               tensor([-1.9286e-02, -3.6955e-02, -4.4937e-02,  2.1665e-02,  2.5939e-02,\n",
       "                       -9.2384e-03, -1.7973e-02,  6.3115e-04,  3.5434e-02, -1.9184e-02,\n",
       "                        5.9256e-02, -4.5501e-02,  4.7401e-02, -2.1254e-02,  4.6715e-02,\n",
       "                        5.0333e-02,  3.0190e-02, -6.1762e-03,  1.7064e-02,  3.7360e-02,\n",
       "                       -4.8884e-02,  5.7484e-02, -4.7393e-02,  2.7122e-02, -3.3688e-02,\n",
       "                        1.5856e-02,  4.7638e-03,  4.8569e-02, -4.3980e-02, -2.4569e-02,\n",
       "                        5.7450e-03, -2.3511e-02, -6.3107e-02, -3.0612e-02, -1.1877e-02,\n",
       "                       -3.7702e-02, -2.0677e-02,  1.2529e-02,  3.6041e-02,  1.8999e-03,\n",
       "                       -5.3993e-02,  1.6116e-02,  5.5690e-02,  1.9459e-02, -3.1894e-04,\n",
       "                        6.7481e-02, -4.2874e-02,  1.4804e-02, -5.7110e-02, -4.3589e-02,\n",
       "                        1.8960e-02,  2.8731e-02,  5.2920e-02,  5.1019e-02, -2.7435e-02,\n",
       "                        4.8827e-02,  1.1369e-02, -6.1807e-02,  5.5230e-02,  4.2679e-02,\n",
       "                       -7.1638e-02, -1.6679e-02,  6.1883e-02,  5.9882e-02,  1.0921e-02,\n",
       "                       -4.2547e-02,  5.0516e-02, -4.7978e-02,  1.1294e-02, -1.8624e-02,\n",
       "                        1.0965e-02,  4.7760e-03, -4.5486e-02,  3.8392e-02, -3.4640e-02,\n",
       "                        9.9205e-03,  7.8475e-03,  1.7928e-02, -6.7004e-02,  7.1140e-02,\n",
       "                       -5.1809e-02,  3.4548e-03,  1.0152e-02,  6.5112e-02, -4.5848e-02,\n",
       "                        3.7825e-02, -5.0042e-02, -6.0183e-03, -6.2990e-02,  3.8899e-03,\n",
       "                        1.6746e-02, -4.4176e-02,  3.0742e-02,  1.9556e-02, -1.2484e-02,\n",
       "                       -3.5671e-02, -6.7310e-02, -5.8187e-02, -3.8380e-02, -6.8426e-02,\n",
       "                       -1.9478e-02,  4.7030e-02,  4.5088e-02, -5.8697e-02, -4.3497e-02,\n",
       "                       -2.5336e-03,  4.2807e-02,  3.0524e-02, -4.8236e-02,  2.6863e-02,\n",
       "                        1.9080e-02, -1.7893e-02,  1.3224e-02, -6.4052e-02,  4.9747e-02,\n",
       "                        4.2855e-02, -2.1026e-02, -5.7577e-02,  1.3977e-02,  2.3706e-02,\n",
       "                        3.1944e-02, -6.1593e-03,  3.2418e-02, -5.4717e-02,  8.7865e-03,\n",
       "                        6.3561e-02, -5.2632e-02, -1.0518e-02, -6.1721e-02, -4.7730e-02,\n",
       "                       -2.2259e-02, -5.8802e-02,  2.6261e-03,  5.1546e-02,  6.7882e-02,\n",
       "                        6.6864e-02, -3.0832e-02, -1.6594e-02, -1.8382e-02,  2.9175e-02,\n",
       "                       -3.8595e-03,  1.7017e-02, -4.2991e-02,  3.1601e-02, -6.8719e-02,\n",
       "                        4.1355e-02,  2.0052e-02,  4.8400e-02,  2.4343e-02, -4.2113e-02,\n",
       "                        3.6249e-02,  3.1988e-02,  3.2816e-02, -6.7730e-02, -6.7128e-02,\n",
       "                       -1.8486e-02, -4.2427e-02,  2.4306e-02, -1.6157e-02, -6.0970e-02,\n",
       "                        9.3417e-03,  1.8334e-02, -4.9446e-02, -6.1844e-02,  2.6951e-02,\n",
       "                        1.5720e-02,  5.7382e-02, -3.4029e-02,  4.7009e-02, -6.2501e-02,\n",
       "                        5.0190e-03, -4.7049e-02,  2.9928e-02, -5.5868e-03, -4.5679e-02,\n",
       "                        5.5541e-02,  5.7256e-02, -6.4563e-02,  3.6475e-02, -3.9103e-02,\n",
       "                       -5.3017e-03, -2.2001e-02, -2.1032e-02, -8.1401e-03,  2.8784e-02,\n",
       "                        4.5590e-02, -2.6182e-02,  3.2745e-03,  5.1625e-02, -1.3619e-02,\n",
       "                        4.3103e-02,  5.8204e-02, -6.8158e-03, -1.6702e-03,  5.4055e-02,\n",
       "                       -3.1114e-02,  5.4935e-04, -7.1339e-02,  5.1670e-02,  3.7305e-02,\n",
       "                       -4.1199e-02, -3.7611e-02, -5.1286e-02,  4.7121e-02,  1.7580e-02,\n",
       "                        3.5349e-02, -2.0006e-02,  6.2815e-02,  1.6630e-02, -3.9222e-02,\n",
       "                       -5.1867e-02, -5.0925e-02,  1.6679e-02, -2.9311e-02,  8.0120e-03,\n",
       "                       -2.1445e-03, -5.4681e-02,  6.8386e-02, -3.5951e-02,  7.6421e-03,\n",
       "                       -5.5136e-02, -6.6701e-02,  3.6566e-02,  3.1119e-02,  5.7020e-02,\n",
       "                        2.7647e-02,  4.5121e-02,  2.2433e-02, -8.1541e-03,  6.4002e-02,\n",
       "                        3.2473e-02,  2.5968e-02, -1.8262e-02,  3.1394e-02, -1.9277e-02,\n",
       "                        4.7002e-02,  4.7657e-02, -6.9653e-02,  4.7845e-02, -4.0622e-02,\n",
       "                       -6.5396e-02, -7.5138e-03,  3.5547e-02,  6.2187e-02,  6.5143e-02,\n",
       "                       -3.3288e-02, -1.2282e-02, -3.7605e-02,  4.7117e-02, -2.3162e-02,\n",
       "                       -2.5457e-02, -6.3958e-02,  5.9082e-02, -1.8302e-02,  5.7721e-03,\n",
       "                        3.8186e-02, -3.0236e-02,  1.8775e-02,  1.9715e-02,  1.5469e-02,\n",
       "                       -2.9815e-02, -5.4284e-02, -3.1840e-03,  5.2004e-02,  3.1185e-02,\n",
       "                       -3.6574e-02, -6.4161e-02, -6.2186e-02, -6.8646e-02, -2.6904e-02,\n",
       "                        1.5899e-02,  5.1993e-02,  1.1581e-02,  2.8692e-02,  1.9472e-02,\n",
       "                        6.0803e-02, -2.8756e-02, -6.2164e-02, -1.9859e-02, -6.9437e-03,\n",
       "                       -2.6231e-02,  6.3654e-02,  6.9232e-02, -6.3086e-02, -4.4265e-02,\n",
       "                       -4.2305e-02, -6.3829e-02, -2.4594e-02, -8.1227e-03,  4.2417e-02,\n",
       "                       -3.0528e-02, -5.9088e-02,  1.9422e-02,  6.9196e-02,  6.9254e-02,\n",
       "                        4.3446e-02, -1.6424e-02,  5.5962e-02, -6.4567e-02,  1.8482e-02,\n",
       "                        3.0599e-02, -4.1731e-02, -4.4624e-02,  5.9351e-03,  6.0637e-02,\n",
       "                        4.4782e-02,  4.8341e-02, -6.3179e-02, -2.9741e-02, -1.2147e-02,\n",
       "                        2.7582e-02,  3.8416e-02,  5.9674e-02, -3.6022e-02, -3.5260e-02,\n",
       "                        6.1058e-02, -1.4207e-02, -2.7741e-02, -6.0462e-02,  6.1670e-02,\n",
       "                       -6.5842e-02, -6.8913e-02,  5.4198e-02, -4.8872e-02, -5.0207e-02,\n",
       "                       -5.1983e-02,  2.3099e-02,  1.0932e-02,  4.8141e-02, -6.2173e-03,\n",
       "                        3.3935e-02,  6.0720e-02,  4.8765e-02, -2.6777e-02, -6.6895e-02,\n",
       "                       -4.4831e-02, -5.1763e-02, -5.5237e-02,  3.0416e-02, -5.6074e-02,\n",
       "                       -2.6136e-02, -1.6911e-02, -1.8944e-02,  6.6394e-02, -6.5100e-02,\n",
       "                       -5.9693e-02,  5.2756e-02,  2.2009e-02,  4.1940e-02, -3.4280e-02,\n",
       "                       -4.4661e-02,  5.6982e-02,  6.7830e-03, -4.9357e-02, -2.7419e-02,\n",
       "                       -2.4550e-02,  6.5440e-02,  3.8736e-02,  1.3898e-02,  2.1979e-02,\n",
       "                        2.6569e-02, -1.1114e-03, -2.0351e-02, -1.6501e-02,  5.9727e-02,\n",
       "                        3.6370e-02, -4.4324e-02,  1.1000e-02,  2.1130e-02,  2.8733e-02,\n",
       "                       -5.3817e-02,  5.1989e-03,  8.1041e-03,  6.0819e-03,  4.7850e-02,\n",
       "                       -5.3165e-02,  2.8063e-02, -1.3626e-02, -6.6343e-02, -7.0226e-02,\n",
       "                        5.1760e-02,  2.3093e-02, -2.0177e-02,  1.7554e-02, -5.6740e-02,\n",
       "                       -2.3443e-02,  3.5600e-02,  3.5243e-02, -6.3575e-02, -4.1791e-02,\n",
       "                       -2.2803e-02, -6.8311e-02, -3.1036e-04, -5.5867e-02, -4.9090e-03,\n",
       "                        1.1646e-02, -5.6214e-02, -6.1435e-03,  5.9592e-02,  5.2425e-02,\n",
       "                        4.6391e-02,  9.8223e-03,  6.7285e-02,  2.2120e-02,  3.2892e-02,\n",
       "                        2.4771e-02,  8.8037e-03,  2.1745e-02, -5.3792e-02,  1.2483e-02,\n",
       "                       -5.3592e-02, -5.1991e-02, -5.6696e-02, -5.4912e-02,  3.3224e-02,\n",
       "                        1.7528e-02,  6.5908e-02,  5.5553e-02, -4.0601e-03,  6.3719e-02,\n",
       "                       -5.9476e-02, -2.5166e-02, -2.5814e-02,  5.2262e-02, -1.8224e-02,\n",
       "                        3.6170e-02, -9.0170e-03,  4.5407e-02,  4.4869e-02, -6.1934e-02,\n",
       "                       -3.1557e-02,  7.0281e-02, -6.6863e-02,  3.7287e-02, -2.2729e-02,\n",
       "                        6.7780e-02,  1.9215e-02,  3.3138e-02,  1.4920e-02, -3.9174e-02,\n",
       "                       -5.3070e-02,  4.4223e-02, -3.0125e-02, -2.1201e-02,  1.1553e-02,\n",
       "                        5.2769e-02, -3.0306e-02,  6.8432e-03, -1.0576e-02, -6.4798e-02,\n",
       "                       -1.3897e-02, -4.4184e-03,  3.0738e-03, -6.2863e-02, -1.6947e-02,\n",
       "                       -5.8187e-02,  7.6436e-03, -2.8558e-02,  5.8734e-02,  6.5575e-02,\n",
       "                       -6.0638e-02,  5.8649e-02, -5.8568e-02,  6.7992e-03, -4.6424e-02,\n",
       "                       -4.7253e-02, -2.6976e-02,  8.1613e-03, -5.5943e-02,  2.2377e-02,\n",
       "                        4.3761e-02, -5.7571e-02, -1.2858e-03,  4.7833e-02,  5.9622e-02,\n",
       "                       -3.6365e-02, -4.3470e-02,  4.4785e-02,  1.1917e-02,  2.1324e-02,\n",
       "                        1.2432e-03,  5.3700e-02,  2.7570e-02,  4.7330e-02,  3.6029e-02,\n",
       "                       -4.7756e-02,  2.9171e-02,  1.2379e-02, -9.8698e-03, -1.6366e-02,\n",
       "                       -1.3308e-02,  6.0048e-02,  2.3133e-02,  3.6937e-02,  3.8266e-02,\n",
       "                        5.2678e-02,  5.1168e-02,  3.8785e-02,  8.6730e-03,  1.3116e-02,\n",
       "                        1.3690e-02,  1.4619e-02, -2.3777e-02,  3.4713e-02,  3.9772e-02,\n",
       "                       -3.7878e-02,  4.6081e-02,  4.4388e-02,  4.0375e-02,  1.5180e-02,\n",
       "                       -3.5528e-02, -7.9852e-03, -3.3315e-02,  2.2271e-02, -1.4428e-02,\n",
       "                       -2.9885e-02, -3.1544e-02,  1.9386e-02,  3.0737e-02,  6.3888e-02,\n",
       "                       -6.5266e-02,  5.5190e-02,  5.2095e-02, -5.8847e-02,  3.9015e-02,\n",
       "                        3.2169e-02,  5.8581e-02,  9.6100e-03, -2.2102e-02,  6.1425e-02,\n",
       "                       -1.0489e-02, -5.8634e-02,  4.7173e-02,  6.8506e-02,  3.0437e-02,\n",
       "                       -6.5919e-02, -4.4900e-03, -6.9313e-02,  2.7493e-02,  5.7752e-02,\n",
       "                        3.6201e-03,  1.4235e-02, -1.1560e-03, -7.0531e-02, -4.5086e-02,\n",
       "                        2.0583e-02, -7.6946e-03,  2.6833e-02, -3.1227e-02, -2.2469e-02,\n",
       "                       -1.1016e-03, -6.4191e-02,  6.3171e-02,  4.9001e-02,  5.8710e-02,\n",
       "                        1.8819e-03, -9.8977e-03, -2.5081e-02, -5.2960e-04,  2.2544e-02,\n",
       "                        6.4444e-02, -4.3138e-02,  2.3182e-02, -2.0313e-02, -4.3795e-02,\n",
       "                       -1.9071e-02,  4.1884e-02, -6.0950e-02, -2.0482e-02,  1.9884e-02,\n",
       "                       -4.9786e-02,  6.4082e-02, -5.9915e-02, -3.3871e-02, -4.9588e-02,\n",
       "                        5.5365e-02,  5.2730e-02,  6.2621e-02, -3.3880e-03,  4.6839e-02,\n",
       "                        2.6989e-02, -6.4189e-02,  8.7404e-03,  3.6902e-02,  4.1058e-02,\n",
       "                        6.6349e-02,  5.5847e-02, -9.1230e-03,  1.9417e-02, -1.0129e-02,\n",
       "                        2.6696e-02,  6.9313e-02,  7.0443e-02,  7.0537e-02, -5.2704e-02,\n",
       "                       -8.9702e-03,  5.8042e-03,  3.4966e-02, -5.1027e-02,  3.8746e-02,\n",
       "                        5.9567e-02,  2.5080e-02, -5.9278e-03,  1.4590e-02,  3.7124e-02,\n",
       "                        5.7656e-02, -2.3330e-02, -5.1878e-02,  3.6094e-03,  5.5392e-02,\n",
       "                        7.1072e-03, -6.9650e-02,  5.0104e-03, -3.8217e-02,  2.3069e-03,\n",
       "                       -6.4528e-02,  3.6677e-02,  9.9433e-03,  3.9899e-02,  1.2437e-02,\n",
       "                        2.4351e-02, -8.3266e-03, -4.2981e-03,  6.6598e-04, -4.0125e-02,\n",
       "                       -2.1989e-03,  2.1604e-02, -4.5865e-02,  2.1805e-02, -4.7302e-02,\n",
       "                        2.2169e-02, -6.0205e-02,  1.4013e-02, -2.9714e-02,  2.6563e-02,\n",
       "                        6.9671e-02, -1.8291e-02, -7.3323e-03, -2.0041e-02,  6.3316e-02,\n",
       "                        3.6381e-02,  6.9037e-02, -7.9971e-03, -1.2805e-02,  4.6922e-02,\n",
       "                        2.7833e-02,  1.1396e-02, -4.4648e-02, -5.3425e-02, -6.0502e-02,\n",
       "                        6.8144e-02,  4.1023e-03,  1.9995e-02,  4.8818e-02, -5.7903e-02,\n",
       "                       -5.6709e-02, -1.4509e-02, -5.2866e-02, -2.7237e-02, -3.0706e-02,\n",
       "                       -3.1744e-02, -2.5265e-02,  9.8631e-03,  1.6123e-02,  2.0684e-02,\n",
       "                       -6.9173e-02,  1.8315e-03,  5.5772e-02, -1.8243e-02, -2.4169e-02,\n",
       "                        3.0667e-02,  8.1324e-03, -5.5458e-02, -2.7485e-02,  5.9253e-02,\n",
       "                        1.4723e-02, -4.4964e-02, -5.4003e-02,  5.4393e-02,  1.0264e-02,\n",
       "                        2.1727e-02, -5.0934e-02,  1.7276e-02, -2.5209e-02, -1.0506e-02,\n",
       "                        2.5620e-02, -3.4760e-02, -6.1958e-02, -2.7037e-02,  2.1500e-02,\n",
       "                        8.1204e-03,  1.3262e-02, -2.7110e-02,  6.7275e-02,  3.0674e-02,\n",
       "                       -3.7358e-02, -6.5096e-02, -1.8375e-02,  1.6340e-02, -6.5532e-03,\n",
       "                        1.2949e-02,  1.8912e-02,  3.1966e-02,  5.1555e-03, -2.6767e-02,\n",
       "                        1.9693e-02,  2.6563e-02, -5.4852e-02,  6.5833e-02, -1.8668e-02,\n",
       "                       -5.6763e-02,  6.7955e-02, -4.5665e-04,  9.2033e-03, -4.6263e-02,\n",
       "                       -4.8760e-02,  3.9137e-02,  5.7915e-03, -6.1168e-02,  1.2009e-02,\n",
       "                       -5.9858e-03, -4.3460e-02,  2.7878e-02,  6.7758e-02,  2.4848e-02,\n",
       "                        6.0045e-02,  4.7510e-02, -5.6806e-02,  2.1269e-02, -1.5522e-02,\n",
       "                        3.3901e-02,  5.2537e-02,  5.4648e-02,  1.6382e-02, -2.2320e-02,\n",
       "                        6.1476e-02, -6.6502e-02,  2.0495e-02,  2.2695e-02,  2.0463e-02,\n",
       "                       -2.0052e-02, -5.4157e-02,  3.1857e-02,  1.8126e-02, -1.6161e-02,\n",
       "                        3.1210e-02, -3.2107e-02, -6.6308e-02, -4.9941e-02,  2.5468e-02,\n",
       "                       -2.0932e-02, -1.9163e-02, -3.4167e-02,  5.2237e-02,  4.4959e-02,\n",
       "                       -6.0036e-02,  5.7731e-02,  4.8495e-03,  8.2916e-03, -2.5690e-02,\n",
       "                        5.6007e-02, -6.4447e-02,  6.3097e-02,  5.8252e-02, -6.7560e-05,\n",
       "                        4.3166e-02, -5.9676e-02,  3.4992e-02, -3.7539e-02,  3.9547e-02,\n",
       "                        5.8746e-02,  4.0919e-02, -5.2146e-03,  5.9880e-02, -1.8426e-02,\n",
       "                       -3.4017e-02,  1.2096e-02, -1.0323e-02,  3.2836e-02,  4.4642e-02,\n",
       "                       -6.0634e-03, -2.3913e-02, -5.4848e-02,  6.7568e-02,  3.2660e-03,\n",
       "                       -3.2641e-02,  2.2931e-02, -9.1457e-03, -2.0398e-02,  4.9747e-02,\n",
       "                       -4.1673e-02, -6.0031e-02,  1.5734e-02,  3.7625e-03, -3.2532e-02,\n",
       "                       -5.0819e-02,  4.6938e-02,  6.8354e-02,  4.3788e-02, -2.9892e-02])),\n",
       "              ('performer.net.layers.0.1.fn.fn.w2.weight',\n",
       "               tensor([[-0.0293,  0.0137, -0.0104,  ..., -0.0341,  0.0334, -0.0327],\n",
       "                       [ 0.0020, -0.0007, -0.0002,  ..., -0.0294,  0.0005,  0.0123],\n",
       "                       [-0.0195,  0.0294, -0.0331,  ...,  0.0190, -0.0217,  0.0045],\n",
       "                       ...,\n",
       "                       [-0.0236, -0.0203,  0.0268,  ...,  0.0025,  0.0297,  0.0039],\n",
       "                       [-0.0358,  0.0168,  0.0195,  ...,  0.0035,  0.0249,  0.0119],\n",
       "                       [ 0.0206,  0.0132, -0.0071,  ...,  0.0216,  0.0163, -0.0338]])),\n",
       "              ('performer.net.layers.0.1.fn.fn.w2.bias',\n",
       "               tensor([-3.5603e-03, -7.3044e-03,  1.6170e-02, -3.1858e-02,  2.7562e-02,\n",
       "                        1.6635e-03, -2.0907e-02, -1.5476e-02,  1.4950e-02,  2.7050e-02,\n",
       "                       -2.0434e-02, -2.7769e-02, -3.1455e-02,  6.7375e-03, -2.3351e-02,\n",
       "                        8.4592e-05, -2.2211e-02,  1.9385e-02,  1.6904e-02,  2.4990e-02,\n",
       "                       -9.8674e-03,  3.2112e-02,  1.1734e-02,  1.4060e-02, -2.8342e-02,\n",
       "                       -9.4388e-03, -2.7767e-02,  1.5579e-02,  3.5673e-02,  2.5614e-02,\n",
       "                       -1.7720e-02, -2.7660e-02, -1.8787e-02, -3.4249e-02, -2.2339e-02,\n",
       "                        2.6620e-02,  3.4980e-02,  1.5478e-02,  1.0523e-02, -4.8026e-04,\n",
       "                       -3.5438e-02, -3.2600e-02,  2.5630e-02, -2.8672e-02,  1.6271e-02,\n",
       "                       -3.1828e-02,  1.6253e-02,  3.3943e-02, -3.0055e-02,  1.2784e-03,\n",
       "                       -1.8876e-02, -2.8199e-03,  3.5447e-02, -2.4679e-02, -2.8271e-02,\n",
       "                        2.3511e-02,  1.6597e-02, -2.4481e-02, -2.2427e-02,  4.0488e-03,\n",
       "                       -4.3717e-03,  2.2158e-02, -3.5059e-03, -7.2403e-03, -1.9640e-02,\n",
       "                       -2.1967e-02,  3.2718e-02,  1.2893e-02,  1.0910e-02, -1.8741e-02,\n",
       "                        5.5125e-03, -4.2523e-03, -1.8502e-03,  1.4205e-02, -1.0590e-02,\n",
       "                       -2.9184e-02,  2.6037e-02, -2.4587e-02,  1.1926e-02,  2.2426e-02,\n",
       "                       -7.3823e-03, -2.2012e-03, -7.3698e-03,  1.6129e-02,  2.8259e-02,\n",
       "                        1.9195e-02, -1.6729e-02, -9.7025e-05, -1.3178e-02, -9.2475e-03,\n",
       "                        2.4162e-02, -3.5724e-03, -2.8775e-03, -1.8774e-02, -1.7760e-03,\n",
       "                       -2.8126e-02, -2.7200e-02, -3.0946e-02, -2.3925e-02, -1.8501e-02,\n",
       "                       -6.3895e-03,  2.3674e-02,  2.4563e-02,  3.0012e-02,  1.4603e-02,\n",
       "                       -1.0195e-02,  2.0926e-02,  1.8027e-03, -3.4715e-02, -1.4341e-02,\n",
       "                       -1.3465e-02,  8.9630e-03, -1.7127e-02,  2.1072e-02, -8.4257e-03,\n",
       "                        3.2467e-02,  1.4251e-02, -2.4775e-02, -5.5607e-03, -6.4474e-03,\n",
       "                        1.0066e-02, -2.4434e-02,  1.7849e-03,  3.4290e-02,  2.1393e-02,\n",
       "                       -1.3453e-02,  8.7991e-03, -7.1380e-03,  2.8454e-02, -1.2610e-02,\n",
       "                       -5.4984e-03, -1.8892e-02, -1.7633e-02,  3.2082e-02,  3.1294e-02,\n",
       "                       -5.7293e-03, -2.5337e-02,  1.7396e-02, -1.0036e-02,  2.5280e-02,\n",
       "                       -4.3118e-03,  1.3266e-02,  2.5356e-02,  2.9055e-02,  2.4459e-02,\n",
       "                        3.3638e-02, -1.2733e-02,  2.9667e-03,  1.5916e-02, -1.6679e-02,\n",
       "                        8.9452e-03,  1.5276e-02, -1.2644e-02, -2.3022e-02,  2.1953e-02,\n",
       "                       -3.0363e-02, -9.3262e-03,  7.1974e-03,  2.6774e-02,  2.2629e-02,\n",
       "                        3.0873e-03,  1.8884e-02, -3.2307e-02,  2.6893e-02, -3.2699e-02,\n",
       "                        4.0309e-04, -2.4949e-02,  3.9550e-03, -2.2180e-02,  2.4911e-02,\n",
       "                        2.1880e-02, -2.4762e-02, -9.4740e-03, -7.4248e-03,  3.3577e-02,\n",
       "                        3.0158e-02,  3.4951e-02,  2.0648e-02,  1.1249e-02, -9.5967e-03,\n",
       "                       -1.3202e-02, -3.3995e-02, -2.3112e-02, -2.4322e-02, -3.3827e-02,\n",
       "                       -2.7059e-02, -2.0718e-02,  1.9752e-02, -5.3166e-04, -2.6899e-02,\n",
       "                       -2.0136e-02, -1.6901e-02,  2.1957e-02,  3.4585e-02, -2.2306e-02,\n",
       "                        2.0725e-02, -5.6771e-03,  4.2635e-03, -8.7452e-03,  4.3830e-03])),\n",
       "              ('performer.net.layers.1.0.norm.weight',\n",
       "               tensor([0.9982, 0.9980, 0.9987, 0.9999, 0.9972, 0.9980, 0.9969, 0.9983, 0.9965,\n",
       "                       1.0056, 0.9998, 0.9996, 1.0006, 0.9973, 0.9962, 0.9991, 0.9990, 0.9988,\n",
       "                       0.9973, 0.9999, 1.0039, 0.9998, 0.9999, 0.9980, 0.9993, 0.9993, 0.9998,\n",
       "                       1.0012, 0.9972, 0.9994, 0.9996, 0.9995, 1.0015, 0.9979, 0.9982, 1.0010,\n",
       "                       0.9979, 0.9962, 1.0009, 0.9982, 0.9976, 0.9975, 0.9980, 0.9994, 0.9994,\n",
       "                       0.9966, 0.9997, 1.0020, 0.9999, 1.0014, 0.9986, 1.0020, 1.0016, 0.9948,\n",
       "                       0.9982, 0.9965, 0.9959, 0.9980, 0.9987, 0.9971, 1.0001, 0.9973, 0.9983,\n",
       "                       0.9974, 0.9977, 0.9988, 0.9992, 1.0033, 0.9964, 0.9989, 1.0009, 0.9983,\n",
       "                       0.9985, 0.9962, 0.9984, 0.9962, 1.0015, 1.0010, 0.9993, 1.0019, 0.9978,\n",
       "                       1.0018, 1.0011, 1.0006, 1.0012, 1.0009, 0.9972, 0.9966, 0.9995, 0.9942,\n",
       "                       1.0012, 1.0003, 0.9994, 0.9991, 0.9997, 0.9991, 0.9999, 1.0004, 0.9992,\n",
       "                       0.9969, 1.0003, 0.9965, 1.0005, 0.9980, 0.9989, 0.9983, 0.9983, 0.9992,\n",
       "                       0.9971, 0.9970, 0.9981, 1.0015, 0.9995, 0.9993, 0.9981, 1.0002, 0.9986,\n",
       "                       1.0017, 1.0008, 0.9978, 0.9977, 0.9982, 0.9985, 1.0003, 0.9949, 0.9995,\n",
       "                       0.9990, 0.9980, 0.9997, 1.0016, 0.9991, 1.0002, 0.9977, 0.9977, 0.9991,\n",
       "                       1.0000, 0.9977, 0.9999, 0.9966, 0.9956, 0.9993, 0.9983, 0.9985, 0.9993,\n",
       "                       0.9988, 0.9996, 0.9989, 1.0000, 1.0004, 0.9975, 1.0019, 0.9973, 0.9990,\n",
       "                       0.9970, 0.9982, 1.0014, 0.9955, 0.9978, 0.9982, 0.9987, 1.0015, 0.9976,\n",
       "                       0.9981, 0.9983, 0.9985, 0.9959, 0.9980, 1.0004, 0.9980, 1.0021, 1.0007,\n",
       "                       1.0000, 0.9983, 0.9984, 0.9996, 1.0000, 0.9981, 0.9992, 1.0000, 0.9988,\n",
       "                       0.9973, 0.9971, 0.9973, 0.9971, 0.9994, 0.9969, 0.9979, 1.0003, 0.9984,\n",
       "                       1.0001, 0.9970, 1.0024, 0.9999, 0.9969, 0.9995, 0.9989, 1.0040, 0.9983,\n",
       "                       0.9991, 1.0044])),\n",
       "              ('performer.net.layers.1.0.norm.bias',\n",
       "               tensor([ 8.3169e-04, -1.5639e-03,  1.9229e-04, -1.5038e-04, -2.1219e-03,\n",
       "                       -1.6194e-03,  8.5664e-04, -6.9794e-04,  1.3780e-03,  2.2078e-03,\n",
       "                        1.8997e-03, -2.4091e-03,  8.9201e-04, -1.1885e-03, -3.4329e-04,\n",
       "                       -2.9714e-04,  1.1614e-03, -1.5637e-03, -3.9004e-03,  5.6839e-04,\n",
       "                        3.9561e-04,  8.3311e-04,  8.3065e-04,  9.3173e-04, -1.8030e-03,\n",
       "                       -6.0367e-04,  1.2089e-03, -8.3909e-04, -2.8192e-03,  9.9991e-04,\n",
       "                        1.7900e-03, -1.0010e-03, -7.0861e-05, -1.2572e-03,  8.1484e-04,\n",
       "                       -1.3723e-03, -5.8463e-04,  1.8551e-03,  6.3558e-04, -1.2040e-03,\n",
       "                        1.5152e-03, -1.1928e-04,  1.5889e-03,  5.3438e-04, -4.2822e-05,\n",
       "                        2.4342e-04,  1.1717e-04,  2.1384e-03,  3.2797e-04,  3.1035e-04,\n",
       "                        8.7900e-04,  6.2032e-04, -8.6615e-04,  4.5847e-03, -2.9396e-04,\n",
       "                        1.7172e-03, -9.3424e-04, -1.5127e-04,  2.4952e-03,  2.8079e-03,\n",
       "                       -8.4666e-04, -2.5558e-04,  2.8092e-04,  9.3305e-04, -2.4715e-03,\n",
       "                       -5.7951e-06,  9.1844e-05, -4.3863e-04,  9.3554e-04, -1.4975e-03,\n",
       "                        7.7010e-04, -1.4732e-03, -1.2909e-03, -4.0084e-03,  3.4756e-04,\n",
       "                       -2.0721e-03,  5.0985e-04, -8.0533e-04,  1.9039e-03,  2.7094e-05,\n",
       "                       -9.7586e-04,  6.8706e-06,  1.1251e-03, -2.4727e-03,  1.5704e-04,\n",
       "                        1.5644e-03,  6.6926e-05, -7.0936e-04, -7.5233e-04,  1.1649e-03,\n",
       "                        1.4127e-04,  9.1485e-04, -2.5763e-04, -1.8668e-03, -2.6394e-05,\n",
       "                       -2.6310e-05,  3.0393e-03, -2.3806e-04,  4.4691e-04, -1.1704e-03,\n",
       "                        8.0837e-04, -8.5197e-04,  1.2582e-03,  1.7678e-03, -5.5311e-04,\n",
       "                       -1.9274e-03,  2.2363e-04, -1.6747e-04,  2.5188e-03,  1.4603e-03,\n",
       "                        1.8459e-03, -1.4125e-03, -3.1458e-04, -1.7519e-03, -3.5223e-03,\n",
       "                       -1.6729e-03, -6.3436e-04, -1.6828e-03, -2.0605e-04, -2.3599e-03,\n",
       "                       -8.5635e-04,  1.7852e-03, -1.0657e-03,  2.1512e-04, -4.9081e-04,\n",
       "                       -1.0722e-03,  5.8198e-04, -3.7224e-04, -7.8959e-04,  2.3426e-03,\n",
       "                        5.6536e-04,  3.6809e-04, -3.5322e-04,  3.1719e-05, -9.2563e-04,\n",
       "                       -1.2229e-03, -2.4219e-04,  1.5959e-03, -3.1012e-04, -3.4760e-03,\n",
       "                       -3.6598e-04, -5.3789e-04, -1.7493e-03, -7.5009e-04, -9.8404e-04,\n",
       "                        1.4403e-03, -1.2107e-03,  1.8979e-04, -6.8498e-04,  1.3872e-03,\n",
       "                       -8.1285e-06,  1.1195e-03,  3.0147e-04, -3.4882e-03, -4.0141e-06,\n",
       "                       -1.5128e-03,  3.5262e-03, -1.7651e-03,  1.2511e-03,  1.3384e-04,\n",
       "                        3.6541e-03, -1.3993e-03,  7.9096e-04,  2.5371e-04,  1.3415e-04,\n",
       "                        1.7062e-03,  1.0898e-03,  1.2922e-03,  5.7511e-04, -1.3767e-03,\n",
       "                       -1.1425e-03,  7.1464e-04,  2.4610e-03, -6.7197e-05,  1.1701e-05,\n",
       "                       -2.7915e-04, -1.2196e-03, -1.1503e-03,  7.8282e-04, -3.7211e-05,\n",
       "                       -1.3819e-03,  2.9809e-03, -1.4073e-03,  2.5136e-03,  8.6874e-04,\n",
       "                       -1.4913e-03,  2.7475e-05, -6.8204e-05,  4.2976e-04, -6.0193e-04,\n",
       "                       -2.8629e-03, -1.3652e-03,  9.1059e-05,  2.8772e-03, -1.0185e-03,\n",
       "                        2.5503e-04,  6.1381e-04,  1.3218e-03, -5.1438e-04,  2.2093e-03])),\n",
       "              ('performer.net.layers.1.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-1.4473,  1.3916,  0.4578,  ...,  2.4941, -2.5781,  0.9048],\n",
       "                       [-0.6689, -1.3936, -0.9961,  ...,  0.3545, -0.1205,  0.7524],\n",
       "                       [ 0.0091, -1.1006, -1.9932,  ...,  1.6895,  0.8418,  0.8877],\n",
       "                       ...,\n",
       "                       [ 0.8579, -1.2695, -0.6167,  ...,  0.3630, -1.6562,  0.8193],\n",
       "                       [ 0.7383, -0.3628, -1.1221,  ..., -0.1613, -0.6699,  1.5576],\n",
       "                       [-0.6519, -0.2207,  0.5903,  ...,  0.2084, -0.8301, -0.2236]])),\n",
       "              ('performer.net.layers.1.0.fn.to_q.weight',\n",
       "               tensor([[ 0.0364, -0.0350, -0.0562,  ..., -0.0537, -0.0407, -0.0276],\n",
       "                       [-0.0658, -0.0391, -0.0025,  ..., -0.0463, -0.0495,  0.0105],\n",
       "                       [-0.0453,  0.0219, -0.0093,  ..., -0.0280,  0.0580,  0.0200],\n",
       "                       ...,\n",
       "                       [ 0.0265, -0.0279,  0.0142,  ..., -0.0572, -0.0414,  0.0283],\n",
       "                       [ 0.0413,  0.0122, -0.0229,  ..., -0.0357, -0.0666,  0.0476],\n",
       "                       [-0.0680,  0.0753, -0.0487,  ..., -0.0026,  0.0278,  0.0520]])),\n",
       "              ('performer.net.layers.1.0.fn.to_k.weight',\n",
       "               tensor([[ 0.0086, -0.0284, -0.0548,  ..., -0.0646, -0.0391,  0.0057],\n",
       "                       [-0.0011, -0.0480, -0.0443,  ...,  0.0192, -0.0412,  0.0290],\n",
       "                       [ 0.0242, -0.0545,  0.0496,  ...,  0.0428, -0.0178,  0.0629],\n",
       "                       ...,\n",
       "                       [ 0.0068,  0.0100,  0.0456,  ..., -0.0508, -0.0191, -0.0474],\n",
       "                       [ 0.0371, -0.0461, -0.0505,  ...,  0.0366, -0.0358, -0.0015],\n",
       "                       [ 0.0605,  0.0013,  0.0284,  ..., -0.0416, -0.0287,  0.0197]])),\n",
       "              ('performer.net.layers.1.0.fn.to_v.weight',\n",
       "               tensor([[ 0.0448, -0.0168,  0.0551,  ...,  0.0082, -0.0363,  0.0409],\n",
       "                       [ 0.0629,  0.0174, -0.0307,  ...,  0.0532,  0.0315, -0.0154],\n",
       "                       [ 0.0375, -0.0602, -0.0164,  ...,  0.0569, -0.0318,  0.0702],\n",
       "                       ...,\n",
       "                       [ 0.0424, -0.0648, -0.0462,  ...,  0.0345,  0.0505, -0.0637],\n",
       "                       [-0.0379,  0.0293, -0.0679,  ..., -0.0294,  0.0297,  0.0032],\n",
       "                       [-0.0050, -0.0696,  0.0692,  ...,  0.0252, -0.0211, -0.0293]])),\n",
       "              ('performer.net.layers.1.0.fn.to_out.weight',\n",
       "               tensor([[-0.0307, -0.0253, -0.0349,  ..., -0.0345,  0.0210, -0.0185],\n",
       "                       [-0.0324,  0.0338,  0.0312,  ...,  0.0135,  0.0100, -0.0112],\n",
       "                       [ 0.0042,  0.0340, -0.0351,  ..., -0.0181, -0.0156,  0.0311],\n",
       "                       ...,\n",
       "                       [ 0.0162,  0.0083, -0.0359,  ...,  0.0345, -0.0161, -0.0047],\n",
       "                       [-0.0321, -0.0242,  0.0189,  ...,  0.0145,  0.0129,  0.0306],\n",
       "                       [-0.0237, -0.0223, -0.0067,  ...,  0.0305, -0.0395, -0.0229]])),\n",
       "              ('performer.net.layers.1.0.fn.to_out.bias',\n",
       "               tensor([-0.0115,  0.0334,  0.0172,  0.0199,  0.0099, -0.0059, -0.0095,  0.0199,\n",
       "                       -0.0052, -0.0224,  0.0157,  0.0086,  0.0147, -0.0174, -0.0092, -0.0178,\n",
       "                       -0.0187, -0.0180,  0.0331, -0.0076, -0.0298, -0.0135,  0.0306,  0.0215,\n",
       "                       -0.0071,  0.0306, -0.0214, -0.0200, -0.0366,  0.0320, -0.0290,  0.0151,\n",
       "                       -0.0287,  0.0113,  0.0057, -0.0046, -0.0308, -0.0341, -0.0150, -0.0104,\n",
       "                        0.0007, -0.0264,  0.0391, -0.0321,  0.0056, -0.0234, -0.0047,  0.0326,\n",
       "                       -0.0228,  0.0316, -0.0347,  0.0154,  0.0227,  0.0219, -0.0229, -0.0329,\n",
       "                        0.0057,  0.0276,  0.0325, -0.0234, -0.0286,  0.0175,  0.0386, -0.0366,\n",
       "                        0.0255, -0.0374, -0.0014, -0.0070,  0.0028, -0.0294, -0.0157, -0.0144,\n",
       "                       -0.0275, -0.0136,  0.0355, -0.0208,  0.0005,  0.0275,  0.0085, -0.0364,\n",
       "                       -0.0370,  0.0031, -0.0146, -0.0130, -0.0070,  0.0304, -0.0150, -0.0320,\n",
       "                       -0.0164,  0.0308,  0.0099,  0.0360, -0.0374,  0.0080, -0.0060, -0.0298,\n",
       "                        0.0357,  0.0222, -0.0282,  0.0136, -0.0256, -0.0385, -0.0324, -0.0115,\n",
       "                        0.0110,  0.0198, -0.0159, -0.0216,  0.0161,  0.0369,  0.0212,  0.0215,\n",
       "                       -0.0293, -0.0243, -0.0180,  0.0029, -0.0024, -0.0199,  0.0164, -0.0367,\n",
       "                        0.0328, -0.0093,  0.0012, -0.0008, -0.0105, -0.0014, -0.0305, -0.0092,\n",
       "                        0.0074,  0.0026, -0.0174,  0.0269,  0.0170, -0.0073,  0.0276,  0.0156,\n",
       "                       -0.0171,  0.0124, -0.0203, -0.0220,  0.0010, -0.0387,  0.0075,  0.0299,\n",
       "                       -0.0038, -0.0092,  0.0344,  0.0068,  0.0173, -0.0367,  0.0302, -0.0010,\n",
       "                        0.0259,  0.0264,  0.0387,  0.0177,  0.0185,  0.0109, -0.0100, -0.0341,\n",
       "                        0.0254,  0.0101, -0.0355, -0.0331, -0.0121, -0.0038,  0.0316,  0.0265,\n",
       "                       -0.0352, -0.0090,  0.0048,  0.0316,  0.0076, -0.0383, -0.0186,  0.0298,\n",
       "                        0.0212, -0.0166, -0.0247, -0.0116,  0.0402, -0.0051,  0.0268,  0.0248,\n",
       "                       -0.0139,  0.0170, -0.0215,  0.0010,  0.0243,  0.0304,  0.0267,  0.0217,\n",
       "                       -0.0319, -0.0211, -0.0217, -0.0119,  0.0252,  0.0058,  0.0093,  0.0175])),\n",
       "              ('performer.net.layers.1.1.norm.weight',\n",
       "               tensor([0.9995, 1.0036, 1.0012, 1.0020, 0.9990, 0.9999, 0.9997, 1.0008, 1.0051,\n",
       "                       1.0005, 1.0017, 1.0008, 1.0025, 0.9994, 1.0007, 1.0004, 1.0038, 1.0038,\n",
       "                       0.9993, 1.0005, 1.0002, 1.0005, 1.0015, 1.0073, 1.0002, 1.0050, 1.0023,\n",
       "                       0.9971, 1.0056, 1.0004, 1.0011, 0.9994, 0.9981, 1.0023, 1.0020, 0.9997,\n",
       "                       1.0018, 1.0032, 0.9995, 1.0045, 0.9985, 1.0046, 0.9994, 1.0001, 1.0002,\n",
       "                       1.0004, 1.0001, 1.0019, 1.0042, 0.9997, 1.0028, 1.0023, 1.0017, 0.9986,\n",
       "                       0.9996, 1.0009, 1.0002, 1.0007, 1.0005, 0.9983, 1.0035, 1.0003, 0.9999,\n",
       "                       1.0005, 1.0013, 1.0027, 1.0035, 0.9987, 1.0006, 1.0016, 1.0071, 1.0018,\n",
       "                       0.9994, 1.0011, 1.0020, 1.0066, 1.0022, 1.0041, 1.0035, 1.0025, 1.0002,\n",
       "                       1.0035, 1.0006, 0.9997, 1.0027, 1.0034, 1.0035, 1.0037, 1.0025, 1.0038,\n",
       "                       1.0047, 1.0032, 1.0007, 1.0031, 1.0006, 1.0014, 0.9999, 1.0014, 1.0018,\n",
       "                       1.0040, 1.0027, 1.0015, 1.0088, 0.9981, 0.9996, 1.0010, 1.0011, 1.0009,\n",
       "                       0.9996, 0.9987, 1.0047, 1.0069, 1.0011, 1.0075, 0.9974, 1.0017, 0.9986,\n",
       "                       0.9982, 1.0023, 1.0004, 1.0015, 1.0016, 1.0001, 1.0005, 1.0014, 1.0081,\n",
       "                       0.9992, 1.0013, 1.0020, 0.9997, 1.0077, 0.9995, 1.0000, 1.0039, 1.0033,\n",
       "                       0.9992, 0.9985, 1.0013, 1.0071, 1.0022, 1.0006, 1.0045, 1.0000, 1.0019,\n",
       "                       1.0036, 1.0030, 1.0038, 1.0013, 0.9989, 1.0019, 1.0050, 1.0007, 1.0006,\n",
       "                       1.0010, 1.0040, 1.0034, 1.0021, 1.0027, 1.0022, 1.0043, 1.0081, 0.9979,\n",
       "                       1.0014, 1.0016, 1.0014, 0.9993, 0.9998, 1.0077, 1.0043, 1.0014, 1.0010,\n",
       "                       1.0016, 1.0012, 1.0072, 1.0024, 1.0026, 0.9992, 1.0019, 1.0050, 1.0027,\n",
       "                       1.0004, 0.9998, 0.9988, 0.9999, 1.0049, 1.0006, 1.0042, 0.9992, 1.0010,\n",
       "                       1.0026, 1.0041, 1.0003, 1.0063, 1.0031, 1.0058, 1.0013, 0.9998, 1.0018,\n",
       "                       1.0010, 1.0015])),\n",
       "              ('performer.net.layers.1.1.norm.bias',\n",
       "               tensor([ 7.8911e-04,  1.4362e-04, -5.6238e-05, -2.9545e-04, -3.1124e-04,\n",
       "                        9.5594e-04,  6.6470e-04,  9.1285e-04, -5.6894e-04,  1.5363e-04,\n",
       "                        3.8268e-04, -2.3918e-03,  2.8137e-04, -1.2806e-03, -4.2985e-05,\n",
       "                       -6.5194e-04, -1.1610e-04,  1.5425e-04,  1.2443e-04,  4.4525e-05,\n",
       "                        1.7797e-03, -1.7656e-03, -1.3890e-03,  2.7203e-04,  1.4831e-03,\n",
       "                       -9.8636e-04,  1.5781e-04, -3.1231e-04,  4.0808e-04, -6.0510e-04,\n",
       "                        1.1743e-03,  7.0250e-04, -1.1925e-03, -1.4084e-03, -5.6524e-04,\n",
       "                        1.1513e-03, -8.9949e-04, -1.0708e-03, -4.6970e-04,  8.4087e-04,\n",
       "                       -1.0523e-03, -2.2132e-04,  1.2799e-03, -1.5402e-03,  7.5851e-04,\n",
       "                       -8.6847e-05, -4.2629e-04, -7.1997e-04,  5.3904e-04, -1.0278e-03,\n",
       "                        1.9542e-03, -5.1932e-05, -1.0692e-04,  1.2785e-03, -1.6656e-03,\n",
       "                       -1.2924e-03,  4.2798e-05,  2.5474e-04, -2.0073e-04, -1.0154e-03,\n",
       "                        1.7565e-04,  9.9293e-04,  2.2042e-04,  3.8934e-04, -1.8224e-04,\n",
       "                       -5.1884e-05, -6.6221e-04, -2.2374e-03, -8.8691e-04, -9.6841e-04,\n",
       "                        6.4674e-04, -1.3434e-04, -8.6717e-04, -2.4678e-04, -1.5020e-03,\n",
       "                       -5.4904e-04, -2.8919e-04,  2.3429e-04, -3.3894e-04,  7.5353e-05,\n",
       "                        2.7966e-04, -1.4827e-03,  1.4858e-03,  1.1128e-03,  7.1749e-04,\n",
       "                       -3.9097e-04,  3.7462e-04, -3.3880e-04, -3.6280e-04, -8.4102e-04,\n",
       "                       -3.8440e-05,  7.8945e-04,  2.6992e-04, -4.3866e-04,  1.4540e-03,\n",
       "                       -6.6343e-04, -6.9971e-04,  7.0417e-04, -4.6650e-04,  5.5602e-04,\n",
       "                       -2.6402e-03, -1.5304e-03, -8.3710e-04,  2.7847e-04, -2.3805e-04,\n",
       "                       -2.0084e-04, -4.1436e-04,  1.3609e-04, -1.7506e-04, -4.3153e-04,\n",
       "                       -2.1550e-04, -1.5496e-05, -5.3667e-05,  1.9032e-03,  1.3610e-03,\n",
       "                        5.9319e-04,  3.5967e-04,  6.7360e-04,  8.9561e-04,  1.5128e-03,\n",
       "                        1.2636e-03,  8.1608e-05,  4.9335e-05, -1.3296e-04, -1.6881e-04,\n",
       "                       -5.5411e-04,  2.2407e-04,  6.2026e-04,  1.7324e-04, -1.6589e-03,\n",
       "                        1.9857e-04, -1.6513e-03, -2.5778e-04, -1.5892e-03,  4.3167e-04,\n",
       "                       -2.5620e-03,  7.8030e-04,  3.1697e-04,  5.7824e-04, -1.5663e-03,\n",
       "                       -9.4869e-04,  7.2429e-04, -8.6941e-04,  5.9067e-05, -3.7497e-04,\n",
       "                        1.0061e-03, -3.8854e-04, -4.3940e-04, -8.7532e-04,  1.8058e-03,\n",
       "                       -1.2834e-03, -1.2611e-03, -1.5819e-04, -1.9364e-03, -6.5123e-04,\n",
       "                       -2.9760e-04,  1.6572e-03,  1.9892e-05, -2.5487e-04,  1.2133e-04,\n",
       "                       -5.2324e-04,  2.3887e-04,  7.2417e-04,  6.9493e-04,  5.5350e-04,\n",
       "                        1.3796e-03,  2.2589e-05,  1.8104e-03, -8.7861e-04, -3.4226e-04,\n",
       "                        7.8124e-05,  1.8060e-03,  2.9501e-04,  1.6036e-04, -1.4847e-03,\n",
       "                       -4.9361e-04,  9.4566e-04,  5.3352e-04,  2.6290e-04,  2.7274e-04,\n",
       "                       -3.3663e-04,  1.0784e-03, -2.6253e-05,  2.5912e-04, -2.3027e-03,\n",
       "                       -2.6994e-04, -1.3741e-03, -3.9481e-04,  4.5741e-04, -2.6604e-03,\n",
       "                        9.8214e-04,  7.0182e-05,  2.0895e-04,  1.1548e-04, -7.2494e-05,\n",
       "                       -6.1957e-04,  1.7144e-03,  5.8782e-04,  1.0357e-04, -9.5781e-04])),\n",
       "              ('performer.net.layers.1.1.fn.fn.w1.weight',\n",
       "               tensor([[-0.0296, -0.0452, -0.0094,  ..., -0.0551,  0.0696,  0.0368],\n",
       "                       [-0.0440,  0.0219, -0.0227,  ..., -0.0659,  0.0460,  0.0687],\n",
       "                       [-0.0420,  0.0373,  0.0153,  ...,  0.0352, -0.0644, -0.0191],\n",
       "                       ...,\n",
       "                       [ 0.0422,  0.0611,  0.0507,  ...,  0.0330, -0.0095, -0.0138],\n",
       "                       [ 0.0521,  0.0164,  0.0107,  ...,  0.0218,  0.0375,  0.0149],\n",
       "                       [-0.0358,  0.0656,  0.0139,  ..., -0.0640, -0.0019,  0.0663]])),\n",
       "              ('performer.net.layers.1.1.fn.fn.w1.bias',\n",
       "               tensor([ 5.4910e-02, -1.6852e-02,  5.5973e-02, -8.1108e-03,  1.4832e-02,\n",
       "                       -2.8445e-02,  5.8001e-02, -2.1720e-02, -6.6852e-03, -5.4097e-02,\n",
       "                       -9.2195e-03, -2.1901e-02,  3.3662e-02, -2.7929e-02, -6.9992e-02,\n",
       "                        2.3502e-02, -5.7486e-03,  1.5654e-02,  4.6763e-02,  7.1269e-02,\n",
       "                       -4.0540e-03, -2.1544e-02, -2.0703e-02,  6.6445e-02,  6.3105e-02,\n",
       "                       -4.0576e-02, -2.5743e-02, -7.0167e-02, -1.6123e-02, -4.6740e-02,\n",
       "                       -4.9272e-02,  4.7465e-02,  1.9527e-02, -2.3497e-02, -1.4141e-03,\n",
       "                        3.5580e-02, -4.4449e-02,  3.0889e-02, -1.1022e-02,  3.0767e-02,\n",
       "                        9.9992e-03, -6.5214e-02,  5.8627e-02, -6.2156e-02,  1.8596e-02,\n",
       "                       -6.8824e-02, -6.1848e-02,  6.6619e-03, -2.2465e-02, -3.7711e-02,\n",
       "                       -5.9920e-02,  3.6677e-02, -6.3706e-02,  4.5382e-02, -1.9116e-02,\n",
       "                        3.8689e-02, -5.9208e-02,  2.3288e-02, -3.3271e-02,  1.6744e-02,\n",
       "                       -6.7256e-02,  5.0232e-02, -1.1436e-02, -5.8948e-02, -2.7353e-02,\n",
       "                       -1.1468e-02, -3.9780e-02, -6.2770e-02, -2.8566e-02, -4.8827e-02,\n",
       "                       -6.8089e-02,  3.1139e-02,  3.9939e-03, -6.8070e-02, -6.5370e-02,\n",
       "                       -9.2435e-03, -2.1716e-02,  1.4879e-04, -2.5980e-02,  3.7208e-02,\n",
       "                       -2.8614e-02, -1.7093e-02, -4.7295e-05, -1.3416e-02,  6.3234e-02,\n",
       "                        1.0018e-02,  5.7119e-02,  5.4381e-02,  1.9910e-02,  4.9760e-03,\n",
       "                        5.9097e-02, -1.5960e-02,  3.6541e-02, -5.3401e-02, -4.7443e-02,\n",
       "                        5.2521e-02, -2.5860e-02, -3.2057e-02, -5.2205e-02,  4.4290e-02,\n",
       "                       -5.0705e-02,  3.2379e-02,  6.3022e-02, -2.6143e-03,  5.1029e-02,\n",
       "                        6.6281e-02,  4.9007e-02,  5.0249e-02, -4.6304e-02, -6.8934e-02,\n",
       "                       -4.3759e-02,  6.9755e-02, -5.4582e-02,  6.0523e-02, -4.1438e-02,\n",
       "                       -4.5035e-02, -1.7309e-02, -1.2910e-03,  4.6674e-02, -2.4646e-02,\n",
       "                        2.2628e-02, -1.1878e-02, -1.9794e-02,  6.0442e-02,  7.1462e-02,\n",
       "                       -2.7337e-02,  1.7920e-02,  4.1721e-02,  2.1458e-02, -4.4993e-02,\n",
       "                        4.5164e-02, -4.2024e-02,  4.4036e-02, -1.2214e-02,  6.7124e-02,\n",
       "                        5.8685e-04,  3.6803e-02, -6.6381e-02, -2.1693e-02,  4.5995e-02,\n",
       "                       -5.0928e-03,  4.7723e-02, -3.1817e-02,  6.0060e-02,  6.6509e-02,\n",
       "                       -3.8569e-02, -2.3262e-03,  6.0849e-02,  4.7494e-02, -2.2381e-04,\n",
       "                        2.0395e-02,  5.7479e-02,  3.8212e-02, -1.9202e-02, -6.9617e-02,\n",
       "                       -4.7758e-02,  2.9264e-02,  6.8441e-02, -4.9297e-03,  1.6462e-02,\n",
       "                        5.2572e-02, -5.0721e-02, -3.0701e-02,  3.4996e-02,  4.0123e-03,\n",
       "                        4.8526e-02,  9.4723e-03, -2.8399e-02,  1.8279e-02, -4.5045e-02,\n",
       "                       -1.4329e-02,  6.8510e-02,  1.0124e-02,  3.4810e-02,  1.3315e-02,\n",
       "                       -5.0362e-02, -1.1978e-02, -3.4513e-03, -4.6418e-02, -5.4981e-03,\n",
       "                        6.5490e-02, -5.4651e-02,  5.9205e-02,  3.0569e-02, -6.3542e-02,\n",
       "                       -2.4786e-02,  6.5877e-02,  5.0096e-03,  6.8661e-02,  4.9575e-02,\n",
       "                        2.9813e-02,  3.8108e-02,  5.6478e-02,  4.9109e-02, -4.6133e-02,\n",
       "                        5.2884e-02, -6.7002e-02,  1.7212e-02,  2.5559e-02, -6.3886e-02,\n",
       "                        6.6103e-03,  4.4255e-02,  5.8170e-02, -8.7864e-03, -8.7450e-03,\n",
       "                       -1.3976e-02, -1.2816e-02, -5.1621e-02, -2.2727e-02,  5.4589e-02,\n",
       "                        4.4914e-02,  2.9659e-02, -1.6946e-02, -4.7822e-02, -1.3855e-02,\n",
       "                       -6.5507e-02, -2.9576e-03,  2.3478e-02, -1.2105e-04, -5.9827e-02,\n",
       "                        1.3439e-02,  5.9082e-02,  6.4469e-02, -4.2798e-04, -5.6200e-02,\n",
       "                       -1.5994e-02,  2.1141e-02,  2.1698e-02, -5.3891e-02, -5.2090e-02,\n",
       "                       -3.8742e-02,  3.3318e-02, -4.5809e-02, -1.1186e-03, -4.6193e-02,\n",
       "                        3.1761e-02,  4.1214e-03, -6.3394e-02,  2.1081e-02, -6.4584e-02,\n",
       "                        7.9592e-03, -2.7184e-02, -6.4407e-02, -3.8817e-02, -4.5548e-02,\n",
       "                       -2.3945e-02,  1.7304e-02,  5.0303e-02,  4.7625e-02, -3.5016e-02,\n",
       "                        6.5857e-02,  1.5444e-02, -5.0071e-03, -7.0606e-02, -1.4208e-02,\n",
       "                       -5.1110e-02,  2.6374e-02, -6.3964e-02, -4.3150e-02, -1.9606e-03,\n",
       "                        5.5359e-02, -4.7872e-02,  6.8470e-02,  4.7679e-02,  5.6186e-02,\n",
       "                        4.9868e-02, -3.8964e-02, -2.9530e-02,  5.6383e-02, -2.0249e-02,\n",
       "                        3.6114e-02, -5.1776e-02, -5.4184e-02, -6.9821e-02,  2.4421e-02,\n",
       "                       -6.8908e-03, -1.4870e-02, -2.6670e-02, -2.0415e-02, -2.6269e-03,\n",
       "                        6.0946e-02,  4.2428e-02, -5.5736e-02, -4.7855e-02, -1.5399e-02,\n",
       "                        3.6642e-02,  2.2011e-02,  6.0173e-02,  9.4296e-03,  1.1832e-02,\n",
       "                       -3.8466e-03, -6.1783e-02, -5.2167e-02,  4.2832e-02,  5.5672e-02,\n",
       "                       -5.3837e-02,  2.2606e-02, -1.1788e-02, -4.5698e-02,  5.5231e-02,\n",
       "                        1.4226e-02, -6.2288e-02, -6.6142e-02, -5.4718e-02,  1.9487e-02,\n",
       "                        5.6927e-02,  5.6362e-02,  1.9434e-02, -1.9323e-02, -6.7708e-02,\n",
       "                       -4.5262e-02, -3.7649e-02,  4.5740e-02, -1.5495e-02, -3.4779e-02,\n",
       "                        5.1924e-02, -3.2075e-02,  1.9222e-02,  1.0749e-02, -4.2560e-02,\n",
       "                        7.0846e-03, -1.1255e-02,  5.5237e-02,  1.0221e-02, -2.8667e-03,\n",
       "                       -2.7440e-02,  2.4320e-02, -1.1858e-02,  6.7638e-02,  3.7021e-02,\n",
       "                       -6.1848e-02,  4.9620e-02,  3.2880e-02, -5.0664e-02,  2.8159e-02,\n",
       "                       -3.7718e-02, -6.2164e-02,  3.3459e-02, -9.8781e-03, -6.9284e-02,\n",
       "                        2.2010e-02,  1.5223e-03,  2.0309e-02,  9.8842e-04,  5.7838e-02,\n",
       "                        7.4259e-03, -1.3661e-03,  6.3486e-02,  5.2794e-02,  5.2942e-02,\n",
       "                       -4.4455e-02, -3.0807e-02,  2.8122e-02, -1.5015e-02,  3.7649e-02,\n",
       "                       -5.2762e-02,  1.5009e-02, -2.1012e-02, -5.3353e-02,  6.9485e-02,\n",
       "                        2.6273e-02,  5.0450e-02, -6.4824e-02,  2.3525e-02, -6.5280e-03,\n",
       "                        1.6195e-02, -6.0650e-03, -1.3830e-02, -1.3808e-02, -4.6186e-02,\n",
       "                        4.2062e-02, -3.2309e-02,  3.7119e-02,  3.1314e-02,  3.6428e-02,\n",
       "                        7.0525e-02, -2.6878e-02, -2.8452e-02, -1.2971e-03,  8.4855e-03,\n",
       "                       -5.1268e-02, -5.0834e-02,  2.5242e-02,  2.5530e-02, -4.4412e-02,\n",
       "                       -5.5843e-02, -3.9798e-02, -6.4355e-03, -1.8170e-02,  6.3271e-02,\n",
       "                        2.5008e-02, -3.0775e-02, -8.9111e-03,  6.8773e-03, -1.5028e-02,\n",
       "                        5.6869e-02,  1.8295e-02,  4.9213e-02, -7.6693e-03, -2.7751e-03,\n",
       "                        3.8206e-02, -3.7185e-02,  5.8546e-03, -5.9709e-04, -2.2059e-02,\n",
       "                        1.7270e-02,  1.8386e-02,  1.8035e-02,  3.4428e-02,  5.5916e-03,\n",
       "                       -5.2268e-02, -3.5666e-02, -3.4584e-02, -2.0555e-03, -9.4854e-03,\n",
       "                       -1.3637e-02, -1.0933e-02,  4.4134e-02, -2.5090e-02, -4.8400e-02,\n",
       "                       -1.7410e-02, -2.9763e-03, -5.2835e-02,  6.0724e-02,  2.5524e-02,\n",
       "                       -5.9816e-02,  1.8562e-02,  7.0355e-02, -5.7408e-02,  1.0514e-02,\n",
       "                        5.0786e-02, -6.2787e-02, -5.6880e-02, -3.5913e-02, -2.9572e-02,\n",
       "                        4.5213e-02,  5.8677e-02,  5.8488e-02,  1.3518e-04, -3.6775e-02,\n",
       "                       -8.9504e-03,  6.5726e-02, -3.6208e-02, -5.0479e-02,  3.2899e-02,\n",
       "                        1.7868e-02, -2.2333e-02, -6.7351e-02, -6.1207e-02, -4.7889e-02,\n",
       "                        4.1190e-03, -2.1708e-02, -1.9981e-02, -4.7180e-02,  2.5621e-02,\n",
       "                       -5.3355e-03,  1.6872e-04, -1.5673e-02, -1.5591e-02, -3.2164e-02,\n",
       "                       -2.7295e-03,  3.2034e-02, -1.2348e-02, -4.5563e-02, -4.6143e-03,\n",
       "                       -2.8426e-04,  4.1830e-02, -4.3533e-02,  5.4597e-02, -4.8912e-02,\n",
       "                        1.8879e-02,  4.3634e-02,  4.9075e-02, -2.1314e-02, -1.7098e-02,\n",
       "                        3.3099e-04,  5.8604e-02,  9.4581e-03, -1.5843e-02, -1.3452e-02,\n",
       "                        1.4809e-02, -3.4527e-03,  7.4577e-03, -6.0182e-02, -4.1969e-02,\n",
       "                        5.0067e-02, -4.7154e-02, -5.8081e-02, -1.0274e-02, -4.5133e-02,\n",
       "                       -8.3192e-03, -2.3928e-02,  2.8433e-02, -3.9482e-02, -6.6517e-02,\n",
       "                       -3.1962e-02, -2.4608e-02, -8.7298e-03,  6.3744e-02,  1.7269e-02,\n",
       "                       -2.2373e-02, -6.3801e-03,  6.5866e-02,  4.8273e-02, -2.4370e-03,\n",
       "                       -8.1194e-03, -3.7664e-02,  1.0214e-02, -1.7173e-03,  3.4378e-02,\n",
       "                        4.8769e-02,  1.1386e-03,  4.2017e-02,  3.4187e-03, -4.7382e-02,\n",
       "                        1.1261e-02, -5.3000e-02, -3.3291e-02, -4.9941e-02,  8.1922e-03,\n",
       "                       -7.9182e-03,  4.8317e-02,  2.2493e-02,  2.2658e-02,  3.3592e-02,\n",
       "                       -1.6401e-02,  2.4788e-02,  3.5955e-02, -1.4230e-02, -3.8744e-02,\n",
       "                       -8.7558e-03,  3.1350e-02,  1.0935e-02,  5.0609e-02,  5.8984e-02,\n",
       "                       -1.2158e-02,  2.1404e-02,  1.6030e-02,  2.7343e-02, -2.9895e-02,\n",
       "                        4.9995e-02,  5.7328e-02, -5.9666e-02,  4.3832e-02, -4.1530e-04,\n",
       "                        3.6517e-02, -6.2579e-02, -3.1934e-02,  2.8197e-03,  3.2405e-02,\n",
       "                        6.7464e-02, -1.0793e-02, -4.5223e-02,  3.9734e-02,  5.2747e-03,\n",
       "                        1.5841e-02, -1.3867e-02, -6.9922e-02,  4.1958e-03, -5.4210e-02,\n",
       "                       -1.4975e-02, -3.6300e-02, -4.2138e-03, -6.8411e-02, -4.0393e-02,\n",
       "                       -2.3572e-02,  4.3487e-02,  1.2975e-02, -8.9366e-03, -2.3062e-02,\n",
       "                       -3.3565e-02,  1.6122e-03, -6.5474e-02,  1.0120e-02, -4.3529e-02,\n",
       "                       -5.7686e-02,  1.0103e-02,  6.3612e-02,  1.7497e-02,  5.7742e-02,\n",
       "                        1.5742e-02,  3.2666e-02,  4.4689e-02, -4.6724e-02,  3.0740e-02,\n",
       "                       -4.3954e-02, -1.9431e-02,  3.7269e-02, -1.2543e-02,  6.0982e-02,\n",
       "                        1.1400e-02,  1.3223e-02,  2.9629e-02,  6.5978e-02, -6.6510e-02,\n",
       "                        6.8601e-02, -6.5341e-02,  3.8738e-02, -4.6840e-02,  4.9521e-02,\n",
       "                        1.9636e-02,  5.3962e-03, -5.1965e-03, -1.2441e-02, -2.7054e-02,\n",
       "                       -5.7537e-03, -5.5305e-03, -4.4720e-02,  4.9251e-02,  2.7052e-02,\n",
       "                        3.4940e-03, -1.4232e-02, -5.4396e-02,  8.6224e-03,  5.8781e-02,\n",
       "                       -5.3212e-02, -3.9454e-02, -3.5574e-02,  4.7096e-02,  6.3059e-03,\n",
       "                        3.6220e-02, -7.0447e-02, -5.1947e-02, -4.1091e-02, -8.7726e-03,\n",
       "                       -3.0934e-02, -2.5690e-02,  2.3146e-02, -5.4342e-02, -6.0843e-02,\n",
       "                       -6.2889e-02,  2.2420e-03, -2.4693e-03, -4.8180e-02,  7.7866e-04,\n",
       "                        5.5646e-02, -6.7376e-02,  1.6950e-02, -3.7790e-03, -1.4635e-02,\n",
       "                       -6.4024e-02, -1.9549e-02, -3.4916e-02, -2.7379e-02, -3.9406e-02,\n",
       "                        1.7337e-03,  6.8675e-02, -5.1940e-02,  4.9812e-02,  2.2021e-03,\n",
       "                        1.2102e-02,  2.2658e-02, -3.6802e-02,  3.6994e-03,  1.4126e-02,\n",
       "                        6.6095e-02, -1.7343e-03,  5.3172e-02, -1.2515e-02, -7.4456e-03,\n",
       "                       -3.0443e-02, -4.9373e-03,  5.1719e-02, -6.8015e-02, -8.9999e-03,\n",
       "                       -6.9130e-02,  5.2427e-03,  3.3202e-02,  5.9490e-02,  2.8003e-02,\n",
       "                       -2.2927e-02,  7.0863e-02, -1.3566e-02,  8.5042e-03, -4.4435e-02,\n",
       "                        3.4144e-03,  5.4168e-02, -3.8206e-03, -7.8242e-03,  3.8872e-02,\n",
       "                       -1.5158e-02,  3.2047e-03, -5.5985e-02, -2.0671e-02,  2.0631e-05,\n",
       "                       -2.2613e-02, -1.4208e-02,  3.6392e-02,  7.7348e-03, -3.3414e-02,\n",
       "                        2.4029e-02, -6.6478e-02,  5.5007e-03,  2.9768e-02,  3.1718e-02,\n",
       "                        4.9864e-02,  3.0075e-02,  6.2281e-02, -4.5902e-02, -5.3508e-02,\n",
       "                       -2.0766e-02,  4.9978e-02, -6.8320e-02, -6.5822e-02, -2.0338e-02,\n",
       "                       -6.4272e-02, -4.0463e-02,  3.7161e-02, -8.4831e-03,  2.2050e-02,\n",
       "                        1.3575e-02, -1.4976e-02, -1.0386e-02,  2.0600e-02,  1.0230e-02,\n",
       "                        4.1458e-02, -5.2024e-02, -5.2193e-02,  1.3267e-02,  6.5657e-02,\n",
       "                        1.3211e-02,  6.3866e-02,  4.7408e-02, -5.8540e-02,  6.7360e-02,\n",
       "                        3.7394e-02,  6.4889e-02,  5.7302e-02,  6.2340e-02,  2.7725e-03,\n",
       "                        3.2005e-02,  5.7892e-03,  1.6545e-02, -2.0946e-03,  5.5930e-02,\n",
       "                       -3.1142e-02, -5.5054e-03,  2.7107e-02, -4.5353e-02,  3.4942e-02,\n",
       "                       -4.2477e-02,  4.8556e-02,  2.9356e-03,  8.8196e-03,  5.9710e-02,\n",
       "                       -3.2744e-02,  2.7837e-02, -2.1403e-02, -1.0402e-02,  3.6707e-02,\n",
       "                       -3.2353e-03,  2.7862e-02, -6.0252e-03,  1.3101e-02, -1.5697e-02,\n",
       "                        5.3614e-02,  6.8035e-02,  4.5250e-02, -4.6914e-02,  1.3972e-02,\n",
       "                        5.9713e-02,  1.8065e-02, -5.0759e-02, -2.1523e-03, -6.2205e-02,\n",
       "                        1.8843e-02, -5.1790e-02, -5.9092e-03, -4.4126e-02, -2.6182e-02,\n",
       "                        5.8460e-02,  4.0983e-02, -2.9830e-02,  6.3846e-02,  5.4930e-02,\n",
       "                        1.3716e-02, -6.4594e-02,  5.5320e-02, -2.7658e-02, -6.6433e-02,\n",
       "                       -5.9783e-02, -3.3071e-02,  3.7117e-02,  1.3323e-02, -1.5150e-02,\n",
       "                       -3.9984e-02, -4.1514e-02, -2.0775e-03, -6.2799e-02,  6.6060e-04,\n",
       "                        3.0690e-02, -5.3157e-03, -4.3407e-02, -5.0454e-02,  4.4573e-02,\n",
       "                        4.7190e-02, -2.6442e-02, -5.6676e-02, -2.0080e-02,  1.6287e-02])),\n",
       "              ('performer.net.layers.1.1.fn.fn.w2.weight',\n",
       "               tensor([[-0.0113, -0.0157,  0.0287,  ..., -0.0082,  0.0157,  0.0026],\n",
       "                       [-0.0356, -0.0242, -0.0045,  ...,  0.0034, -0.0186, -0.0289],\n",
       "                       [ 0.0214, -0.0244, -0.0140,  ...,  0.0302, -0.0226, -0.0182],\n",
       "                       ...,\n",
       "                       [-0.0310,  0.0058, -0.0092,  ...,  0.0320,  0.0249, -0.0262],\n",
       "                       [-0.0193, -0.0156,  0.0006,  ..., -0.0037, -0.0253,  0.0322],\n",
       "                       [ 0.0142,  0.0104, -0.0105,  ...,  0.0206,  0.0122, -0.0299]])),\n",
       "              ('performer.net.layers.1.1.fn.fn.w2.bias',\n",
       "               tensor([ 2.0991e-02,  9.7094e-03,  2.5029e-02,  2.3786e-02, -2.6904e-02,\n",
       "                        2.7399e-02,  1.1744e-02, -2.9629e-02, -2.3965e-02,  3.5071e-02,\n",
       "                        1.9479e-02,  1.8663e-02,  1.3742e-02,  1.4981e-02,  3.5062e-02,\n",
       "                       -3.6060e-02, -1.8384e-02,  3.3240e-02, -3.3483e-02,  7.8991e-03,\n",
       "                       -3.5366e-02,  8.1932e-03, -1.1816e-02,  2.5933e-02,  2.1581e-02,\n",
       "                       -1.3642e-02,  1.5882e-02,  1.9009e-02, -7.5487e-03,  8.7971e-03,\n",
       "                       -1.6887e-02, -2.6081e-02, -2.4237e-02, -1.3435e-02,  1.9733e-02,\n",
       "                        1.2660e-02, -4.2493e-04,  1.7244e-02,  9.3503e-04, -3.3121e-02,\n",
       "                        3.4347e-02, -2.4389e-02,  2.6956e-02,  3.0906e-02, -3.5444e-02,\n",
       "                       -6.6922e-03,  2.9886e-02,  2.2770e-02,  1.6532e-02, -2.2076e-02,\n",
       "                        3.1363e-02, -2.3329e-02, -3.6895e-03, -2.4606e-02, -2.9316e-02,\n",
       "                        3.4462e-02,  1.0117e-02, -1.2843e-02,  2.7471e-02, -2.6379e-02,\n",
       "                        2.7400e-02,  2.4608e-02, -8.4070e-03,  2.5207e-02, -1.6124e-02,\n",
       "                        1.2263e-02, -2.9486e-02, -1.1604e-02,  2.8420e-02,  7.0808e-03,\n",
       "                       -3.1084e-02,  1.2708e-02, -2.5530e-02,  2.8149e-02,  9.2868e-03,\n",
       "                        7.8666e-03,  2.2097e-02,  1.7884e-02,  2.1568e-02,  3.4825e-02,\n",
       "                       -1.9364e-02,  1.8606e-02,  1.4662e-02, -2.1506e-02,  2.5926e-03,\n",
       "                       -3.3767e-03,  8.0785e-03, -2.2048e-02,  7.2509e-03,  3.3928e-02,\n",
       "                        1.0976e-03,  1.9247e-02,  1.6324e-02,  1.0962e-02, -1.5880e-02,\n",
       "                       -1.7684e-02, -3.0302e-02,  1.6174e-02, -8.6251e-03, -2.4319e-02,\n",
       "                       -2.7554e-02,  1.4110e-02,  7.2693e-03,  1.0297e-02, -3.2276e-02,\n",
       "                       -2.3235e-02,  5.5927e-03, -5.0125e-03,  1.6252e-02,  7.2415e-04,\n",
       "                        8.4976e-03,  1.1127e-02,  2.8378e-02,  1.4566e-03, -2.3004e-02,\n",
       "                        2.7833e-02, -2.7987e-02,  7.8459e-03,  3.2929e-02, -3.0332e-02,\n",
       "                        1.9356e-02,  1.6169e-02, -1.3206e-02,  1.9533e-02, -2.1547e-02,\n",
       "                       -1.3039e-02,  2.6326e-03,  2.8156e-02, -1.7893e-02,  1.9830e-02,\n",
       "                        1.3733e-02, -3.0995e-02,  5.6399e-03, -2.2122e-02,  3.5192e-02,\n",
       "                       -6.4149e-03, -1.1842e-02,  1.8470e-02,  2.2418e-02, -2.6429e-02,\n",
       "                       -5.1249e-03, -3.0479e-02, -8.5005e-03, -3.4599e-02,  3.3323e-02,\n",
       "                        1.6662e-03, -1.0672e-02,  4.0285e-03, -3.0620e-02,  1.5537e-02,\n",
       "                        2.9068e-02,  2.6938e-03,  2.2380e-02,  3.2217e-02, -5.2377e-03,\n",
       "                        1.3932e-02,  1.6147e-02,  1.5433e-02, -2.3789e-03,  2.3672e-02,\n",
       "                       -9.8133e-03,  3.6388e-05,  1.0498e-02,  2.3091e-02,  2.4298e-03,\n",
       "                        6.4086e-03, -1.1153e-02,  2.1886e-02, -8.7159e-03, -2.0249e-02,\n",
       "                        1.4292e-02, -2.8872e-02,  2.9428e-02, -2.9654e-02,  1.9381e-02,\n",
       "                       -2.6182e-02,  1.1658e-03, -2.3928e-03, -1.5702e-02, -1.3519e-03,\n",
       "                        1.9859e-02,  1.0740e-02, -9.2000e-03, -3.3301e-02, -1.4239e-02,\n",
       "                        9.9556e-03,  3.3342e-02, -8.6760e-03,  3.2885e-03,  3.4616e-02,\n",
       "                        2.8978e-02,  1.2406e-02,  1.1013e-02,  7.0258e-04,  3.2935e-02,\n",
       "                        7.4001e-03,  7.1531e-04,  2.3453e-02,  3.2348e-02,  7.0195e-03])),\n",
       "              ('performer.net.layers.2.0.norm.weight',\n",
       "               tensor([1.0004, 0.9972, 1.0000, 0.9993, 0.9989, 0.9990, 1.0000, 0.9986, 0.9981,\n",
       "                       0.9993, 1.0000, 0.9983, 0.9977, 1.0001, 0.9957, 0.9987, 0.9991, 0.9981,\n",
       "                       1.0025, 0.9982, 0.9999, 0.9987, 0.9984, 0.9990, 0.9973, 0.9988, 0.9991,\n",
       "                       0.9928, 0.9975, 0.9960, 0.9975, 0.9969, 0.9964, 0.9994, 1.0003, 0.9986,\n",
       "                       0.9978, 0.9971, 0.9976, 1.0024, 0.9972, 0.9974, 0.9977, 0.9997, 0.9999,\n",
       "                       1.0003, 0.9999, 0.9988, 1.0007, 0.9949, 0.9986, 0.9944, 0.9997, 0.9983,\n",
       "                       0.9998, 0.9972, 1.0019, 0.9998, 0.9993, 1.0005, 1.0006, 0.9981, 0.9976,\n",
       "                       0.9973, 0.9985, 0.9998, 0.9947, 0.9998, 0.9979, 0.9998, 0.9961, 0.9988,\n",
       "                       0.9988, 1.0007, 0.9998, 0.9956, 0.9991, 1.0021, 1.0026, 0.9976, 0.9999,\n",
       "                       0.9994, 0.9986, 0.9997, 0.9983, 0.9997, 1.0037, 0.9981, 1.0009, 1.0031,\n",
       "                       1.0010, 0.9988, 0.9998, 0.9991, 0.9985, 0.9998, 0.9962, 0.9965, 0.9979,\n",
       "                       0.9968, 0.9991, 1.0001, 0.9982, 0.9975, 1.0018, 1.0001, 1.0004, 0.9997,\n",
       "                       0.9998, 0.9987, 0.9970, 0.9954, 0.9985, 0.9975, 1.0007, 0.9984, 0.9968,\n",
       "                       1.0047, 1.0004, 0.9987, 0.9992, 0.9978, 0.9996, 1.0005, 0.9981, 0.9983,\n",
       "                       1.0002, 1.0017, 0.9980, 0.9941, 1.0012, 0.9987, 0.9988, 0.9996, 0.9982,\n",
       "                       0.9976, 0.9997, 0.9989, 0.9983, 1.0000, 0.9990, 0.9980, 1.0004, 0.9972,\n",
       "                       1.0009, 0.9997, 0.9986, 0.9973, 1.0016, 0.9992, 0.9955, 0.9992, 0.9981,\n",
       "                       0.9985, 0.9981, 1.0062, 0.9978, 0.9997, 1.0012, 0.9997, 0.9985, 0.9981,\n",
       "                       0.9971, 0.9941, 0.9968, 0.9996, 0.9986, 0.9994, 0.9985, 0.9992, 1.0036,\n",
       "                       1.0010, 0.9985, 0.9959, 0.9967, 0.9962, 0.9965, 1.0004, 0.9955, 1.0017,\n",
       "                       0.9996, 0.9993, 1.0003, 1.0005, 0.9983, 0.9954, 0.9957, 0.9998, 1.0026,\n",
       "                       0.9987, 0.9984, 1.0005, 0.9979, 0.9993, 0.9996, 0.9995, 1.0008, 1.0052,\n",
       "                       0.9984, 0.9978])),\n",
       "              ('performer.net.layers.2.0.norm.bias',\n",
       "               tensor([-6.1001e-04, -5.8377e-04,  2.2448e-04, -1.1954e-03, -7.7195e-04,\n",
       "                       -1.9662e-03, -8.5242e-04,  9.4309e-04, -7.3534e-04, -7.4669e-04,\n",
       "                        1.2998e-03,  2.7338e-03,  1.7423e-03, -8.4581e-04,  1.1985e-03,\n",
       "                       -6.9684e-04,  7.8762e-04,  1.6397e-03, -1.1307e-03, -4.4179e-04,\n",
       "                       -5.8075e-04,  1.0655e-03,  1.8635e-03,  7.3550e-04, -1.3338e-03,\n",
       "                       -6.4600e-05,  2.0765e-03,  1.1305e-03, -8.0788e-04, -6.4865e-04,\n",
       "                        2.2012e-03,  7.9129e-04, -3.1025e-04, -6.5025e-04,  1.4302e-03,\n",
       "                       -1.2702e-03,  1.4237e-03, -5.6467e-04,  8.8064e-04,  1.4323e-03,\n",
       "                        2.7854e-03, -7.4808e-04,  1.5827e-04,  3.4257e-04, -1.1955e-03,\n",
       "                       -6.9859e-05,  4.4338e-04,  5.9377e-04,  1.3906e-03,  1.0691e-04,\n",
       "                        7.1398e-04, -1.5556e-03, -1.7724e-03,  1.3210e-03,  5.7782e-04,\n",
       "                       -6.0389e-04,  7.1955e-04, -3.4927e-04,  5.5030e-04,  1.0107e-03,\n",
       "                       -7.3156e-04,  2.9962e-04,  3.7149e-03,  9.8651e-04, -6.6322e-04,\n",
       "                        6.9697e-04, -3.6225e-04, -7.5802e-04, -2.6839e-04, -2.0160e-04,\n",
       "                       -1.4479e-03, -1.8521e-03, -1.4053e-03, -5.3391e-04, -3.4808e-06,\n",
       "                        2.8791e-03,  1.3653e-04,  6.4860e-04, -4.0465e-04, -4.0694e-04,\n",
       "                       -5.5039e-04,  1.0854e-04,  1.2089e-03,  1.5114e-04, -4.0029e-04,\n",
       "                       -6.3039e-04, -2.0705e-04, -2.3312e-03, -9.2772e-04, -1.3488e-03,\n",
       "                        5.0461e-04,  3.5013e-04, -9.9611e-04, -1.0034e-03,  1.6247e-03,\n",
       "                        3.2263e-05,  2.7286e-04,  9.6265e-04,  5.5690e-04, -1.0209e-03,\n",
       "                       -6.1530e-04, -5.8601e-04, -1.2774e-03,  1.5370e-03, -1.8839e-03,\n",
       "                        3.7359e-04, -1.0250e-03, -9.4404e-05,  2.2032e-03,  9.6280e-05,\n",
       "                       -6.0894e-04, -1.6725e-03,  2.1766e-03, -8.5459e-04, -1.0352e-03,\n",
       "                       -6.5724e-04, -9.5470e-04, -1.5096e-03, -9.5945e-05, -2.3219e-03,\n",
       "                       -6.4629e-04, -8.1010e-04,  4.2991e-05,  3.6578e-04, -2.7496e-04,\n",
       "                        1.5666e-04, -7.8944e-04,  2.1575e-03,  8.3672e-04,  1.6476e-03,\n",
       "                       -7.1342e-04, -5.3310e-04,  9.2929e-04,  2.8896e-04, -2.1623e-03,\n",
       "                       -9.3866e-04,  3.4962e-04,  4.0377e-04,  4.3238e-04,  1.6531e-03,\n",
       "                       -8.0716e-06, -1.4132e-04,  9.9928e-06, -2.1513e-03, -1.2185e-03,\n",
       "                        4.7625e-04, -8.9617e-04,  1.1672e-03, -1.7751e-03,  2.4284e-04,\n",
       "                       -9.3869e-04,  1.2733e-03,  2.1536e-03, -1.5897e-03, -1.3855e-03,\n",
       "                        3.3990e-04,  2.0976e-03, -3.2653e-04, -3.0508e-04, -6.1986e-04,\n",
       "                        9.2183e-04, -1.3576e-03,  7.1702e-04, -1.2697e-03,  1.5615e-03,\n",
       "                        1.4487e-03,  1.1599e-03, -2.9953e-04, -4.4123e-04, -5.7146e-05,\n",
       "                       -8.0169e-04,  4.1469e-05,  1.6125e-03, -1.5894e-03, -2.7620e-04,\n",
       "                        2.8703e-03, -2.1113e-03, -1.7764e-03, -1.7581e-03, -6.5414e-04,\n",
       "                       -7.5488e-04,  8.0742e-04, -6.9130e-04,  7.5276e-04,  1.8989e-03,\n",
       "                       -3.9280e-03, -1.1324e-03,  7.0814e-05, -5.4432e-04, -4.7255e-04,\n",
       "                       -5.3716e-04, -1.5494e-04,  1.1902e-03,  5.5109e-04, -1.2509e-03,\n",
       "                        6.9582e-04, -3.5774e-04, -1.1379e-03, -1.6953e-03,  1.5560e-03])),\n",
       "              ('performer.net.layers.2.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-1.1133, -0.7554,  0.6367,  ...,  0.8530,  0.8765, -0.4207],\n",
       "                       [ 1.1055, -1.8652, -0.7334,  ...,  1.6270,  2.2324,  0.8276],\n",
       "                       [-0.5566,  0.1230, -0.3064,  ...,  1.9678, -0.3652, -0.5078],\n",
       "                       ...,\n",
       "                       [-1.0869, -0.2771,  1.2715,  ..., -1.0225,  1.4922, -0.1163],\n",
       "                       [ 0.3794, -1.2080, -0.3989,  ..., -0.7734,  2.1914, -0.2318],\n",
       "                       [-1.3701, -1.4482, -1.8848,  ...,  0.6357,  0.2317, -2.0410]])),\n",
       "              ('performer.net.layers.2.0.fn.to_q.weight',\n",
       "               tensor([[-0.0680,  0.0486, -0.0633,  ...,  0.0297,  0.0050, -0.0014],\n",
       "                       [-0.0696,  0.0387, -0.0606,  ...,  0.0170,  0.0463,  0.0187],\n",
       "                       [ 0.0698, -0.0328,  0.0273,  ...,  0.0393, -0.0572, -0.0024],\n",
       "                       ...,\n",
       "                       [-0.0379,  0.0394, -0.0329,  ..., -0.0679, -0.0462,  0.0579],\n",
       "                       [-0.0104, -0.0326, -0.0254,  ..., -0.0425, -0.0432, -0.0687],\n",
       "                       [ 0.0139,  0.0070, -0.0611,  ...,  0.0619,  0.0197,  0.0635]])),\n",
       "              ('performer.net.layers.2.0.fn.to_k.weight',\n",
       "               tensor([[ 0.0514,  0.0045,  0.0330,  ..., -0.0682, -0.0157,  0.0436],\n",
       "                       [-0.0067, -0.0180, -0.0071,  ..., -0.0026, -0.0489,  0.0449],\n",
       "                       [-0.0206,  0.0539,  0.0062,  ...,  0.0680, -0.0599, -0.0087],\n",
       "                       ...,\n",
       "                       [-0.0633,  0.0469,  0.0012,  ..., -0.0494,  0.0325, -0.0204],\n",
       "                       [-0.0523, -0.0188, -0.0355,  ...,  0.0174,  0.0364, -0.0012],\n",
       "                       [-0.0421, -0.0505,  0.0202,  ...,  0.0207, -0.0181, -0.0120]])),\n",
       "              ('performer.net.layers.2.0.fn.to_v.weight',\n",
       "               tensor([[-0.0109, -0.0293, -0.0488,  ..., -0.0318,  0.0287, -0.0630],\n",
       "                       [ 0.0130, -0.0355,  0.0442,  ..., -0.0679,  0.0175, -0.0046],\n",
       "                       [-0.0256, -0.0154, -0.0313,  ...,  0.0429,  0.0343, -0.0009],\n",
       "                       ...,\n",
       "                       [-0.0319, -0.0618,  0.0383,  ..., -0.0642,  0.0117,  0.0562],\n",
       "                       [ 0.0184, -0.0237,  0.0051,  ..., -0.0207, -0.0231,  0.0507],\n",
       "                       [-0.0471, -0.0165,  0.0359,  ...,  0.0054, -0.0335,  0.0395]])),\n",
       "              ('performer.net.layers.2.0.fn.to_out.weight',\n",
       "               tensor([[ 0.0249,  0.0111,  0.0111,  ...,  0.0351, -0.0142,  0.0237],\n",
       "                       [ 0.0210, -0.0175,  0.0259,  ...,  0.0181,  0.0282,  0.0032],\n",
       "                       [-0.0281,  0.0356,  0.0104,  ..., -0.0381,  0.0016,  0.0198],\n",
       "                       ...,\n",
       "                       [-0.0134,  0.0277,  0.0181,  ...,  0.0279, -0.0006,  0.0088],\n",
       "                       [-0.0353,  0.0158, -0.0332,  ...,  0.0230,  0.0070,  0.0340],\n",
       "                       [-0.0261,  0.0082,  0.0207,  ...,  0.0032, -0.0124, -0.0367]])),\n",
       "              ('performer.net.layers.2.0.fn.to_out.bias',\n",
       "               tensor([-3.2279e-02, -5.7759e-03, -1.0549e-02, -3.6681e-03, -1.5697e-03,\n",
       "                       -2.6271e-02, -1.8408e-02,  3.5432e-02,  2.1864e-02, -1.6418e-02,\n",
       "                       -1.3337e-02, -3.0318e-02,  1.1050e-02,  2.2634e-02,  1.8118e-02,\n",
       "                        3.5591e-02,  1.9186e-02,  1.9733e-02, -3.8313e-02, -1.1409e-02,\n",
       "                        1.7498e-02, -3.5611e-02,  2.9470e-02, -2.2539e-03, -2.9360e-02,\n",
       "                        1.2440e-02, -5.5024e-03,  2.4407e-02,  3.2288e-02, -3.3121e-02,\n",
       "                       -2.3812e-02, -3.6897e-02, -1.3002e-02, -8.7630e-03,  3.7057e-02,\n",
       "                       -8.9868e-03, -1.2890e-02,  3.5308e-02,  5.3020e-03, -3.0936e-02,\n",
       "                       -3.5330e-02, -3.1512e-02, -1.7553e-02,  1.3001e-02,  8.4293e-03,\n",
       "                       -2.6638e-02, -3.8399e-02, -3.9276e-02, -1.7397e-02, -2.9067e-02,\n",
       "                       -2.9823e-02, -1.8425e-03,  1.8568e-02, -2.3549e-02,  3.5315e-02,\n",
       "                       -1.3948e-02,  3.1691e-02,  3.8823e-02,  1.7678e-02,  6.2320e-03,\n",
       "                       -1.5281e-02,  1.9349e-02,  4.6059e-03,  8.6375e-03,  3.7430e-02,\n",
       "                       -1.9661e-02, -8.8655e-03, -1.5144e-02,  1.0994e-02,  8.0576e-03,\n",
       "                       -2.1002e-02, -3.9989e-03, -2.9738e-03,  1.4562e-02, -1.9307e-02,\n",
       "                       -3.0240e-02,  5.3939e-03,  3.0218e-02, -2.4166e-02,  3.4648e-02,\n",
       "                       -1.0862e-02, -1.1213e-02, -3.7719e-02,  2.7645e-02,  3.4239e-02,\n",
       "                       -3.2879e-02, -2.0126e-03,  4.2942e-03, -1.4839e-02,  1.0585e-02,\n",
       "                        3.7756e-02, -5.7746e-03, -9.6911e-03, -1.8905e-03,  8.9610e-03,\n",
       "                        3.9595e-02,  1.1539e-02, -2.2248e-02,  6.9282e-05,  5.5963e-04,\n",
       "                       -3.2568e-02,  1.7975e-02, -8.0933e-03,  2.3236e-02, -7.7321e-03,\n",
       "                        1.3808e-02, -2.5534e-02, -2.6052e-02, -3.7462e-02, -3.4038e-02,\n",
       "                        5.0175e-03, -5.6187e-03,  7.9788e-04, -2.3250e-04, -1.7263e-02,\n",
       "                       -1.4300e-02,  7.6475e-03,  3.5469e-02,  6.5532e-05, -2.0237e-02,\n",
       "                       -7.9132e-03, -2.4521e-02, -3.2330e-02,  7.6251e-03, -3.4424e-03,\n",
       "                       -3.2762e-02, -1.0418e-02,  1.8789e-02,  3.4521e-02, -1.9000e-02,\n",
       "                       -2.4509e-02,  9.9255e-03,  6.2225e-03,  8.0519e-03,  2.7103e-02,\n",
       "                       -5.2646e-03,  2.9329e-02, -1.4681e-02,  2.8567e-02, -1.3593e-02,\n",
       "                        7.0470e-03,  1.4042e-02, -3.8296e-02,  3.9576e-02,  2.2904e-02,\n",
       "                        3.3595e-02,  1.3488e-02, -2.9495e-05,  1.7899e-02,  1.3870e-02,\n",
       "                       -1.5848e-02, -3.7737e-03,  3.7233e-02, -3.6566e-02, -7.2760e-03,\n",
       "                        1.0592e-02, -1.6275e-02,  1.5750e-02, -1.1871e-02, -1.8222e-02,\n",
       "                        2.6760e-03,  2.3613e-02,  1.9821e-02,  9.1378e-03, -3.8106e-02,\n",
       "                       -1.0921e-02, -8.2094e-03,  6.8189e-04, -1.8777e-03,  3.5553e-02,\n",
       "                        2.1795e-02,  2.3445e-02,  2.2722e-02,  2.8752e-02,  1.8797e-02,\n",
       "                        2.9316e-02,  7.7285e-03, -2.5514e-02, -9.8254e-03,  3.6306e-02,\n",
       "                       -7.7225e-03, -1.4770e-05, -6.5807e-03, -3.9253e-02,  1.4928e-02,\n",
       "                       -4.0585e-04, -2.4689e-03, -9.3977e-03,  2.0631e-02, -3.6439e-02,\n",
       "                       -2.5999e-03,  2.9361e-02, -1.4087e-02,  1.4508e-02, -2.0526e-02,\n",
       "                        1.8387e-03,  9.2281e-03,  6.2947e-03,  9.2511e-03,  1.1229e-02])),\n",
       "              ('performer.net.layers.2.1.norm.weight',\n",
       "               tensor([1.0035, 1.0018, 0.9989, 1.0008, 1.0025, 1.0006, 1.0069, 1.0001, 1.0064,\n",
       "                       1.0002, 1.0012, 1.0008, 1.0060, 0.9987, 1.0000, 1.0021, 1.0038, 1.0003,\n",
       "                       1.0030, 1.0017, 1.0143, 1.0028, 1.0022, 1.0099, 0.9985, 1.0027, 1.0041,\n",
       "                       1.0048, 1.0017, 1.0025, 1.0008, 1.0003, 1.0011, 1.0018, 1.0012, 1.0012,\n",
       "                       1.0010, 1.0022, 0.9996, 1.0028, 0.9991, 0.9969, 1.0004, 1.0036, 1.0051,\n",
       "                       1.0026, 1.0005, 1.0048, 1.0030, 1.0017, 1.0057, 1.0059, 0.9995, 1.0061,\n",
       "                       1.0010, 1.0002, 1.0042, 1.0001, 1.0008, 1.0008, 1.0077, 1.0030, 1.0016,\n",
       "                       1.0039, 1.0036, 1.0048, 1.0065, 1.0003, 1.0105, 1.0000, 1.0017, 1.0032,\n",
       "                       1.0020, 1.0006, 1.0036, 1.0011, 1.0047, 1.0072, 1.0015, 1.0003, 1.0010,\n",
       "                       1.0030, 1.0009, 1.0036, 0.9976, 1.0040, 1.0037, 1.0002, 1.0039, 1.0058,\n",
       "                       1.0048, 1.0026, 1.0014, 1.0000, 1.0001, 0.9996, 1.0017, 1.0018, 1.0042,\n",
       "                       1.0012, 1.0019, 1.0019, 1.0044, 1.0019, 1.0003, 1.0011, 1.0033, 1.0037,\n",
       "                       1.0001, 0.9998, 0.9999, 1.0064, 1.0007, 1.0078, 1.0023, 1.0016, 1.0031,\n",
       "                       1.0006, 1.0032, 0.9992, 0.9981, 1.0083, 1.0008, 1.0004, 1.0013, 1.0036,\n",
       "                       1.0034, 1.0007, 1.0033, 1.0026, 1.0097, 1.0006, 1.0060, 1.0041, 1.0051,\n",
       "                       0.9989, 1.0074, 1.0024, 1.0030, 1.0019, 1.0025, 1.0064, 1.0014, 0.9983,\n",
       "                       1.0014, 1.0030, 1.0003, 1.0021, 0.9997, 1.0077, 1.0022, 1.0016, 1.0023,\n",
       "                       1.0029, 0.9993, 1.0014, 0.9995, 1.0039, 1.0003, 1.0011, 1.0026, 0.9985,\n",
       "                       0.9999, 1.0010, 1.0019, 1.0006, 1.0017, 1.0013, 1.0073, 1.0062, 1.0009,\n",
       "                       1.0020, 1.0015, 1.0107, 1.0011, 1.0020, 1.0003, 1.0006, 1.0033, 1.0009,\n",
       "                       1.0013, 1.0025, 1.0028, 1.0043, 1.0020, 1.0039, 1.0044, 0.9981, 1.0005,\n",
       "                       1.0014, 1.0096, 1.0049, 1.0081, 1.0015, 1.0072, 1.0010, 1.0024, 1.0005,\n",
       "                       1.0020, 1.0014])),\n",
       "              ('performer.net.layers.2.1.norm.bias',\n",
       "               tensor([ 1.0170e-04, -2.8850e-04,  1.2995e-03,  3.9965e-05,  2.7184e-04,\n",
       "                        1.3364e-05, -7.2432e-04,  1.2660e-03, -1.2900e-03, -3.7101e-04,\n",
       "                       -1.7730e-03,  6.1913e-04, -2.1948e-04,  6.3496e-04,  1.6283e-03,\n",
       "                       -1.0733e-03, -1.7331e-04, -5.5833e-05,  1.2120e-03,  8.9874e-04,\n",
       "                       -4.5612e-04, -3.8568e-04,  6.4435e-04, -1.4317e-03, -1.4320e-03,\n",
       "                        7.5023e-04, -1.2341e-03, -1.2912e-03,  2.7194e-04,  1.3631e-04,\n",
       "                       -1.1159e-04,  5.6481e-04,  1.8177e-04, -1.1548e-03,  2.6262e-04,\n",
       "                        2.1932e-04,  4.2377e-05, -2.0881e-04, -7.8568e-04, -4.0575e-04,\n",
       "                       -5.1821e-04, -4.3626e-04,  1.4386e-03,  5.7471e-04,  8.7669e-04,\n",
       "                        8.4665e-04, -4.2414e-04, -6.0842e-04,  5.7582e-04, -1.3005e-03,\n",
       "                        6.2793e-04,  1.1812e-03,  8.3292e-04,  3.0944e-04, -3.0756e-04,\n",
       "                       -1.2758e-05, -2.1815e-05,  2.2668e-04,  1.2679e-04, -1.4906e-05,\n",
       "                       -3.3537e-04,  7.6593e-04, -4.4096e-04,  3.2217e-04, -5.3503e-04,\n",
       "                        4.3512e-05, -5.2212e-04, -1.3531e-03,  8.6632e-04,  1.5141e-03,\n",
       "                       -4.7097e-04, -1.5027e-03, -4.5184e-04,  1.7486e-03, -1.0026e-04,\n",
       "                        1.7513e-04, -1.8744e-04, -1.3663e-03, -9.2776e-04,  1.5153e-03,\n",
       "                        1.4281e-04, -7.5476e-04,  2.2263e-04,  6.3695e-04,  4.2453e-04,\n",
       "                       -9.6374e-05, -2.6768e-04,  6.6486e-04,  1.0741e-04,  5.7630e-04,\n",
       "                        1.2001e-03, -1.2005e-03,  5.6000e-04,  4.4718e-04,  1.0051e-04,\n",
       "                        1.1448e-03,  8.1714e-04, -1.4118e-03,  1.8531e-03,  2.3469e-04,\n",
       "                       -2.3079e-03, -3.9729e-05,  2.6040e-04, -6.3904e-04,  9.2653e-04,\n",
       "                       -1.2991e-03,  4.9501e-04, -3.7730e-04,  5.6273e-04,  3.2612e-05,\n",
       "                       -1.1862e-04,  1.7783e-03,  4.1100e-04,  7.1749e-04,  5.3082e-04,\n",
       "                        9.5115e-04,  2.5687e-04,  1.4078e-04,  3.2438e-03,  2.2438e-03,\n",
       "                       -6.0791e-04, -2.6236e-04,  7.4239e-04,  9.2679e-05,  1.0052e-03,\n",
       "                        6.6619e-04,  7.0204e-04, -4.5937e-04,  9.5109e-04,  6.1692e-04,\n",
       "                        3.1216e-04, -3.9055e-04,  1.3419e-04,  4.2366e-07, -1.3542e-03,\n",
       "                        1.3834e-03,  1.0562e-03,  1.4637e-03,  5.5918e-04,  1.2741e-04,\n",
       "                       -6.5582e-04, -1.4310e-03, -1.4564e-03,  4.9103e-04, -1.5390e-04,\n",
       "                        8.5134e-04, -5.4524e-04, -6.2715e-04,  1.0109e-03, -4.8012e-04,\n",
       "                       -4.0146e-04, -2.8044e-05,  9.9357e-04, -3.0262e-04,  1.1008e-03,\n",
       "                       -7.9867e-04,  9.7497e-04,  4.5229e-04,  2.4819e-04, -1.2431e-05,\n",
       "                       -4.4410e-04,  8.6677e-04, -1.1339e-03, -1.6967e-03, -4.0014e-04,\n",
       "                       -5.2290e-04,  5.5111e-04,  6.5974e-04, -4.5344e-04, -6.7509e-04,\n",
       "                       -1.2832e-05,  7.1539e-04, -2.2017e-04, -8.0818e-04, -4.9068e-05,\n",
       "                        8.7606e-04,  2.9130e-04,  7.4316e-04,  1.1081e-04,  4.5368e-04,\n",
       "                        1.2177e-03, -8.7665e-04, -1.5870e-04, -1.6114e-04,  1.2121e-03,\n",
       "                       -2.8100e-04, -2.6215e-04, -3.5504e-03, -2.7652e-04, -3.6573e-04,\n",
       "                        3.6234e-04,  1.4205e-03, -1.0054e-03,  9.4635e-04,  1.3306e-04,\n",
       "                        4.3831e-04,  1.6613e-03,  2.0158e-05, -4.0476e-04,  2.7777e-04])),\n",
       "              ('performer.net.layers.2.1.fn.fn.w1.weight',\n",
       "               tensor([[-0.0401, -0.0147, -0.0679,  ...,  0.0527, -0.0500,  0.0545],\n",
       "                       [-0.0111,  0.0017, -0.0264,  ...,  0.0559,  0.0030, -0.0206],\n",
       "                       [ 0.0061,  0.0423,  0.0125,  ..., -0.0477,  0.0336, -0.0549],\n",
       "                       ...,\n",
       "                       [-0.0091, -0.0452,  0.0520,  ...,  0.0112,  0.0022, -0.0219],\n",
       "                       [ 0.0400,  0.0489,  0.0284,  ..., -0.0488, -0.0547,  0.0256],\n",
       "                       [ 0.0544, -0.0245,  0.0084,  ...,  0.0607,  0.0129,  0.0218]])),\n",
       "              ('performer.net.layers.2.1.fn.fn.w1.bias',\n",
       "               tensor([-0.0229, -0.0282,  0.0004,  0.0193, -0.0460, -0.0665, -0.0679, -0.0536,\n",
       "                       -0.0090, -0.0043, -0.0539, -0.0217,  0.0641,  0.0275, -0.0535, -0.0693,\n",
       "                       -0.0435, -0.0703, -0.0630, -0.0356, -0.0175, -0.0295,  0.0168,  0.0326,\n",
       "                        0.0657, -0.0437,  0.0589, -0.0500,  0.0292,  0.0675, -0.0606,  0.0508,\n",
       "                        0.0294,  0.0586,  0.0163, -0.0645, -0.0620,  0.0517, -0.0067, -0.0029,\n",
       "                       -0.0644, -0.0215, -0.0458,  0.0694, -0.0007,  0.0258,  0.0411,  0.0457,\n",
       "                       -0.0338,  0.0178,  0.0253, -0.0033,  0.0594, -0.0104, -0.0102, -0.0659,\n",
       "                       -0.0109,  0.0066, -0.0446, -0.0569,  0.0051,  0.0281,  0.0116,  0.0484,\n",
       "                        0.0398,  0.0091, -0.0598, -0.0577, -0.0444,  0.0432, -0.0348, -0.0420,\n",
       "                       -0.0259,  0.0290, -0.0562, -0.0408, -0.0328,  0.0289, -0.0402,  0.0579,\n",
       "                       -0.0042,  0.0267,  0.0045, -0.0483,  0.0527,  0.0643, -0.0028, -0.0487,\n",
       "                        0.0337, -0.0457, -0.0419, -0.0135,  0.0388, -0.0153,  0.0081, -0.0624,\n",
       "                        0.0287,  0.0105, -0.0356, -0.0399, -0.0566, -0.0389, -0.0175,  0.0224,\n",
       "                        0.0383,  0.0221,  0.0349, -0.0486, -0.0542,  0.0309, -0.0330, -0.0581,\n",
       "                       -0.0465,  0.0195,  0.0456,  0.0067,  0.0130,  0.0591,  0.0134, -0.0566,\n",
       "                       -0.0596,  0.0162,  0.0592,  0.0012, -0.0021, -0.0029,  0.0573,  0.0155,\n",
       "                       -0.0508,  0.0279,  0.0107,  0.0115, -0.0093, -0.0143,  0.0023, -0.0351,\n",
       "                        0.0638, -0.0672, -0.0519,  0.0408,  0.0205,  0.0170, -0.0373, -0.0188,\n",
       "                       -0.0644, -0.0669,  0.0505,  0.0053,  0.0212,  0.0222,  0.0522, -0.0272,\n",
       "                       -0.0328,  0.0428, -0.0010, -0.0531,  0.0078, -0.0600,  0.0451,  0.0296,\n",
       "                       -0.0315, -0.0643, -0.0255, -0.0054, -0.0579,  0.0580,  0.0211, -0.0071,\n",
       "                       -0.0503,  0.0304,  0.0200,  0.0520,  0.0082, -0.0257, -0.0224, -0.0186,\n",
       "                       -0.0207, -0.0391,  0.0474, -0.0052,  0.0708,  0.0225, -0.0495,  0.0686,\n",
       "                       -0.0548,  0.0519, -0.0173,  0.0353,  0.0095,  0.0335, -0.0715,  0.0489,\n",
       "                       -0.0685, -0.0318,  0.0679, -0.0092,  0.0518, -0.0179,  0.0629,  0.0316,\n",
       "                       -0.0291,  0.0574,  0.0237,  0.0203,  0.0166,  0.0714, -0.0060,  0.0228,\n",
       "                       -0.0288, -0.0692, -0.0458,  0.0587, -0.0421, -0.0198,  0.0543, -0.0536,\n",
       "                       -0.0658, -0.0373,  0.0243, -0.0623, -0.0082,  0.0009, -0.0225, -0.0574,\n",
       "                       -0.0098, -0.0256, -0.0569,  0.0247, -0.0286,  0.0408, -0.0673, -0.0321,\n",
       "                        0.0300,  0.0472, -0.0461,  0.0333,  0.0584,  0.0430,  0.0438, -0.0159,\n",
       "                        0.0442, -0.0134,  0.0681,  0.0311,  0.0119,  0.0540,  0.0702, -0.0554,\n",
       "                        0.0188, -0.0399, -0.0687, -0.0401, -0.0356, -0.0124, -0.0572,  0.0298,\n",
       "                        0.0425,  0.0271,  0.0116,  0.0229, -0.0464,  0.0133,  0.0311, -0.0464,\n",
       "                        0.0280, -0.0289, -0.0547, -0.0254, -0.0669, -0.0073,  0.0391,  0.0183,\n",
       "                       -0.0048, -0.0418, -0.0523, -0.0340, -0.0688, -0.0310, -0.0594,  0.0525,\n",
       "                       -0.0517, -0.0262, -0.0153, -0.0004,  0.0015, -0.0364,  0.0010, -0.0060,\n",
       "                        0.0442,  0.0310, -0.0550,  0.0629,  0.0164, -0.0031, -0.0405, -0.0185,\n",
       "                       -0.0039, -0.0611, -0.0551,  0.0428, -0.0079, -0.0224, -0.0023,  0.0431,\n",
       "                        0.0440,  0.0106,  0.0139,  0.0113, -0.0358, -0.0042, -0.0587,  0.0694,\n",
       "                        0.0024, -0.0681,  0.0698,  0.0241, -0.0180,  0.0221, -0.0073,  0.0053,\n",
       "                       -0.0188, -0.0151,  0.0459, -0.0643,  0.0465,  0.0568, -0.0419, -0.0018,\n",
       "                        0.0284,  0.0327, -0.0538,  0.0545, -0.0432,  0.0614, -0.0326, -0.0098,\n",
       "                       -0.0142, -0.0345,  0.0403,  0.0573, -0.0204,  0.0294,  0.0322, -0.0381,\n",
       "                       -0.0657,  0.0502,  0.0688,  0.0664,  0.0172, -0.0553, -0.0596, -0.0436,\n",
       "                       -0.0135,  0.0018, -0.0420,  0.0164,  0.0637,  0.0401,  0.0613, -0.0377,\n",
       "                        0.0362, -0.0293, -0.0446, -0.0337,  0.0149, -0.0272,  0.0243,  0.0437,\n",
       "                        0.0493,  0.0415, -0.0177,  0.0127, -0.0699, -0.0535,  0.0176,  0.0426,\n",
       "                       -0.0041,  0.0329,  0.0540, -0.0588,  0.0149, -0.0151, -0.0615, -0.0313,\n",
       "                        0.0411,  0.0030, -0.0573,  0.0528,  0.0516,  0.0165,  0.0370,  0.0679,\n",
       "                        0.0004,  0.0165,  0.0574,  0.0492, -0.0515, -0.0689,  0.0069, -0.0672,\n",
       "                       -0.0563,  0.0437, -0.0632,  0.0476, -0.0391,  0.0689, -0.0284,  0.0308,\n",
       "                       -0.0146,  0.0086, -0.0393,  0.0577, -0.0149,  0.0537, -0.0358,  0.0347,\n",
       "                        0.0505, -0.0271,  0.0504, -0.0137, -0.0397, -0.0693, -0.0249,  0.0700,\n",
       "                       -0.0038,  0.0385,  0.0576,  0.0529,  0.0500, -0.0561, -0.0086, -0.0283,\n",
       "                        0.0031,  0.0607,  0.0619, -0.0479,  0.0279, -0.0574, -0.0151, -0.0112,\n",
       "                        0.0286,  0.0670,  0.0197,  0.0236,  0.0047, -0.0243,  0.0502, -0.0309,\n",
       "                       -0.0128,  0.0272, -0.0231,  0.0621,  0.0449,  0.0446,  0.0649, -0.0569,\n",
       "                        0.0306,  0.0717, -0.0040,  0.0076, -0.0051,  0.0462, -0.0082, -0.0016,\n",
       "                        0.0480,  0.0111, -0.0192,  0.0208,  0.0123, -0.0024, -0.0606, -0.0131,\n",
       "                        0.0403,  0.0609, -0.0244,  0.0582,  0.0219,  0.0415,  0.0024, -0.0253,\n",
       "                        0.0106, -0.0468, -0.0600,  0.0021,  0.0539, -0.0082,  0.0115,  0.0655,\n",
       "                       -0.0100,  0.0079,  0.0595, -0.0323,  0.0137, -0.0184,  0.0375,  0.0533,\n",
       "                       -0.0101,  0.0696, -0.0525,  0.0218,  0.0035, -0.0023, -0.0306,  0.0264,\n",
       "                        0.0629,  0.0678, -0.0457,  0.0536, -0.0054, -0.0177, -0.0236, -0.0278,\n",
       "                       -0.0401, -0.0647, -0.0394,  0.0661, -0.0498, -0.0429, -0.0275, -0.0081,\n",
       "                        0.0262,  0.0333,  0.0620,  0.0085,  0.0175,  0.0172,  0.0239,  0.0021,\n",
       "                        0.0221,  0.0094,  0.0197,  0.0411,  0.0610, -0.0241, -0.0293,  0.0145,\n",
       "                       -0.0587,  0.0296,  0.0677, -0.0291,  0.0294, -0.0523, -0.0066,  0.0544,\n",
       "                       -0.0136, -0.0087, -0.0335,  0.0101, -0.0652,  0.0213, -0.0330,  0.0416,\n",
       "                        0.0119,  0.0569, -0.0027,  0.0203, -0.0174, -0.0637,  0.0662,  0.0149,\n",
       "                       -0.0707, -0.0289, -0.0372, -0.0643, -0.0624, -0.0553, -0.0619,  0.0372,\n",
       "                       -0.0439, -0.0480, -0.0091, -0.0374, -0.0678,  0.0555, -0.0665,  0.0692,\n",
       "                       -0.0036, -0.0258,  0.0471,  0.0040,  0.0123,  0.0691,  0.0693,  0.0263,\n",
       "                        0.0627, -0.0608, -0.0525, -0.0167, -0.0477, -0.0529, -0.0593, -0.0496,\n",
       "                        0.0109,  0.0090,  0.0215,  0.0580, -0.0332, -0.0276,  0.0631,  0.0106,\n",
       "                       -0.0640,  0.0021, -0.0033,  0.0049, -0.0477,  0.0429,  0.0168,  0.0578,\n",
       "                        0.0630, -0.0485, -0.0257,  0.0334,  0.0698, -0.0600, -0.0515, -0.0579,\n",
       "                       -0.0324, -0.0081, -0.0567, -0.0256,  0.0278,  0.0121,  0.0723,  0.0488,\n",
       "                        0.0419,  0.0656,  0.0231, -0.0629,  0.0655, -0.0696, -0.0427, -0.0087,\n",
       "                       -0.0397,  0.0098, -0.0400,  0.0525,  0.0693, -0.0534, -0.0575, -0.0639,\n",
       "                       -0.0491,  0.0411,  0.0041,  0.0146, -0.0447, -0.0484,  0.0258,  0.0298,\n",
       "                        0.0442, -0.0015,  0.0604, -0.0464, -0.0155,  0.0452, -0.0075,  0.0632,\n",
       "                        0.0565, -0.0552,  0.0422,  0.0122,  0.0356, -0.0281,  0.0674,  0.0469,\n",
       "                       -0.0412, -0.0528,  0.0327, -0.0359,  0.0467, -0.0424, -0.0175,  0.0451,\n",
       "                       -0.0688, -0.0345,  0.0040,  0.0083,  0.0662,  0.0169, -0.0558,  0.0447,\n",
       "                       -0.0142,  0.0086, -0.0434, -0.0703,  0.0345,  0.0436,  0.0487,  0.0054,\n",
       "                        0.0643, -0.0551,  0.0004,  0.0334, -0.0097, -0.0221, -0.0363, -0.0023,\n",
       "                        0.0558, -0.0682,  0.0443, -0.0172, -0.0082,  0.0667, -0.0243,  0.0235,\n",
       "                        0.0070,  0.0132, -0.0531, -0.0540,  0.0677, -0.0548,  0.0322,  0.0031,\n",
       "                        0.0541,  0.0355, -0.0534, -0.0284, -0.0080, -0.0460,  0.0570, -0.0315,\n",
       "                       -0.0680,  0.0371, -0.0604, -0.0730,  0.0413, -0.0415,  0.0694, -0.0454,\n",
       "                        0.0430, -0.0361, -0.0224,  0.0016,  0.0288,  0.0089, -0.0599,  0.0261,\n",
       "                       -0.0694,  0.0019,  0.0701,  0.0506, -0.0085, -0.0249,  0.0334, -0.0007,\n",
       "                        0.0516,  0.0556,  0.0383, -0.0073, -0.0639,  0.0579, -0.0362, -0.0119,\n",
       "                        0.0085,  0.0444,  0.0354, -0.0592,  0.0360, -0.0267,  0.0003, -0.0432,\n",
       "                       -0.0354,  0.0498, -0.0657,  0.0222,  0.0246, -0.0333,  0.0255,  0.0273,\n",
       "                        0.0123, -0.0368,  0.0479,  0.0234,  0.0237, -0.0247,  0.0160,  0.0714,\n",
       "                       -0.0129, -0.0074, -0.0088, -0.0565,  0.0033, -0.0125, -0.0600,  0.0517,\n",
       "                       -0.0345,  0.0177, -0.0603,  0.0250,  0.0479, -0.0441,  0.0024, -0.0407,\n",
       "                       -0.0384,  0.0233,  0.0496, -0.0182, -0.0066,  0.0156,  0.0500, -0.0411])),\n",
       "              ('performer.net.layers.2.1.fn.fn.w2.weight',\n",
       "               tensor([[-0.0269, -0.0065,  0.0043,  ..., -0.0273,  0.0224, -0.0136],\n",
       "                       [ 0.0201,  0.0078,  0.0053,  ...,  0.0222, -0.0287, -0.0214],\n",
       "                       [ 0.0283,  0.0338, -0.0154,  ...,  0.0190,  0.0258,  0.0217],\n",
       "                       ...,\n",
       "                       [ 0.0148,  0.0354, -0.0215,  ...,  0.0035,  0.0132, -0.0327],\n",
       "                       [ 0.0052,  0.0046, -0.0368,  ...,  0.0039,  0.0300, -0.0140],\n",
       "                       [-0.0131, -0.0094, -0.0315,  ..., -0.0181, -0.0167, -0.0137]])),\n",
       "              ('performer.net.layers.2.1.fn.fn.w2.bias',\n",
       "               tensor([ 1.0476e-02, -3.2608e-02, -1.6401e-02,  3.0056e-02, -1.7817e-02,\n",
       "                        2.9561e-02,  1.2868e-03,  2.5081e-02, -4.0057e-03,  2.9074e-02,\n",
       "                        3.2287e-03,  9.2866e-03,  3.2862e-02, -9.4517e-03,  2.2614e-02,\n",
       "                        2.2331e-02, -2.7293e-02,  1.0297e-02,  1.5397e-02,  8.1102e-03,\n",
       "                       -3.2554e-02, -1.4208e-02,  1.9875e-02,  7.7767e-03, -1.8168e-02,\n",
       "                        3.4199e-02,  3.2303e-02,  2.5296e-02,  1.9981e-02, -2.5008e-02,\n",
       "                        1.7387e-02,  3.2011e-02, -3.0591e-02, -2.0620e-02,  1.7190e-05,\n",
       "                       -4.8989e-04, -9.9359e-03, -2.3471e-02, -3.4301e-02, -2.7047e-02,\n",
       "                        1.6624e-02, -1.9198e-03, -1.1355e-02, -3.2818e-02, -2.4110e-02,\n",
       "                        2.1711e-02,  1.7358e-02, -1.7517e-02, -1.0791e-03,  3.5371e-02,\n",
       "                        3.3617e-02, -2.9206e-02,  1.7055e-02,  6.7517e-03,  1.0467e-02,\n",
       "                       -1.4900e-03, -2.3246e-02,  1.0332e-02, -2.6822e-02,  7.6038e-03,\n",
       "                       -3.1137e-03, -1.0088e-02,  3.1818e-02, -2.4199e-02, -4.9454e-03,\n",
       "                       -2.1954e-02,  1.4983e-02,  2.1627e-02,  1.1978e-02,  9.8472e-03,\n",
       "                        2.1554e-02, -1.0756e-02, -2.5256e-02, -1.9217e-02,  2.4228e-02,\n",
       "                        3.4536e-02,  3.1224e-02,  2.7605e-03, -2.4337e-03,  1.7447e-02,\n",
       "                       -1.4440e-02,  3.8417e-03,  2.8456e-02, -5.6387e-04, -1.5267e-02,\n",
       "                       -2.0181e-02, -1.4413e-02,  1.7224e-02,  1.6548e-02,  1.5778e-02,\n",
       "                       -2.4588e-02,  7.0378e-03,  1.7957e-02, -3.0790e-02,  3.4291e-02,\n",
       "                       -2.5876e-02, -2.7307e-02,  2.9499e-02,  2.1997e-03, -4.6310e-03,\n",
       "                       -1.6198e-02,  2.4134e-02,  1.3244e-02,  1.2791e-02, -2.9325e-02,\n",
       "                       -2.1059e-02, -1.6058e-02, -1.6822e-02,  5.4304e-03,  1.6476e-02,\n",
       "                       -2.9745e-02,  8.8427e-03,  3.0774e-02, -1.0220e-02, -1.7271e-02,\n",
       "                       -1.1212e-02, -1.8845e-02,  2.8876e-02, -8.6079e-03,  1.7841e-03,\n",
       "                       -1.2413e-04, -1.6351e-02,  2.9079e-02,  1.5496e-02,  1.9029e-02,\n",
       "                       -2.8569e-02,  7.5678e-03, -1.1855e-02, -2.3980e-03, -1.8560e-02,\n",
       "                       -4.5488e-03, -1.3178e-02,  2.9571e-02, -2.7811e-02, -1.9391e-02,\n",
       "                        1.0556e-02,  1.8538e-02, -5.2047e-03, -2.8057e-02,  1.4060e-02,\n",
       "                       -1.0183e-02,  3.3106e-02,  2.0302e-02,  1.1712e-02,  8.4418e-04,\n",
       "                       -2.2898e-02, -1.2580e-02,  1.7482e-02, -2.5773e-02, -2.4897e-02,\n",
       "                       -1.5052e-03, -2.9911e-02,  1.5186e-02, -5.4333e-04, -5.8383e-03,\n",
       "                       -1.5686e-04, -1.2954e-02, -2.2133e-02, -1.2741e-02, -5.6157e-03,\n",
       "                       -1.2234e-02, -3.3260e-02,  2.7966e-03, -2.5739e-02, -3.1849e-03,\n",
       "                       -6.6226e-03, -2.6271e-02,  1.6503e-02,  1.4818e-02, -2.2159e-02,\n",
       "                        2.2356e-02,  1.1290e-02,  8.3158e-03, -1.1616e-02,  2.7490e-02,\n",
       "                        5.7114e-03, -2.1000e-02, -2.1435e-02,  1.8377e-02, -2.3735e-02,\n",
       "                        2.4230e-02,  4.9880e-03,  1.3084e-02, -1.3794e-02,  1.2938e-02,\n",
       "                        6.1150e-03, -2.7345e-02, -7.9774e-04, -3.1213e-02, -5.8143e-03,\n",
       "                       -1.0094e-02, -4.9459e-04,  1.2990e-02,  3.3271e-02, -1.5585e-02,\n",
       "                        2.7682e-02,  6.8168e-03,  5.1839e-03, -3.1109e-02,  7.5363e-03])),\n",
       "              ('performer.net.layers.3.0.norm.weight',\n",
       "               tensor([1.0005, 0.9992, 1.0003, 0.9971, 0.9929, 0.9977, 0.9996, 0.9977, 0.9978,\n",
       "                       0.9972, 0.9983, 0.9992, 0.9986, 1.0014, 1.0000, 0.9997, 1.0019, 0.9983,\n",
       "                       0.9962, 0.9993, 0.9979, 0.9961, 0.9958, 0.9992, 0.9988, 1.0003, 0.9985,\n",
       "                       1.0000, 1.0004, 0.9954, 0.9975, 1.0003, 1.0015, 0.9977, 0.9990, 0.9990,\n",
       "                       1.0008, 1.0010, 1.0018, 0.9990, 0.9982, 0.9994, 0.9994, 0.9992, 0.9957,\n",
       "                       1.0021, 0.9985, 0.9986, 0.9998, 0.9988, 0.9977, 1.0029, 0.9979, 0.9978,\n",
       "                       0.9993, 1.0012, 1.0000, 0.9981, 0.9975, 0.9985, 1.0015, 1.0009, 1.0010,\n",
       "                       0.9962, 0.9973, 1.0000, 0.9985, 1.0018, 0.9987, 0.9980, 0.9996, 0.9985,\n",
       "                       0.9995, 0.9988, 1.0030, 1.0013, 0.9955, 1.0014, 0.9985, 0.9987, 0.9997,\n",
       "                       0.9978, 0.9968, 0.9976, 0.9974, 1.0004, 0.9956, 1.0009, 1.0004, 0.9977,\n",
       "                       1.0003, 0.9990, 0.9987, 1.0006, 0.9951, 0.9969, 1.0012, 1.0008, 0.9959,\n",
       "                       0.9988, 0.9999, 0.9993, 0.9964, 0.9994, 0.9999, 0.9981, 0.9981, 0.9977,\n",
       "                       0.9976, 0.9984, 0.9995, 1.0025, 1.0001, 0.9967, 0.9998, 1.0008, 0.9999,\n",
       "                       0.9954, 0.9979, 0.9997, 0.9966, 0.9993, 1.0033, 0.9993, 0.9998, 0.9993,\n",
       "                       0.9975, 0.9985, 0.9981, 0.9955, 0.9993, 0.9994, 0.9968, 1.0001, 0.9995,\n",
       "                       0.9988, 1.0013, 1.0003, 0.9999, 0.9980, 0.9992, 0.9966, 1.0008, 0.9975,\n",
       "                       0.9959, 0.9993, 1.0008, 0.9985, 0.9973, 1.0005, 0.9975, 1.0011, 0.9984,\n",
       "                       0.9989, 1.0004, 1.0032, 0.9980, 0.9981, 0.9953, 1.0007, 0.9996, 0.9984,\n",
       "                       1.0002, 1.0000, 0.9995, 0.9982, 0.9982, 1.0003, 1.0006, 0.9958, 0.9974,\n",
       "                       1.0033, 0.9980, 1.0003, 1.0009, 1.0005, 1.0003, 1.0018, 0.9977, 0.9977,\n",
       "                       0.9962, 0.9989, 0.9993, 0.9972, 0.9975, 0.9984, 0.9974, 0.9978, 1.0026,\n",
       "                       1.0008, 0.9986, 0.9998, 0.9974, 0.9981, 0.9979, 0.9986, 1.0010, 0.9986,\n",
       "                       0.9991, 1.0015])),\n",
       "              ('performer.net.layers.3.0.norm.bias',\n",
       "               tensor([-4.4371e-04, -1.0080e-03, -8.9062e-04, -9.1354e-04,  3.6175e-04,\n",
       "                       -9.1156e-04,  1.5491e-03, -1.5861e-04, -1.3754e-03, -2.6180e-04,\n",
       "                        1.0836e-03, -1.4090e-03,  1.4705e-03, -6.2090e-05, -1.5838e-04,\n",
       "                       -6.7299e-05, -1.3606e-03, -8.0412e-04, -2.1367e-03, -8.2501e-04,\n",
       "                       -1.3752e-04,  1.0347e-03,  2.1299e-03,  1.5881e-03,  2.0312e-04,\n",
       "                       -8.0852e-04,  7.8376e-04, -4.7235e-04,  5.9333e-04,  1.2434e-05,\n",
       "                        8.6330e-04,  7.4188e-04,  3.6147e-05,  7.8259e-04, -1.0013e-04,\n",
       "                       -3.2143e-03, -7.5377e-04,  8.3274e-04,  1.4482e-03,  6.0805e-04,\n",
       "                        3.1271e-03,  5.0186e-04,  1.5185e-04, -7.7516e-04, -2.4216e-05,\n",
       "                       -1.9080e-03,  8.7206e-04, -1.0625e-03,  1.7979e-03,  1.6323e-04,\n",
       "                        1.8799e-03,  3.2804e-04, -9.5641e-04, -6.7348e-04,  3.6668e-04,\n",
       "                        2.3960e-03,  3.2009e-04,  1.7714e-03,  2.8463e-03,  8.5816e-04,\n",
       "                       -1.2202e-03,  8.5328e-05,  3.2459e-03, -1.4043e-03, -2.6824e-03,\n",
       "                        8.3592e-04,  1.4880e-03,  9.1203e-04, -3.9875e-04,  3.1914e-04,\n",
       "                        5.1096e-04, -5.8480e-04,  3.5718e-05, -1.6073e-03, -4.5027e-04,\n",
       "                       -1.8051e-03, -1.6459e-04,  1.1805e-04, -3.4602e-03, -1.1052e-03,\n",
       "                        1.2483e-03, -1.7519e-04,  6.4832e-04, -2.4723e-04,  2.5108e-04,\n",
       "                        1.8506e-03,  1.3133e-03,  5.7699e-04,  1.2450e-04, -1.2659e-03,\n",
       "                        5.9384e-04, -1.1834e-03, -5.3194e-04, -1.3305e-03,  1.3214e-03,\n",
       "                        4.5277e-05,  7.3985e-04,  3.1036e-04, -3.2834e-05, -1.3550e-03,\n",
       "                        1.0386e-03,  6.0114e-04,  5.1933e-04,  1.3813e-03, -4.3630e-05,\n",
       "                       -1.4760e-03, -2.8058e-04,  8.6038e-04,  5.1327e-04,  3.5311e-03,\n",
       "                        4.3003e-04, -1.1432e-03, -3.8461e-04, -1.1508e-03, -1.7332e-03,\n",
       "                        5.4466e-04, -7.8074e-05,  6.8681e-05,  6.8074e-04, -2.7855e-03,\n",
       "                        2.5943e-04, -6.2475e-04, -1.6919e-03,  1.6211e-04, -8.2360e-04,\n",
       "                       -2.7094e-04, -2.9283e-04,  1.1531e-03, -1.3380e-05,  6.8914e-05,\n",
       "                        1.1204e-03,  4.0990e-05, -1.3407e-03,  4.8707e-04, -8.4855e-04,\n",
       "                       -2.5455e-03,  1.0306e-03, -5.9020e-05,  6.4325e-04, -1.2074e-03,\n",
       "                       -4.6634e-04,  8.8768e-04,  6.2450e-04, -2.4024e-03,  4.1777e-04,\n",
       "                        1.4482e-03, -4.9822e-04,  1.9357e-03,  1.6352e-04,  1.3230e-03,\n",
       "                       -2.3449e-03,  2.3301e-03,  2.1445e-03, -4.0002e-04, -1.3305e-03,\n",
       "                        1.4596e-03,  2.0782e-03,  7.1626e-05,  3.7489e-03, -7.7254e-04,\n",
       "                        1.1317e-03,  1.9550e-04,  1.9225e-04,  3.1412e-04,  1.8023e-03,\n",
       "                        3.5675e-03,  2.1454e-04, -1.4926e-03, -9.9882e-04, -5.2410e-04,\n",
       "                       -6.3603e-04,  7.7666e-04,  2.5326e-03, -5.4638e-04, -1.0798e-03,\n",
       "                       -6.1463e-04, -2.6287e-03, -1.3615e-03, -2.0196e-03, -9.5537e-04,\n",
       "                       -1.8366e-04,  1.1354e-03, -1.6171e-03,  3.9622e-04,  5.2966e-05,\n",
       "                       -1.5796e-03,  5.4046e-04, -2.0168e-03,  5.3620e-04, -1.4695e-03,\n",
       "                       -2.8217e-03, -1.1597e-03, -6.8783e-04,  7.8571e-04, -2.8649e-03,\n",
       "                        5.2190e-04, -1.9695e-04, -1.1676e-04, -5.3124e-04,  8.7906e-04])),\n",
       "              ('performer.net.layers.3.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-0.6880,  0.6196, -0.3928,  ..., -0.7544,  0.8398,  0.3430],\n",
       "                       [ 0.0564, -0.9639, -0.0389,  ...,  0.4082,  1.4062,  0.5249],\n",
       "                       [ 0.4373,  0.8271, -1.4814,  ...,  1.3574,  1.1377,  0.2435],\n",
       "                       ...,\n",
       "                       [ 0.2590,  0.3149,  0.0622,  ...,  0.0446,  0.1350, -1.7568],\n",
       "                       [ 0.1150,  0.8994,  0.5430,  ..., -0.6211, -0.6318,  2.0234],\n",
       "                       [-0.6973, -0.0619,  2.0781,  ...,  0.7017, -0.4470,  0.2502]])),\n",
       "              ('performer.net.layers.3.0.fn.to_q.weight',\n",
       "               tensor([[ 0.0323, -0.0531,  0.0289,  ..., -0.0240, -0.0573, -0.0233],\n",
       "                       [ 0.0338, -0.0583, -0.0389,  ...,  0.0202, -0.0620,  0.0598],\n",
       "                       [ 0.0071,  0.0022, -0.0605,  ...,  0.0105,  0.0659, -0.0145],\n",
       "                       ...,\n",
       "                       [-0.0574,  0.0413,  0.0163,  ...,  0.0374,  0.0105,  0.0693],\n",
       "                       [-0.0592,  0.0589, -0.0398,  ...,  0.0683, -0.0530, -0.0275],\n",
       "                       [-0.0135,  0.0231, -0.0235,  ..., -0.0405, -0.0327,  0.0203]])),\n",
       "              ('performer.net.layers.3.0.fn.to_k.weight',\n",
       "               tensor([[-0.0157,  0.0513,  0.0093,  ...,  0.0387, -0.0589,  0.0462],\n",
       "                       [ 0.0568,  0.0413,  0.0262,  ...,  0.0585, -0.0315,  0.0353],\n",
       "                       [-0.0238,  0.0683,  0.0484,  ...,  0.0263, -0.0018, -0.0136],\n",
       "                       ...,\n",
       "                       [-0.0273,  0.0547, -0.0107,  ..., -0.0387, -0.0348,  0.0480],\n",
       "                       [ 0.0475,  0.0328,  0.0042,  ...,  0.0649,  0.0154,  0.0531],\n",
       "                       [-0.0270,  0.0303, -0.0252,  ...,  0.0500, -0.0041,  0.0320]])),\n",
       "              ('performer.net.layers.3.0.fn.to_v.weight',\n",
       "               tensor([[-0.0367, -0.0027, -0.0152,  ..., -0.0447, -0.0534, -0.0561],\n",
       "                       [-0.0508, -0.0127, -0.0611,  ...,  0.0372, -0.0171,  0.0065],\n",
       "                       [-0.0659, -0.0392,  0.0359,  ...,  0.0455, -0.0092,  0.0659],\n",
       "                       ...,\n",
       "                       [ 0.0167,  0.0058, -0.0529,  ...,  0.0676,  0.0412,  0.0361],\n",
       "                       [-0.0382,  0.0512, -0.0436,  ..., -0.0006,  0.0038, -0.0017],\n",
       "                       [-0.0478,  0.0651, -0.0629,  ...,  0.0168,  0.0308, -0.0589]])),\n",
       "              ('performer.net.layers.3.0.fn.to_out.weight',\n",
       "               tensor([[-0.0359, -0.0307, -0.0058,  ..., -0.0214,  0.0132,  0.0382],\n",
       "                       [-0.0278,  0.0236, -0.0148,  ...,  0.0334, -0.0339, -0.0257],\n",
       "                       [ 0.0384, -0.0247, -0.0032,  ...,  0.0110,  0.0201, -0.0072],\n",
       "                       ...,\n",
       "                       [ 0.0100, -0.0032,  0.0214,  ..., -0.0371,  0.0034, -0.0332],\n",
       "                       [ 0.0052, -0.0186,  0.0166,  ..., -0.0366, -0.0029,  0.0338],\n",
       "                       [ 0.0318, -0.0146,  0.0383,  ..., -0.0105,  0.0321,  0.0047]])),\n",
       "              ('performer.net.layers.3.0.fn.to_out.bias',\n",
       "               tensor([-0.0122,  0.0373, -0.0121,  0.0094,  0.0223, -0.0008, -0.0256, -0.0355,\n",
       "                       -0.0030,  0.0035, -0.0297,  0.0263, -0.0112,  0.0326,  0.0322, -0.0375,\n",
       "                        0.0048,  0.0224,  0.0355, -0.0196, -0.0348, -0.0203,  0.0044, -0.0361,\n",
       "                        0.0242, -0.0212,  0.0091,  0.0252,  0.0109, -0.0185, -0.0138, -0.0279,\n",
       "                       -0.0326, -0.0239, -0.0385,  0.0129,  0.0350,  0.0025,  0.0351,  0.0207,\n",
       "                        0.0003, -0.0251, -0.0099,  0.0166, -0.0038,  0.0232, -0.0209, -0.0021,\n",
       "                        0.0191, -0.0043,  0.0291, -0.0007, -0.0231,  0.0294, -0.0396, -0.0362,\n",
       "                       -0.0079, -0.0046,  0.0313, -0.0033,  0.0287, -0.0155, -0.0386, -0.0227,\n",
       "                       -0.0307,  0.0369, -0.0159, -0.0066,  0.0354,  0.0281, -0.0210, -0.0181,\n",
       "                       -0.0166, -0.0258, -0.0214,  0.0079,  0.0264, -0.0366,  0.0070, -0.0267,\n",
       "                       -0.0197,  0.0023, -0.0191, -0.0127,  0.0326, -0.0074, -0.0120,  0.0087,\n",
       "                        0.0192,  0.0118, -0.0165,  0.0026,  0.0274,  0.0305,  0.0311, -0.0093,\n",
       "                       -0.0094, -0.0333,  0.0199,  0.0008, -0.0023,  0.0009, -0.0268,  0.0195,\n",
       "                       -0.0175, -0.0205, -0.0298,  0.0262,  0.0368,  0.0120, -0.0292, -0.0181,\n",
       "                       -0.0235, -0.0059,  0.0233, -0.0257,  0.0010,  0.0106,  0.0143, -0.0307,\n",
       "                        0.0289,  0.0214, -0.0034, -0.0226,  0.0017,  0.0103,  0.0341, -0.0199,\n",
       "                       -0.0329,  0.0208, -0.0064,  0.0192,  0.0229, -0.0070,  0.0036,  0.0059,\n",
       "                        0.0137,  0.0349,  0.0013, -0.0241, -0.0330, -0.0223, -0.0293,  0.0209,\n",
       "                        0.0271, -0.0189,  0.0349, -0.0080, -0.0099, -0.0265, -0.0226,  0.0223,\n",
       "                        0.0382, -0.0345, -0.0059,  0.0036,  0.0284, -0.0330,  0.0364,  0.0001,\n",
       "                        0.0234,  0.0014,  0.0165,  0.0050, -0.0208, -0.0370,  0.0030,  0.0287,\n",
       "                       -0.0100,  0.0121,  0.0155,  0.0115,  0.0093, -0.0252,  0.0004, -0.0161,\n",
       "                        0.0171,  0.0158, -0.0022,  0.0193, -0.0322,  0.0014, -0.0084,  0.0254,\n",
       "                       -0.0258, -0.0161, -0.0215, -0.0124,  0.0075,  0.0028,  0.0193, -0.0175,\n",
       "                        0.0115,  0.0239,  0.0260,  0.0251,  0.0202, -0.0128, -0.0155, -0.0067])),\n",
       "              ('performer.net.layers.3.1.norm.weight',\n",
       "               tensor([1.0057, 1.0038, 1.0005, 1.0021, 1.0046, 0.9998, 1.0024, 0.9996, 1.0104,\n",
       "                       1.0031, 1.0027, 1.0112, 1.0022, 1.0000, 1.0052, 1.0024, 0.9999, 1.0028,\n",
       "                       1.0105, 1.0095, 1.0156, 1.0024, 1.0047, 1.0016, 1.0039, 1.0049, 1.0013,\n",
       "                       1.0009, 1.0032, 1.0000, 1.0020, 1.0013, 1.0011, 1.0024, 1.0063, 1.0019,\n",
       "                       1.0002, 1.0044, 0.9993, 1.0009, 1.0003, 1.0051, 1.0004, 0.9989, 1.0012,\n",
       "                       1.0014, 1.0004, 1.0053, 1.0037, 1.0032, 1.0015, 1.0010, 0.9999, 0.9994,\n",
       "                       0.9999, 0.9998, 1.0047, 0.9987, 1.0047, 1.0015, 1.0022, 1.0020, 1.0079,\n",
       "                       1.0047, 1.0027, 1.0014, 1.0087, 1.0007, 1.0013, 0.9982, 1.0026, 1.0052,\n",
       "                       0.9977, 1.0018, 1.0044, 1.0069, 1.0030, 1.0055, 1.0020, 1.0015, 1.0025,\n",
       "                       1.0037, 1.0000, 1.0185, 0.9994, 1.0011, 1.0067, 0.9988, 1.0016, 1.0062,\n",
       "                       1.0022, 1.0000, 1.0011, 1.0017, 0.9995, 0.9995, 1.0013, 1.0040, 1.0049,\n",
       "                       1.0028, 1.0008, 1.0026, 1.0019, 1.0033, 0.9996, 1.0004, 1.0131, 1.0061,\n",
       "                       1.0039, 0.9988, 1.0034, 1.0051, 1.0020, 1.0058, 1.0025, 1.0042, 0.9986,\n",
       "                       0.9995, 1.0007, 1.0022, 1.0034, 1.0020, 0.9987, 1.0053, 1.0041, 1.0059,\n",
       "                       1.0009, 1.0007, 1.0021, 1.0017, 0.9990, 1.0005, 0.9987, 1.0009, 1.0002,\n",
       "                       0.9994, 1.0047, 1.0032, 1.0057, 1.0072, 1.0020, 1.0061, 1.0016, 0.9985,\n",
       "                       1.0030, 1.0018, 1.0004, 1.0033, 1.0021, 1.0067, 1.0057, 1.0010, 1.0043,\n",
       "                       1.0014, 1.0013, 1.0027, 1.0036, 1.0058, 1.0041, 1.0027, 1.0032, 1.0006,\n",
       "                       1.0026, 1.0155, 1.0027, 0.9999, 1.0039, 1.0088, 1.0109, 1.0037, 1.0025,\n",
       "                       1.0032, 1.0013, 1.0051, 1.0006, 1.0041, 1.0013, 0.9999, 1.0038, 1.0024,\n",
       "                       1.0036, 1.0032, 1.0029, 1.0008, 1.0042, 1.0011, 1.0045, 1.0018, 1.0008,\n",
       "                       1.0016, 1.0135, 1.0022, 1.0035, 1.0032, 1.0014, 1.0067, 1.0016, 1.0113,\n",
       "                       1.0024, 0.9997])),\n",
       "              ('performer.net.layers.3.1.norm.bias',\n",
       "               tensor([-9.6792e-04,  1.5580e-03,  1.0792e-03, -1.2605e-03,  4.1487e-04,\n",
       "                        1.2279e-03,  1.4404e-03,  8.3973e-04, -4.9847e-05,  1.0165e-03,\n",
       "                        9.8378e-05,  5.8800e-04, -2.1529e-04, -1.3677e-03, -1.1259e-03,\n",
       "                       -7.6638e-05,  6.2313e-04, -1.8095e-04, -4.1009e-04,  1.5658e-04,\n",
       "                       -4.5606e-04, -2.6960e-04, -6.5001e-04, -7.0907e-05, -8.6651e-04,\n",
       "                       -1.1367e-04,  1.0337e-03, -1.3236e-04,  6.9100e-04, -1.5805e-04,\n",
       "                        1.8875e-03, -7.1046e-04,  2.2350e-04, -1.0344e-03,  8.8490e-04,\n",
       "                        1.7410e-03,  5.8211e-04,  1.3183e-04, -3.5025e-03, -1.6163e-03,\n",
       "                       -5.3066e-04,  9.3312e-04, -8.3005e-06, -3.6796e-05, -1.1435e-04,\n",
       "                        4.9028e-04, -1.3426e-03, -7.0826e-04, -8.1295e-04,  2.2955e-05,\n",
       "                       -1.8928e-03, -8.4183e-04, -2.7531e-04,  3.2251e-04, -9.0916e-04,\n",
       "                       -1.2506e-03,  1.4032e-03, -4.6157e-04,  3.7057e-04, -2.2260e-04,\n",
       "                        8.0755e-04,  1.4277e-03, -6.4957e-04,  1.4879e-03, -4.3259e-04,\n",
       "                       -2.7650e-04,  1.0040e-04, -4.3642e-06, -1.5211e-04,  2.0956e-03,\n",
       "                       -1.4686e-03,  1.7695e-03, -1.1354e-04,  5.7608e-04, -4.7951e-04,\n",
       "                        1.7464e-04,  2.3030e-03, -6.5901e-04,  8.8005e-04, -2.7736e-04,\n",
       "                        7.6272e-04,  1.8005e-03,  1.9309e-04,  1.3531e-03, -7.8209e-04,\n",
       "                        1.3843e-04, -1.8933e-04,  7.6307e-04, -1.4631e-04, -1.0233e-03,\n",
       "                       -8.7525e-04,  4.4877e-04, -3.2589e-04,  6.6020e-04, -4.4864e-04,\n",
       "                        1.3591e-04, -1.3460e-03, -1.0306e-03,  2.0684e-03, -1.8995e-04,\n",
       "                       -5.5313e-04, -1.6054e-03,  3.4200e-04,  3.8328e-04,  1.9731e-04,\n",
       "                       -1.5268e-03, -1.3002e-03, -5.2917e-04, -3.3201e-04, -1.4220e-03,\n",
       "                       -1.3415e-03,  4.1603e-04, -1.9643e-04,  3.5406e-04, -3.4809e-04,\n",
       "                        1.1945e-04, -1.3048e-03,  2.1749e-03,  7.1227e-04, -4.4978e-04,\n",
       "                       -3.7722e-05, -8.8576e-04,  1.4098e-03, -2.3674e-03,  1.7889e-04,\n",
       "                        4.9739e-04,  5.8959e-04, -5.1913e-04,  6.0830e-04, -1.1037e-03,\n",
       "                        4.4616e-04, -9.9987e-04,  2.1251e-03,  1.5635e-03, -5.4052e-04,\n",
       "                        1.6241e-03,  1.1782e-04, -6.0665e-04, -2.0502e-03, -2.3826e-04,\n",
       "                        1.2624e-04, -2.0771e-03, -1.5585e-03,  1.5190e-04, -5.7187e-04,\n",
       "                        1.1100e-03, -6.3210e-04,  7.1760e-04,  2.1872e-03, -6.1727e-04,\n",
       "                        4.7104e-04, -2.2764e-04,  4.3543e-04,  2.6513e-04,  5.5917e-04,\n",
       "                       -1.1396e-04,  1.3068e-03,  1.6902e-04,  1.7857e-04,  3.3211e-04,\n",
       "                       -9.6808e-04, -4.7276e-04, -8.6898e-04,  1.0616e-03, -8.6671e-04,\n",
       "                        3.5767e-04,  1.2792e-03, -4.9896e-05,  3.2529e-04, -1.4629e-03,\n",
       "                        6.7483e-04,  2.1234e-03,  1.1549e-03, -7.6861e-04,  3.3128e-03,\n",
       "                        5.3169e-04,  6.2604e-04,  1.2599e-03,  4.7009e-04, -2.8281e-04,\n",
       "                        1.2303e-03,  1.0484e-04,  1.2927e-03,  1.0824e-04,  3.9765e-04,\n",
       "                        9.7814e-05,  2.7355e-04, -3.5471e-04, -6.5134e-04,  3.2889e-04,\n",
       "                       -7.2120e-04,  9.7420e-04, -1.0566e-03,  1.8463e-04, -1.0509e-03,\n",
       "                       -6.7175e-04,  6.8030e-05, -6.3101e-04, -2.3232e-03, -4.6731e-04])),\n",
       "              ('performer.net.layers.3.1.fn.fn.w1.weight',\n",
       "               tensor([[ 0.0341, -0.0573, -0.0454,  ..., -0.0387, -0.0523,  0.0163],\n",
       "                       [ 0.0532, -0.0074,  0.0268,  ...,  0.0583, -0.0724,  0.0365],\n",
       "                       [-0.0050,  0.0665,  0.0712,  ...,  0.0104, -0.0312,  0.0254],\n",
       "                       ...,\n",
       "                       [ 0.0151,  0.0442, -0.0393,  ...,  0.0128,  0.0143, -0.0429],\n",
       "                       [-0.0224,  0.0421,  0.0238,  ..., -0.0587, -0.0105, -0.0440],\n",
       "                       [-0.0122, -0.0516, -0.0591,  ..., -0.0276, -0.0467, -0.0261]])),\n",
       "              ('performer.net.layers.3.1.fn.fn.w1.bias',\n",
       "               tensor([ 0.0268, -0.0265, -0.0090, -0.0657,  0.0416, -0.0150,  0.0249, -0.0254,\n",
       "                        0.0298,  0.0052, -0.0544,  0.0109, -0.0482,  0.0044, -0.0621, -0.0642,\n",
       "                        0.0504,  0.0092,  0.0224, -0.0138, -0.0422, -0.0533,  0.0624, -0.0593,\n",
       "                       -0.0299,  0.0222,  0.0709,  0.0502,  0.0299,  0.0160, -0.0643,  0.0465,\n",
       "                        0.0271,  0.0371, -0.0428,  0.0555,  0.0272, -0.0337,  0.0031, -0.0299,\n",
       "                        0.0667, -0.0406,  0.0630,  0.0049, -0.0319,  0.0162,  0.0223,  0.0503,\n",
       "                       -0.0398,  0.0163, -0.0574, -0.0160,  0.0696, -0.0043,  0.0582,  0.0168,\n",
       "                        0.0057, -0.0449, -0.0500,  0.0264, -0.0671,  0.0364,  0.0447, -0.0377,\n",
       "                       -0.0259, -0.0146, -0.0576,  0.0530, -0.0068,  0.0501,  0.0683, -0.0181,\n",
       "                        0.0308,  0.0113,  0.0396,  0.0024,  0.0459,  0.0376, -0.0485,  0.0158,\n",
       "                        0.0185, -0.0102, -0.0419,  0.0175, -0.0165, -0.0598,  0.0217,  0.0097,\n",
       "                       -0.0515,  0.0066,  0.0140, -0.0569,  0.0027,  0.0146, -0.0521,  0.0406,\n",
       "                        0.0473,  0.0507,  0.0248, -0.0381, -0.0211, -0.0432,  0.0281, -0.0493,\n",
       "                        0.0538,  0.0174, -0.0264,  0.0533,  0.0429, -0.0504,  0.0630, -0.0296,\n",
       "                        0.0633, -0.0359, -0.0472,  0.0581, -0.0673, -0.0082,  0.0254, -0.0225,\n",
       "                        0.0661,  0.0679,  0.0573,  0.0016, -0.0176, -0.0665, -0.0314,  0.0680,\n",
       "                        0.0675, -0.0230, -0.0445,  0.0235, -0.0477, -0.0552, -0.0545,  0.0501,\n",
       "                       -0.0583, -0.0215,  0.0428, -0.0284, -0.0480, -0.0293,  0.0182,  0.0256,\n",
       "                       -0.0040,  0.0132,  0.0136,  0.0477,  0.0364,  0.0405, -0.0044, -0.0274,\n",
       "                        0.0246,  0.0618,  0.0391,  0.0222, -0.0179, -0.0246,  0.0364, -0.0410,\n",
       "                        0.0512, -0.0117, -0.0145, -0.0119,  0.0280, -0.0126,  0.0400, -0.0657,\n",
       "                        0.0499, -0.0602, -0.0438,  0.0598, -0.0307, -0.0682,  0.0108, -0.0374,\n",
       "                        0.0612, -0.0399, -0.0581,  0.0360, -0.0166,  0.0433, -0.0478,  0.0578,\n",
       "                        0.0340, -0.0372, -0.0158,  0.0122,  0.0251, -0.0019, -0.0343,  0.0255,\n",
       "                        0.0075,  0.0029, -0.0193, -0.0487,  0.0433,  0.0191, -0.0555, -0.0658,\n",
       "                        0.0479, -0.0259,  0.0095, -0.0241,  0.0118,  0.0306, -0.0701,  0.0147,\n",
       "                        0.0679, -0.0260,  0.0388, -0.0331, -0.0690,  0.0183, -0.0354, -0.0385,\n",
       "                       -0.0443, -0.0180, -0.0517, -0.0096,  0.0124,  0.0120, -0.0016,  0.0686,\n",
       "                       -0.0027,  0.0378,  0.0145,  0.0224,  0.0047,  0.0301,  0.0662, -0.0525,\n",
       "                       -0.0039, -0.0519, -0.0479, -0.0399,  0.0417,  0.0595,  0.0417, -0.0370,\n",
       "                       -0.0213,  0.0206,  0.0056, -0.0371,  0.0559, -0.0512,  0.0250,  0.0250,\n",
       "                       -0.0102, -0.0079,  0.0676,  0.0665,  0.0677,  0.0090,  0.0432, -0.0039,\n",
       "                        0.0215, -0.0146,  0.0396, -0.0704,  0.0312,  0.0349, -0.0278, -0.0349,\n",
       "                       -0.0028, -0.0215, -0.0477, -0.0555, -0.0526, -0.0077,  0.0394, -0.0150,\n",
       "                        0.0413,  0.0138, -0.0079,  0.0610, -0.0538, -0.0315, -0.0605,  0.0200,\n",
       "                       -0.0214,  0.0608,  0.0641, -0.0135, -0.0372, -0.0538,  0.0402,  0.0554,\n",
       "                        0.0671, -0.0125,  0.0324,  0.0128, -0.0160, -0.0250,  0.0355,  0.0693,\n",
       "                       -0.0443, -0.0603,  0.0554,  0.0070, -0.0143, -0.0086, -0.0003,  0.0428,\n",
       "                       -0.0467,  0.0492, -0.0160,  0.0322, -0.0096,  0.0281,  0.0089,  0.0367,\n",
       "                       -0.0194,  0.0261,  0.0396,  0.0442,  0.0090,  0.0358,  0.0333,  0.0319,\n",
       "                       -0.0079,  0.0086,  0.0613, -0.0279, -0.0553, -0.0468, -0.0076,  0.0656,\n",
       "                        0.0407, -0.0315, -0.0654, -0.0194, -0.0533, -0.0118, -0.0308,  0.0559,\n",
       "                       -0.0329,  0.0202,  0.0106, -0.0444,  0.0593, -0.0480,  0.0172, -0.0438,\n",
       "                       -0.0614,  0.0488, -0.0646, -0.0063, -0.0577,  0.0127, -0.0257, -0.0653,\n",
       "                       -0.0137, -0.0644, -0.0299, -0.0544, -0.0465, -0.0456, -0.0433, -0.0422,\n",
       "                        0.0008,  0.0434,  0.0531, -0.0565,  0.0575,  0.0273,  0.0697,  0.0646,\n",
       "                       -0.0656,  0.0589,  0.0300, -0.0493,  0.0212, -0.0342, -0.0498,  0.0066,\n",
       "                       -0.0308,  0.0290,  0.0292, -0.0209, -0.0021,  0.0013,  0.0125, -0.0351,\n",
       "                        0.0210,  0.0214,  0.0179, -0.0512,  0.0192, -0.0342, -0.0611,  0.0395,\n",
       "                        0.0514,  0.0507, -0.0029, -0.0367, -0.0365, -0.0666,  0.0260, -0.0343,\n",
       "                        0.0416,  0.0380, -0.0597, -0.0265, -0.0050, -0.0443,  0.0486, -0.0664,\n",
       "                       -0.0413,  0.0294,  0.0212,  0.0312, -0.0136, -0.0026,  0.0256, -0.0396,\n",
       "                        0.0116, -0.0687,  0.0062, -0.0584, -0.0016,  0.0163,  0.0699, -0.0083,\n",
       "                       -0.0274,  0.0214,  0.0528, -0.0096, -0.0539,  0.0135, -0.0368,  0.0468,\n",
       "                        0.0260, -0.0426,  0.0234, -0.0202,  0.0021,  0.0194, -0.0690, -0.0368,\n",
       "                        0.0216, -0.0040,  0.0108,  0.0587, -0.0679, -0.0345, -0.0632,  0.0667,\n",
       "                        0.0006,  0.0132,  0.0345, -0.0544, -0.0471, -0.0568,  0.0144, -0.0412,\n",
       "                        0.0510,  0.0298,  0.0632, -0.0131,  0.0423,  0.0523,  0.0490,  0.0619,\n",
       "                        0.0368, -0.0223, -0.0200, -0.0578,  0.0504, -0.0462, -0.0469, -0.0622,\n",
       "                        0.0617,  0.0519, -0.0364,  0.0580,  0.0545, -0.0494,  0.0639,  0.0395,\n",
       "                        0.0073,  0.0624, -0.0424,  0.0130,  0.0239, -0.0338, -0.0672,  0.0103,\n",
       "                       -0.0623,  0.0286, -0.0364,  0.0535, -0.0469,  0.0059,  0.0122,  0.0356,\n",
       "                       -0.0173,  0.0279, -0.0221,  0.0272, -0.0644,  0.0285, -0.0216,  0.0339,\n",
       "                       -0.0617, -0.0281, -0.0364, -0.0574,  0.0040,  0.0320, -0.0097,  0.0167,\n",
       "                       -0.0064,  0.0505, -0.0425,  0.0543, -0.0609, -0.0580, -0.0324,  0.0087,\n",
       "                        0.0244, -0.0245, -0.0043, -0.0395, -0.0567, -0.0365, -0.0146,  0.0461,\n",
       "                       -0.0128,  0.0328, -0.0681, -0.0274, -0.0084,  0.0173, -0.0180,  0.0161,\n",
       "                        0.0212, -0.0518,  0.0426,  0.0028,  0.0665,  0.0647, -0.0619,  0.0284,\n",
       "                        0.0656, -0.0686, -0.0494,  0.0276,  0.0343, -0.0352,  0.0442, -0.0362,\n",
       "                       -0.0696, -0.0686, -0.0464,  0.0410, -0.0483,  0.0495, -0.0242,  0.0100,\n",
       "                        0.0105, -0.0065,  0.0486,  0.0296,  0.0251,  0.0493, -0.0460,  0.0657,\n",
       "                        0.0008,  0.0136, -0.0620,  0.0037, -0.0683, -0.0519, -0.0471,  0.0395,\n",
       "                       -0.0163,  0.0466,  0.0311, -0.0245, -0.0197,  0.0555, -0.0266,  0.0317,\n",
       "                       -0.0074,  0.0086,  0.0454, -0.0634,  0.0118,  0.0319,  0.0391,  0.0379,\n",
       "                       -0.0388,  0.0106, -0.0222,  0.0304,  0.0091, -0.0502,  0.0613, -0.0250,\n",
       "                        0.0511,  0.0223, -0.0347,  0.0504, -0.0011, -0.0242,  0.0108,  0.0257,\n",
       "                        0.0498,  0.0527, -0.0631, -0.0577, -0.0630,  0.0667,  0.0085,  0.0004,\n",
       "                        0.0308, -0.0108, -0.0551,  0.0185,  0.0657,  0.0339, -0.0234, -0.0451,\n",
       "                        0.0534, -0.0489,  0.0663,  0.0568,  0.0273,  0.0441,  0.0467,  0.0268,\n",
       "                       -0.0533,  0.0494, -0.0422, -0.0204, -0.0259, -0.0509,  0.0329, -0.0176,\n",
       "                        0.0306,  0.0429,  0.0047, -0.0555,  0.0664, -0.0059,  0.0385,  0.0520,\n",
       "                        0.0694,  0.0355, -0.0331, -0.0166, -0.0479, -0.0064,  0.0421,  0.0174,\n",
       "                        0.0598,  0.0172, -0.0665,  0.0175,  0.0536,  0.0024,  0.0611,  0.0492,\n",
       "                       -0.0462, -0.0379,  0.0400, -0.0658,  0.0721,  0.0610, -0.0536,  0.0129,\n",
       "                       -0.0440,  0.0621, -0.0153, -0.0084,  0.0236, -0.0621,  0.0108, -0.0407,\n",
       "                        0.0161,  0.0632,  0.0122,  0.0523,  0.0017,  0.0274, -0.0325,  0.0352,\n",
       "                       -0.0075, -0.0413, -0.0077,  0.0474,  0.0113,  0.0433,  0.0647,  0.0354,\n",
       "                       -0.0238, -0.0494,  0.0342, -0.0699, -0.0296, -0.0403,  0.0106, -0.0150,\n",
       "                       -0.0541, -0.0026,  0.0237, -0.0347,  0.0635,  0.0184, -0.0619, -0.0523,\n",
       "                       -0.0455, -0.0140,  0.0042, -0.0146, -0.0321, -0.0532,  0.0646,  0.0369,\n",
       "                       -0.0545, -0.0625,  0.0088,  0.0594, -0.0444, -0.0440,  0.0015, -0.0303,\n",
       "                       -0.0303, -0.0386, -0.0593, -0.0147,  0.0583, -0.0637, -0.0092,  0.0619,\n",
       "                       -0.0207,  0.0553, -0.0444, -0.0382,  0.0671,  0.0559, -0.0534, -0.0668,\n",
       "                        0.0526, -0.0179, -0.0349,  0.0203, -0.0331,  0.0005, -0.0675, -0.0583,\n",
       "                        0.0312, -0.0049,  0.0224,  0.0053, -0.0460, -0.0399,  0.0225, -0.0115,\n",
       "                       -0.0286, -0.0636,  0.0669, -0.0093,  0.0483,  0.0267, -0.0022, -0.0354,\n",
       "                       -0.0615,  0.0642, -0.0674,  0.0289,  0.0298, -0.0616,  0.0410, -0.0158,\n",
       "                        0.0235, -0.0627, -0.0197, -0.0263,  0.0127,  0.0632,  0.0574, -0.0254,\n",
       "                        0.0018, -0.0115,  0.0604,  0.0350, -0.0415,  0.0279,  0.0307,  0.0561,\n",
       "                       -0.0741, -0.0233,  0.0524,  0.0432,  0.0561,  0.0302,  0.0357,  0.0407])),\n",
       "              ('performer.net.layers.3.1.fn.fn.w2.weight',\n",
       "               tensor([[ 0.0218,  0.0190, -0.0005,  ..., -0.0085,  0.0281, -0.0145],\n",
       "                       [-0.0083,  0.0006,  0.0017,  ..., -0.0051, -0.0085, -0.0298],\n",
       "                       [-0.0359,  0.0103,  0.0155,  ..., -0.0005,  0.0284, -0.0268],\n",
       "                       ...,\n",
       "                       [-0.0047, -0.0172, -0.0246,  ..., -0.0183,  0.0289, -0.0246],\n",
       "                       [-0.0224,  0.0334,  0.0030,  ...,  0.0276, -0.0128,  0.0359],\n",
       "                       [-0.0084,  0.0127, -0.0099,  ..., -0.0150, -0.0208,  0.0257]])),\n",
       "              ('performer.net.layers.3.1.fn.fn.w2.bias',\n",
       "               tensor([ 0.0121,  0.0043,  0.0177, -0.0276,  0.0106, -0.0272, -0.0039,  0.0143,\n",
       "                       -0.0288, -0.0309, -0.0242, -0.0186, -0.0035, -0.0282, -0.0049, -0.0129,\n",
       "                        0.0241, -0.0302,  0.0233, -0.0330, -0.0320, -0.0154, -0.0140, -0.0208,\n",
       "                        0.0060,  0.0314, -0.0109, -0.0234,  0.0280,  0.0055,  0.0177, -0.0032,\n",
       "                       -0.0135,  0.0149,  0.0009,  0.0283,  0.0234, -0.0346, -0.0284, -0.0058,\n",
       "                       -0.0214, -0.0040,  0.0327, -0.0030,  0.0101, -0.0040,  0.0239, -0.0010,\n",
       "                        0.0339,  0.0313, -0.0118,  0.0270, -0.0059,  0.0156, -0.0237, -0.0275,\n",
       "                        0.0179, -0.0228, -0.0296,  0.0066, -0.0293,  0.0121, -0.0294,  0.0305,\n",
       "                       -0.0163,  0.0107, -0.0356,  0.0318, -0.0245, -0.0057, -0.0030, -0.0205,\n",
       "                        0.0356,  0.0194, -0.0123,  0.0256,  0.0038,  0.0255,  0.0190, -0.0090,\n",
       "                        0.0236, -0.0026, -0.0332, -0.0105,  0.0167,  0.0348,  0.0331,  0.0193,\n",
       "                        0.0203, -0.0262, -0.0078, -0.0312, -0.0347,  0.0133, -0.0272, -0.0200,\n",
       "                       -0.0217, -0.0291, -0.0002, -0.0348, -0.0023,  0.0027, -0.0305,  0.0163,\n",
       "                       -0.0164, -0.0104,  0.0089, -0.0327, -0.0354, -0.0040, -0.0201,  0.0304,\n",
       "                        0.0186, -0.0261, -0.0206, -0.0319, -0.0176,  0.0289,  0.0104,  0.0340,\n",
       "                       -0.0075,  0.0361, -0.0225, -0.0048, -0.0012,  0.0321, -0.0142, -0.0219,\n",
       "                       -0.0110, -0.0098, -0.0041,  0.0166, -0.0057,  0.0072, -0.0336, -0.0250,\n",
       "                        0.0287, -0.0032,  0.0007,  0.0139,  0.0158,  0.0227,  0.0353,  0.0198,\n",
       "                        0.0076, -0.0179, -0.0292, -0.0130,  0.0170,  0.0015,  0.0132, -0.0091,\n",
       "                       -0.0101,  0.0023, -0.0348,  0.0091,  0.0296,  0.0244,  0.0286,  0.0210,\n",
       "                       -0.0278,  0.0145, -0.0253, -0.0122,  0.0202,  0.0080,  0.0023, -0.0152,\n",
       "                        0.0346, -0.0294, -0.0066,  0.0145, -0.0142,  0.0128, -0.0275, -0.0326,\n",
       "                        0.0260,  0.0013, -0.0247, -0.0347, -0.0055, -0.0336, -0.0260, -0.0281,\n",
       "                        0.0012,  0.0012, -0.0155,  0.0159,  0.0038, -0.0205,  0.0037,  0.0261,\n",
       "                        0.0215,  0.0189,  0.0271, -0.0302,  0.0354,  0.0011,  0.0047, -0.0200])),\n",
       "              ('performer.net.layers.4.0.norm.weight',\n",
       "               tensor([1.0004, 0.9939, 1.0054, 1.0016, 0.9974, 1.0003, 0.9991, 0.9989, 0.9928,\n",
       "                       1.0022, 0.9965, 0.9987, 0.9970, 0.9938, 0.9993, 0.9981, 1.0004, 0.9990,\n",
       "                       0.9930, 1.0007, 1.0012, 0.9997, 1.0026, 1.0036, 0.9968, 0.9950, 1.0020,\n",
       "                       1.0021, 0.9987, 1.0014, 1.0009, 0.9999, 0.9971, 1.0013, 0.9986, 1.0023,\n",
       "                       0.9948, 0.9983, 1.0022, 1.0049, 0.9989, 0.9946, 1.0002, 1.0016, 0.9952,\n",
       "                       0.9996, 0.9986, 0.9977, 1.0003, 1.0029, 1.0019, 0.9974, 1.0060, 0.9989,\n",
       "                       1.0042, 1.0011, 0.9990, 1.0006, 0.9981, 1.0003, 1.0000, 0.9953, 0.9973,\n",
       "                       0.9973, 0.9970, 0.9959, 1.0030, 0.9990, 1.0012, 0.9939, 1.0008, 1.0018,\n",
       "                       1.0029, 0.9937, 0.9932, 1.0017, 1.0029, 1.0044, 1.0016, 0.9990, 0.9969,\n",
       "                       1.0007, 1.0011, 0.9973, 0.9994, 1.0059, 0.9986, 0.9975, 0.9992, 1.0005,\n",
       "                       0.9993, 1.0059, 1.0022, 1.0009, 1.0007, 0.9971, 1.0048, 0.9987, 1.0038,\n",
       "                       0.9966, 1.0013, 1.0051, 1.0038, 1.0019, 1.0053, 0.9994, 1.0037, 1.0060,\n",
       "                       0.9971, 0.9969, 0.9998, 0.9974, 1.0001, 1.0032, 0.9964, 1.0027, 0.9952,\n",
       "                       1.0003, 1.0021, 0.9987, 1.0008, 1.0029, 0.9999, 0.9982, 1.0009, 0.9973,\n",
       "                       0.9992, 0.9984, 0.9932, 1.0028, 1.0039, 0.9989, 0.9993, 1.0015, 0.9977,\n",
       "                       0.9989, 0.9955, 1.0029, 0.9960, 0.9991, 1.0003, 1.0034, 1.0006, 0.9979,\n",
       "                       0.9977, 0.9970, 1.0055, 0.9998, 0.9985, 0.9979, 1.0038, 1.0010, 1.0011,\n",
       "                       0.9985, 1.0024, 1.0058, 0.9990, 0.9969, 0.9987, 0.9952, 1.0064, 1.0041,\n",
       "                       1.0007, 0.9971, 0.9997, 0.9970, 0.9974, 1.0015, 1.0063, 1.0016, 0.9974,\n",
       "                       0.9986, 1.0018, 1.0034, 0.9996, 0.9989, 1.0016, 1.0015, 0.9977, 0.9985,\n",
       "                       1.0018, 0.9997, 1.0016, 0.9973, 0.9996, 0.9955, 1.0008, 0.9965, 1.0018,\n",
       "                       0.9966, 1.0042, 0.9958, 1.0018, 1.0008, 1.0048, 0.9995, 1.0005, 0.9998,\n",
       "                       0.9970, 1.0030])),\n",
       "              ('performer.net.layers.4.0.norm.bias',\n",
       "               tensor([-1.8856e-03, -6.5181e-03, -8.4103e-04,  2.3089e-03, -2.8950e-03,\n",
       "                       -3.5022e-03, -1.9385e-03,  1.4713e-04, -1.8300e-03,  2.4820e-03,\n",
       "                        1.2676e-03, -9.5562e-04,  2.2873e-03, -5.9824e-04, -5.0934e-04,\n",
       "                       -2.2595e-03,  5.5542e-04,  1.1012e-03, -2.6812e-03,  1.2434e-03,\n",
       "                       -3.5385e-04, -1.3784e-04,  9.6182e-04, -3.3474e-03, -7.6413e-06,\n",
       "                       -7.1729e-04, -1.1513e-03, -3.0334e-03, -2.0811e-03,  4.7130e-03,\n",
       "                        1.3752e-04, -7.0328e-04,  5.4635e-03,  3.7598e-03, -1.1122e-03,\n",
       "                       -1.1396e-03,  4.5291e-03, -1.3136e-03, -5.1967e-05, -5.4540e-04,\n",
       "                        2.7884e-03,  1.6741e-03, -1.1976e-03,  7.9178e-04, -2.0300e-03,\n",
       "                       -4.0232e-03,  4.4527e-05,  3.5311e-03,  8.3466e-04,  2.1389e-03,\n",
       "                        6.4286e-04, -3.0040e-03, -5.1312e-03, -2.1598e-03,  2.0375e-03,\n",
       "                        3.1988e-03,  2.0189e-03, -2.1545e-03,  2.0861e-04,  2.1860e-03,\n",
       "                        4.0022e-04,  1.0720e-03,  1.8539e-03, -2.8136e-04, -2.5580e-03,\n",
       "                       -5.6180e-04,  3.1719e-03, -1.3454e-03,  8.4887e-04,  2.8274e-03,\n",
       "                        1.1354e-03,  1.1671e-03,  1.2221e-03, -1.3170e-03, -2.7518e-05,\n",
       "                        6.5052e-04,  9.4116e-04, -2.4086e-04,  1.0727e-03,  7.6980e-04,\n",
       "                       -2.6625e-03,  4.3469e-04,  2.2094e-03,  1.4475e-03,  4.3844e-04,\n",
       "                        2.6641e-03,  7.1203e-04, -3.7373e-03, -2.9615e-03,  3.4926e-03,\n",
       "                        3.6409e-04,  2.0857e-04,  8.9717e-04, -3.1851e-03,  2.9946e-03,\n",
       "                       -3.5209e-03, -3.1872e-04, -1.4159e-03,  8.6384e-04,  1.7995e-03,\n",
       "                        1.8086e-03,  6.7168e-04, -4.8728e-04, -1.1258e-03,  1.5147e-03,\n",
       "                        1.7404e-03, -1.9919e-03,  2.6103e-03,  1.8785e-03, -1.1553e-03,\n",
       "                       -7.6113e-04,  1.4551e-03,  4.6484e-04,  1.7038e-03, -4.1992e-03,\n",
       "                        6.6307e-04, -1.0388e-03,  2.8990e-03, -3.7688e-03, -9.2104e-04,\n",
       "                       -2.2488e-03,  1.1501e-03, -1.6308e-03,  1.6710e-03, -1.8843e-03,\n",
       "                       -2.1839e-03, -1.8188e-04, -1.6804e-04,  1.0517e-03, -1.3702e-03,\n",
       "                       -2.8594e-03,  2.3650e-04, -4.5386e-03, -2.2761e-03,  1.1217e-03,\n",
       "                        1.1565e-04,  1.3914e-03,  1.7381e-03,  8.9483e-04, -8.3011e-04,\n",
       "                       -3.5747e-04,  2.3654e-03,  5.9072e-04, -2.1184e-03,  5.0188e-03,\n",
       "                        5.6976e-04, -3.3655e-03, -7.9405e-04, -2.9492e-03, -1.6644e-03,\n",
       "                        3.5379e-03,  1.1907e-03,  1.1206e-03, -1.1845e-03, -1.6107e-03,\n",
       "                        4.9761e-03,  8.8119e-04, -1.5906e-03,  7.5529e-04, -3.6376e-03,\n",
       "                       -3.7214e-05, -4.4142e-03,  1.0197e-03,  5.0734e-04,  1.9488e-03,\n",
       "                        1.8721e-03,  6.1879e-04,  1.4771e-03, -2.5017e-03,  1.8749e-03,\n",
       "                       -1.2673e-03, -9.8793e-04, -2.2042e-03,  8.2256e-04, -3.0315e-04,\n",
       "                       -6.4656e-04, -7.3465e-04, -4.4555e-03, -2.4289e-03, -1.9764e-04,\n",
       "                        1.4865e-03, -1.1472e-03, -3.3055e-04,  3.4475e-03,  3.2386e-04,\n",
       "                       -2.9733e-03,  3.5007e-04,  2.8159e-03,  6.2363e-05,  1.9714e-03,\n",
       "                        2.4759e-03, -5.8177e-03, -1.6807e-04, -8.1135e-04,  1.0210e-03,\n",
       "                        9.1394e-04,  2.2660e-03, -1.4686e-03, -1.3466e-03,  5.3780e-04])),\n",
       "              ('performer.net.layers.4.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-0.2419,  0.4761,  0.0195,  ...,  0.7622,  0.4431,  0.7520],\n",
       "                       [-0.5781, -0.4768, -0.2754,  ...,  0.5928,  1.7734,  1.8369],\n",
       "                       [-0.3892, -0.0929, -1.9180,  ..., -0.8594, -0.5088,  1.7070],\n",
       "                       ...,\n",
       "                       [ 1.1172, -0.6743, -0.3835,  ...,  1.2559,  0.0025,  0.6309],\n",
       "                       [-0.0281,  0.1345, -1.2617,  ...,  0.0452, -1.1162, -0.6592],\n",
       "                       [ 0.1683, -1.8018,  0.7192,  ..., -0.2010,  1.0732, -0.2683]])),\n",
       "              ('performer.net.layers.4.0.fn.to_q.weight',\n",
       "               tensor([[-0.0391, -0.0252, -0.0492,  ..., -0.0746,  0.0417, -0.0462],\n",
       "                       [ 0.0197,  0.0360,  0.0399,  ..., -0.0271,  0.0383,  0.0478],\n",
       "                       [-0.0129,  0.0608,  0.0170,  ..., -0.0662, -0.0240,  0.0097],\n",
       "                       ...,\n",
       "                       [-0.0682, -0.0034,  0.0296,  ..., -0.0299,  0.0124, -0.0282],\n",
       "                       [-0.0645, -0.0415, -0.0001,  ...,  0.0573,  0.0685,  0.0335],\n",
       "                       [-0.0413, -0.0168,  0.0359,  ..., -0.0056, -0.0159, -0.0338]])),\n",
       "              ('performer.net.layers.4.0.fn.to_k.weight',\n",
       "               tensor([[ 0.0428,  0.0206,  0.0321,  ...,  0.0679, -0.0561, -0.0322],\n",
       "                       [-0.0671, -0.0489,  0.0321,  ..., -0.0024,  0.0158, -0.0234],\n",
       "                       [ 0.0655,  0.0236, -0.0692,  ...,  0.0116,  0.0108,  0.0058],\n",
       "                       ...,\n",
       "                       [ 0.0113,  0.0276, -0.0464,  ..., -0.0682,  0.0671,  0.0178],\n",
       "                       [ 0.0187,  0.0606, -0.0186,  ...,  0.0011,  0.0271, -0.0364],\n",
       "                       [ 0.0599,  0.0354, -0.0450,  ..., -0.0183, -0.0593, -0.0367]])),\n",
       "              ('performer.net.layers.4.0.fn.to_v.weight',\n",
       "               tensor([[ 0.0495, -0.0404,  0.0409,  ...,  0.0132, -0.0659,  0.0605],\n",
       "                       [-0.0276,  0.0367, -0.0640,  ...,  0.0526, -0.0456,  0.0714],\n",
       "                       [-0.0222,  0.0171, -0.0769,  ...,  0.0088,  0.0285, -0.0591],\n",
       "                       ...,\n",
       "                       [-0.0339, -0.0545,  0.0631,  ...,  0.0382,  0.0107, -0.0141],\n",
       "                       [-0.0218,  0.0451, -0.0608,  ..., -0.0021,  0.0150,  0.0483],\n",
       "                       [-0.0035, -0.0166,  0.0653,  ..., -0.0554,  0.0552,  0.0156]])),\n",
       "              ('performer.net.layers.4.0.fn.to_out.weight',\n",
       "               tensor([[ 0.0235,  0.0223,  0.0324,  ..., -0.0323,  0.0172,  0.0164],\n",
       "                       [-0.0129, -0.0107,  0.0087,  ..., -0.0018, -0.0005,  0.0172],\n",
       "                       [-0.0293,  0.0167,  0.0048,  ..., -0.0209,  0.0013, -0.0376],\n",
       "                       ...,\n",
       "                       [-0.0301, -0.0139,  0.0016,  ..., -0.0158, -0.0074, -0.0135],\n",
       "                       [ 0.0327, -0.0034, -0.0030,  ..., -0.0214, -0.0191, -0.0017],\n",
       "                       [ 0.0389,  0.0111,  0.0253,  ...,  0.0263,  0.0114, -0.0343]])),\n",
       "              ('performer.net.layers.4.0.fn.to_out.bias',\n",
       "               tensor([-0.0208, -0.0305,  0.0022,  0.0167,  0.0178, -0.0264, -0.0338,  0.0307,\n",
       "                       -0.0037, -0.0231, -0.0156, -0.0287, -0.0196,  0.0152,  0.0146,  0.0253,\n",
       "                       -0.0299,  0.0081, -0.0164, -0.0106,  0.0168, -0.0149, -0.0150, -0.0155,\n",
       "                       -0.0416, -0.0042,  0.0233, -0.0199,  0.0138, -0.0282, -0.0155,  0.0260,\n",
       "                        0.0136,  0.0127, -0.0022, -0.0239, -0.0060,  0.0348, -0.0029,  0.0206,\n",
       "                       -0.0136, -0.0339,  0.0288, -0.0312, -0.0104,  0.0234, -0.0004, -0.0170,\n",
       "                       -0.0229,  0.0279,  0.0313,  0.0112,  0.0117, -0.0233,  0.0018, -0.0262,\n",
       "                        0.0247, -0.0167,  0.0193,  0.0372,  0.0342,  0.0299,  0.0372, -0.0290,\n",
       "                       -0.0370, -0.0319, -0.0387, -0.0009,  0.0179,  0.0248, -0.0105, -0.0007,\n",
       "                        0.0110, -0.0286, -0.0391, -0.0265, -0.0335, -0.0225,  0.0290, -0.0003,\n",
       "                       -0.0383, -0.0246, -0.0253, -0.0239,  0.0265,  0.0075, -0.0310,  0.0330,\n",
       "                       -0.0263,  0.0098, -0.0269, -0.0378,  0.0089, -0.0183,  0.0087,  0.0296,\n",
       "                        0.0029,  0.0337,  0.0261, -0.0208, -0.0250, -0.0344,  0.0041,  0.0400,\n",
       "                        0.0095,  0.0095,  0.0217, -0.0100,  0.0250, -0.0346,  0.0209,  0.0260,\n",
       "                        0.0367,  0.0073, -0.0375,  0.0203,  0.0352,  0.0084,  0.0030,  0.0073,\n",
       "                        0.0074, -0.0213,  0.0209,  0.0336,  0.0356, -0.0011,  0.0074, -0.0296,\n",
       "                        0.0318, -0.0269,  0.0374,  0.0072,  0.0059,  0.0071, -0.0291,  0.0266,\n",
       "                        0.0370, -0.0019,  0.0307, -0.0006, -0.0224, -0.0272, -0.0352,  0.0021,\n",
       "                        0.0179,  0.0090,  0.0310,  0.0166, -0.0059, -0.0361, -0.0144, -0.0288,\n",
       "                       -0.0119, -0.0019, -0.0074,  0.0145, -0.0218,  0.0123, -0.0295, -0.0070,\n",
       "                       -0.0189, -0.0236, -0.0194,  0.0247,  0.0021,  0.0187, -0.0327,  0.0207,\n",
       "                       -0.0098, -0.0393, -0.0182, -0.0228, -0.0114,  0.0127,  0.0030, -0.0293,\n",
       "                        0.0337, -0.0037, -0.0116, -0.0018,  0.0012,  0.0122, -0.0108,  0.0044,\n",
       "                        0.0227, -0.0365, -0.0353,  0.0198, -0.0005, -0.0075,  0.0180,  0.0207,\n",
       "                       -0.0387, -0.0033,  0.0220, -0.0167, -0.0236, -0.0122,  0.0009,  0.0280])),\n",
       "              ('performer.net.layers.4.1.norm.weight',\n",
       "               tensor([1.0138, 1.0124, 1.0136, 1.0129, 1.0055, 1.0065, 1.0074, 1.0075, 1.0031,\n",
       "                       1.0085, 1.0069, 1.0080, 1.0055, 1.0102, 1.0108, 1.0103, 1.0201, 1.0106,\n",
       "                       0.9993, 1.0120, 1.0047, 1.0054, 1.0059, 1.0179, 1.0066, 1.0042, 1.0071,\n",
       "                       1.0127, 1.0110, 1.0080, 1.0042, 1.0091, 1.0098, 1.0095, 1.0070, 1.0025,\n",
       "                       1.0062, 1.0086, 1.0062, 1.0074, 1.0047, 1.0117, 1.0020, 1.0082, 1.0196,\n",
       "                       1.0048, 1.0053, 1.0202, 1.0117, 1.0048, 1.0050, 1.0228, 1.0111, 1.0081,\n",
       "                       1.0047, 1.0056, 1.0092, 1.0125, 1.0065, 1.0059, 1.0050, 1.0113, 1.0102,\n",
       "                       1.0066, 1.0125, 1.0054, 1.0116, 0.9970, 1.0138, 1.0183, 1.0185, 1.0069,\n",
       "                       1.0083, 1.0088, 1.0138, 1.0107, 1.0092, 1.0120, 1.0061, 1.0093, 1.0088,\n",
       "                       1.0036, 1.0033, 1.0068, 1.0100, 1.0146, 1.0236, 1.0015, 1.0008, 1.0135,\n",
       "                       1.0129, 1.0038, 1.0005, 1.0077, 1.0041, 1.0090, 1.0026, 1.0009, 1.0265,\n",
       "                       1.0071, 1.0108, 1.0090, 1.0139, 1.0098, 1.0083, 1.0193, 1.0115, 1.0101,\n",
       "                       1.0068, 1.0054, 1.0133, 1.0143, 1.0143, 1.0187, 1.0058, 1.0033, 1.0060,\n",
       "                       1.0057, 1.0170, 1.0084, 1.0134, 1.0048, 1.0047, 1.0074, 1.0032, 1.0117,\n",
       "                       1.0151, 1.0141, 1.0047, 1.0073, 1.0071, 1.0096, 1.0052, 1.0059, 1.0101,\n",
       "                       1.0057, 1.0092, 1.0092, 1.0052, 1.0245, 1.0153, 1.0146, 1.0105, 1.0069,\n",
       "                       1.0008, 1.0033, 1.0112, 1.0079, 1.0057, 1.0016, 1.0059, 1.0054, 1.0123,\n",
       "                       1.0138, 1.0106, 1.0074, 0.9994, 1.0086, 1.0114, 1.0063, 1.0108, 1.0065,\n",
       "                       0.9994, 1.0095, 1.0147, 1.0035, 1.0049, 1.0087, 1.0130, 1.0056, 1.0078,\n",
       "                       1.0075, 1.0064, 1.0045, 1.0103, 1.0204, 1.0018, 1.0082, 1.0049, 1.0064,\n",
       "                       1.0063, 1.0088, 1.0050, 1.0041, 1.0050, 1.0066, 1.0109, 1.0064, 1.0184,\n",
       "                       1.0076, 1.0168, 1.0126, 1.0093, 1.0141, 1.0056, 1.0093, 1.0057, 1.0160,\n",
       "                       1.0064, 1.0084])),\n",
       "              ('performer.net.layers.4.1.norm.bias',\n",
       "               tensor([-2.1046e-03,  1.4689e-03,  4.0421e-03, -3.0563e-03, -4.2210e-03,\n",
       "                        4.0511e-03,  1.8641e-03, -2.5816e-03, -3.8235e-03, -1.8803e-03,\n",
       "                       -1.1441e-03,  2.8774e-03,  1.2569e-04, -2.7994e-03, -4.5042e-05,\n",
       "                       -3.2690e-03,  6.4874e-04, -3.2416e-03,  2.5669e-03,  5.4852e-04,\n",
       "                       -1.9957e-03, -2.1857e-03, -2.4401e-03, -2.5294e-03, -1.5760e-03,\n",
       "                       -5.1309e-03, -2.2120e-03, -4.5609e-04,  1.2142e-03,  1.5566e-03,\n",
       "                       -7.8068e-05, -3.1818e-03,  1.3715e-03,  3.8503e-05, -9.6141e-04,\n",
       "                       -2.0290e-03, -3.6704e-04, -2.3685e-03, -1.7599e-03,  5.4357e-03,\n",
       "                       -2.9099e-03,  3.5706e-03,  6.8535e-04, -2.0764e-03,  2.3830e-03,\n",
       "                       -3.3204e-04, -2.4409e-03,  6.5973e-04, -5.1310e-04, -1.5659e-03,\n",
       "                       -1.1395e-03, -3.2338e-03,  2.4504e-03, -4.5630e-03,  1.1659e-03,\n",
       "                       -1.6448e-03, -6.7506e-06, -2.0009e-03, -1.5860e-03, -8.9337e-05,\n",
       "                        3.1169e-03,  2.1651e-03, -3.5085e-03,  4.7683e-03,  2.5069e-04,\n",
       "                        1.1316e-03, -2.0685e-03, -2.6724e-03,  2.5120e-05,  2.2574e-03,\n",
       "                        2.8011e-03,  4.4732e-04, -1.8061e-03, -8.3825e-04, -5.3836e-03,\n",
       "                       -1.3869e-03,  8.4558e-04,  1.7965e-03,  1.1919e-03, -4.8798e-03,\n",
       "                       -1.5745e-03,  1.2511e-04, -3.2707e-03, -4.3841e-03,  2.6684e-03,\n",
       "                        1.7052e-03, -2.6109e-03, -2.8730e-03,  4.4246e-03, -2.2440e-03,\n",
       "                        7.3627e-05, -3.2549e-04, -2.1890e-03, -3.3266e-03, -1.4369e-03,\n",
       "                       -4.9466e-04,  8.3201e-04, -2.3996e-03,  2.6314e-03,  2.7563e-03,\n",
       "                       -6.6691e-04, -2.4979e-03,  6.6551e-05, -1.6221e-03,  3.7754e-03,\n",
       "                        1.8842e-03,  7.9150e-04, -2.4684e-03, -2.6617e-03, -1.6006e-03,\n",
       "                       -3.9265e-03, -4.5656e-03,  2.2839e-03, -1.3679e-03,  1.9263e-03,\n",
       "                       -1.0096e-03,  3.1945e-03,  4.8964e-03, -9.0412e-04,  2.4468e-03,\n",
       "                       -3.1642e-04,  1.8240e-03,  1.2248e-03,  2.6275e-03,  2.7941e-03,\n",
       "                       -3.9060e-03,  6.6275e-05, -1.9306e-03,  1.2930e-03,  2.9522e-03,\n",
       "                        7.1086e-04,  1.3482e-03,  3.9385e-04,  2.0132e-03,  1.3640e-03,\n",
       "                        1.5222e-04, -1.5921e-03,  1.0513e-03,  2.1166e-03,  3.8408e-03,\n",
       "                       -2.3309e-03,  4.7640e-03, -3.0922e-03, -1.6660e-03, -5.2054e-04,\n",
       "                       -1.3043e-03,  3.3601e-06, -2.7380e-03,  8.8961e-04,  4.8533e-03,\n",
       "                        1.7316e-03, -3.3603e-03, -1.4456e-03,  2.4156e-03,  7.6261e-04,\n",
       "                       -1.3524e-03,  9.0580e-05, -1.4706e-03,  5.5244e-03,  1.4361e-03,\n",
       "                       -2.6152e-03,  5.3628e-03,  6.2680e-04,  1.1871e-03,  4.1148e-03,\n",
       "                       -3.6425e-03, -4.2344e-03,  2.7014e-03, -1.2303e-03, -4.7806e-03,\n",
       "                        1.6946e-03,  3.8001e-03,  3.5405e-03, -5.7433e-03, -4.6997e-03,\n",
       "                        2.9664e-04, -1.8740e-03, -2.1925e-03,  1.8199e-04,  3.9407e-04,\n",
       "                        5.7928e-03, -2.6826e-03,  1.1247e-03,  1.8374e-03, -3.1077e-03,\n",
       "                        2.0246e-03,  6.8792e-04,  8.9824e-04,  3.8132e-04,  2.3575e-03,\n",
       "                        1.0428e-03, -7.4545e-04, -2.1235e-03, -1.3220e-03, -1.7411e-03,\n",
       "                        9.4908e-04,  4.0732e-03,  3.0196e-03,  5.3062e-05, -6.3955e-03])),\n",
       "              ('performer.net.layers.4.1.fn.fn.w1.weight',\n",
       "               tensor([[-0.0252, -0.0601,  0.0028,  ..., -0.0325, -0.0547, -0.0682],\n",
       "                       [ 0.0460,  0.0179, -0.0027,  ..., -0.0233,  0.0457, -0.0536],\n",
       "                       [ 0.0285,  0.0547,  0.0628,  ...,  0.0728, -0.0076,  0.0091],\n",
       "                       ...,\n",
       "                       [ 0.0143, -0.0008, -0.0534,  ..., -0.0193,  0.0589, -0.0401],\n",
       "                       [-0.0127, -0.0198,  0.0235,  ..., -0.0193,  0.0583, -0.0042],\n",
       "                       [-0.0627, -0.0324, -0.0537,  ..., -0.0486, -0.0599,  0.0696]])),\n",
       "              ('performer.net.layers.4.1.fn.fn.w1.bias',\n",
       "               tensor([-1.5908e-03, -4.6346e-02, -6.9046e-02,  7.1396e-02, -4.8320e-02,\n",
       "                        5.0950e-02,  3.7760e-02, -2.3456e-02,  5.5780e-02, -1.3953e-02,\n",
       "                       -1.2065e-02,  5.6918e-02, -1.7254e-02, -3.6491e-02,  6.1514e-03,\n",
       "                        4.0008e-02, -4.1023e-03, -6.5296e-02,  5.0457e-02,  6.0907e-02,\n",
       "                        1.8113e-03, -5.3772e-02,  2.4710e-02, -5.1501e-02, -5.1096e-02,\n",
       "                        4.6296e-02,  4.1430e-02,  4.9275e-02,  3.0532e-02,  3.5390e-02,\n",
       "                        1.1953e-02, -1.9288e-02,  5.0127e-02,  2.2516e-02, -1.3389e-02,\n",
       "                        4.6791e-02, -1.4419e-02,  2.4052e-02,  3.3654e-02, -4.5915e-02,\n",
       "                        5.9674e-02, -1.7564e-02, -4.5069e-02,  3.7360e-02,  3.9779e-02,\n",
       "                       -2.1504e-03,  1.7058e-02, -7.5561e-03,  1.6642e-04,  1.9106e-02,\n",
       "                       -4.7589e-02,  2.0324e-02, -3.3133e-02, -2.2797e-02,  6.4509e-02,\n",
       "                       -2.3743e-02,  4.9931e-02, -5.9324e-02, -6.3242e-03,  6.4164e-02,\n",
       "                       -5.6769e-02,  3.6998e-02, -4.8246e-02, -4.3100e-03, -3.1538e-02,\n",
       "                        3.3415e-02, -2.3245e-02,  5.1633e-02,  4.8646e-02, -2.9379e-02,\n",
       "                       -4.6257e-02, -1.4559e-03,  5.2336e-02, -6.3571e-02, -5.7846e-02,\n",
       "                       -2.6841e-02, -1.3340e-02, -3.3844e-02,  6.3674e-02,  6.8222e-02,\n",
       "                        3.4800e-02, -2.6792e-02,  6.4055e-02,  5.3764e-02,  5.3140e-02,\n",
       "                        6.5087e-02,  3.8615e-02, -1.2092e-02, -1.7739e-02, -5.9324e-02,\n",
       "                        1.8964e-02,  3.5086e-02,  4.6069e-02,  3.7325e-02, -1.7681e-03,\n",
       "                        6.0312e-02, -3.0483e-02,  5.6033e-02, -4.0100e-03,  4.5837e-02,\n",
       "                        6.6776e-02,  7.0106e-02, -2.0355e-03, -1.6822e-02, -5.5917e-02,\n",
       "                       -6.3941e-02, -3.9879e-02,  2.1040e-02,  1.9532e-02, -2.5079e-02,\n",
       "                       -6.6531e-02,  6.0203e-02,  5.7413e-02,  5.0952e-02, -5.5319e-02,\n",
       "                       -3.5269e-02,  4.8597e-02,  4.6496e-02, -2.6421e-02, -1.6870e-02,\n",
       "                       -3.6094e-02, -6.2792e-02, -6.3037e-02, -4.5059e-02, -5.1499e-02,\n",
       "                        6.1248e-02, -4.2734e-02, -3.3512e-02, -7.9960e-03, -6.1405e-02,\n",
       "                        4.6705e-02,  4.3050e-02, -2.0824e-02,  8.0445e-03,  1.7581e-02,\n",
       "                       -2.9614e-02, -5.2536e-02,  1.5492e-02,  2.8385e-02, -3.2903e-03,\n",
       "                        4.5277e-02,  6.1166e-02, -6.6563e-02,  1.0718e-02, -6.3092e-02,\n",
       "                        6.1768e-03, -5.9492e-02,  2.8837e-02, -5.3648e-02,  2.2072e-02,\n",
       "                       -1.8893e-02,  5.9001e-02, -5.9892e-02,  5.3251e-02,  4.9226e-02,\n",
       "                        6.0723e-02,  2.4090e-02,  1.8203e-02,  2.9085e-02, -7.3153e-03,\n",
       "                       -2.2983e-02, -5.3291e-02,  5.4623e-02, -2.9376e-02, -6.2575e-02,\n",
       "                        8.4149e-03,  6.7501e-03, -4.4589e-02, -6.3997e-02, -6.7636e-02,\n",
       "                       -3.3419e-02, -6.3080e-02, -5.1200e-02, -5.2071e-02,  5.1811e-02,\n",
       "                       -2.2854e-02,  4.3938e-02,  3.0013e-02, -5.0817e-02,  1.4160e-02,\n",
       "                        4.6462e-02, -2.3971e-02,  5.5129e-02,  2.3852e-02,  3.7644e-02,\n",
       "                       -6.9536e-02, -6.2006e-02, -6.0952e-02, -6.7662e-02,  4.1317e-02,\n",
       "                        8.7276e-03,  4.4805e-02, -2.7616e-02, -9.1138e-04,  1.9731e-02,\n",
       "                        1.6254e-02,  1.3763e-02,  2.2841e-02,  5.3977e-02, -4.9259e-02,\n",
       "                        5.6382e-02, -1.9490e-02,  2.1600e-02,  5.7230e-02, -4.5702e-02,\n",
       "                        6.9100e-02,  7.3920e-02, -7.0267e-02, -7.0239e-03,  1.7603e-02,\n",
       "                        3.5135e-02,  6.3389e-02,  6.8635e-02, -5.5769e-02,  3.1910e-03,\n",
       "                        3.3115e-02,  5.6557e-02, -4.0803e-02,  3.8795e-02, -6.7552e-02,\n",
       "                       -5.9484e-02, -3.2116e-02,  1.2543e-02,  4.1539e-02, -1.3360e-02,\n",
       "                       -3.2927e-02, -4.2928e-02, -9.9840e-03, -2.2067e-02, -2.7982e-02,\n",
       "                       -1.0186e-02,  6.3608e-02,  6.5859e-02, -1.7141e-02,  3.5111e-02,\n",
       "                        5.5576e-02,  5.7691e-02, -3.7105e-02, -5.2831e-02, -1.3624e-02,\n",
       "                        4.1366e-02,  4.9028e-02,  6.2357e-02,  4.9263e-02, -4.8824e-02,\n",
       "                        1.2807e-02, -3.6198e-02,  3.4093e-02, -5.7534e-02,  4.7269e-02,\n",
       "                        6.6410e-02,  4.8504e-03,  1.1796e-02, -3.6429e-02,  6.7389e-03,\n",
       "                        9.5141e-03, -3.8772e-02, -5.3040e-02, -1.8300e-02,  4.8654e-02,\n",
       "                        5.2640e-02,  3.4052e-02,  1.1967e-02, -8.6668e-04,  3.8097e-03,\n",
       "                        1.5600e-02, -1.0940e-02, -1.5677e-02,  5.5249e-02, -3.1965e-02,\n",
       "                        5.0597e-02, -6.2363e-02, -3.7911e-02, -6.5505e-02,  2.3472e-02,\n",
       "                       -1.5611e-02, -6.5258e-02,  2.3607e-02,  2.2924e-02, -6.3469e-02,\n",
       "                        1.7207e-02, -6.3307e-02,  6.1880e-02,  4.8340e-02, -5.8665e-02,\n",
       "                        7.2443e-02,  1.4492e-02, -4.2055e-02, -3.2255e-02,  2.2324e-02,\n",
       "                        6.3945e-02,  1.1871e-02,  4.3828e-02, -6.4089e-02,  4.4096e-02,\n",
       "                        9.0963e-05,  1.9809e-02, -4.9522e-02,  6.3455e-02, -4.5464e-02,\n",
       "                       -3.4798e-03, -4.5687e-02, -3.6965e-02,  6.2157e-02,  7.1248e-03,\n",
       "                        7.1673e-02, -2.2807e-02,  3.8587e-02, -2.9121e-02,  9.7184e-03,\n",
       "                        2.1189e-02,  2.5782e-02,  5.7495e-02,  3.0258e-02, -6.0250e-02,\n",
       "                        9.6952e-03, -5.5006e-02,  5.2346e-02,  5.6732e-02,  3.2861e-02,\n",
       "                        1.1821e-02, -6.0776e-02, -3.6937e-02, -5.5520e-02,  4.1527e-02,\n",
       "                        5.6791e-02, -2.8208e-02,  6.7222e-02,  1.1407e-02, -2.4132e-02,\n",
       "                        4.3897e-02,  2.9558e-02,  2.8674e-02, -6.5290e-02, -5.9714e-02,\n",
       "                       -2.1232e-02, -2.7087e-02, -7.5014e-03, -4.1686e-02, -4.8080e-02,\n",
       "                       -3.7668e-02, -2.9947e-02,  2.6600e-02, -1.7180e-02, -6.9810e-03,\n",
       "                       -2.5578e-02,  1.6874e-02,  1.2542e-02, -1.7418e-02, -4.1286e-02,\n",
       "                        5.8613e-02, -8.4381e-03,  4.5376e-02, -4.7129e-02,  5.9398e-02,\n",
       "                        3.2249e-02, -4.2982e-02, -3.3101e-02,  2.4871e-02, -1.4834e-02,\n",
       "                       -4.9147e-02, -6.1153e-02,  5.7904e-02, -3.7913e-02,  3.3323e-02,\n",
       "                        2.5303e-02, -2.2628e-02,  5.6590e-02,  5.6911e-02,  2.0099e-02,\n",
       "                        2.6211e-02, -4.0961e-02, -6.0070e-02, -6.6007e-03, -5.3127e-02,\n",
       "                        2.6129e-02,  2.9545e-02, -4.6436e-02,  4.8828e-02,  1.7113e-02,\n",
       "                        7.1875e-02,  1.6572e-02, -3.1303e-03,  4.2644e-02,  5.3379e-02,\n",
       "                        4.1386e-03,  4.4110e-02,  4.9154e-02,  4.7339e-02, -2.8760e-02,\n",
       "                        6.9557e-02, -9.5800e-03, -1.7723e-02,  6.2617e-02,  5.8612e-02,\n",
       "                        2.0620e-02, -3.2857e-03, -1.7365e-02, -1.5315e-02, -1.0191e-02,\n",
       "                       -3.9968e-02,  7.1781e-02, -2.3149e-02, -1.7634e-02,  2.1018e-02,\n",
       "                        2.6787e-02, -5.0884e-02,  6.4420e-02, -4.0535e-03,  1.0961e-02,\n",
       "                       -3.6155e-02,  1.7175e-02,  2.0939e-02,  2.8217e-02, -1.4750e-02,\n",
       "                       -2.4763e-02,  1.7695e-02,  9.3211e-03, -5.3010e-02, -4.4271e-02,\n",
       "                       -1.3616e-02,  7.4149e-03,  1.8755e-02, -5.0354e-02,  5.8407e-02,\n",
       "                       -2.5834e-02,  6.8392e-02, -3.7373e-02, -7.1848e-02,  2.3830e-02,\n",
       "                        1.9217e-02, -6.1121e-02,  7.6520e-03, -7.1710e-04,  6.2144e-02,\n",
       "                       -9.4919e-03, -4.2127e-03,  3.8922e-02, -3.8829e-02, -3.9812e-02,\n",
       "                       -5.7710e-02,  1.3278e-02, -1.1852e-02, -5.6087e-02,  2.8863e-03,\n",
       "                        3.3776e-02,  2.9906e-02,  6.7678e-03,  4.3534e-02,  7.2955e-02,\n",
       "                       -3.9372e-03, -4.5089e-02, -5.1369e-02,  3.3690e-02,  6.0401e-02,\n",
       "                       -3.6908e-02, -1.9731e-02, -3.5873e-02, -2.8232e-02,  3.3778e-02,\n",
       "                       -2.4135e-02, -1.1036e-02,  1.5035e-02,  1.8479e-02, -6.4113e-03,\n",
       "                        1.8511e-02,  4.6486e-02, -4.8116e-02, -1.5362e-02, -9.6830e-03,\n",
       "                       -4.0561e-02,  4.0985e-02, -3.5001e-02,  4.6674e-02,  6.5134e-02,\n",
       "                       -1.5105e-02, -6.4368e-02, -6.3715e-02, -5.6364e-02,  2.8668e-02,\n",
       "                        6.1780e-02, -2.0238e-02, -5.7812e-02, -4.3377e-02, -6.6910e-02,\n",
       "                       -6.3304e-02, -2.4176e-03, -3.5396e-02, -2.4803e-02,  1.0952e-02,\n",
       "                        3.4905e-02, -3.7953e-02,  5.3581e-02,  5.7576e-03, -6.7884e-02,\n",
       "                        3.2440e-02,  4.8470e-02,  3.6089e-02,  7.0990e-02, -3.6384e-02,\n",
       "                       -7.0254e-02, -4.6680e-02, -1.0663e-03, -4.0576e-03, -2.7455e-02,\n",
       "                        4.9319e-02, -3.5529e-02,  4.2751e-02,  1.1017e-02,  4.8861e-02,\n",
       "                        5.5642e-02,  4.9890e-02,  2.9706e-02, -2.9469e-02,  3.2705e-02,\n",
       "                        4.6091e-02,  9.8790e-03,  1.6404e-02,  4.4107e-02, -6.8567e-02,\n",
       "                        3.3507e-02, -2.8598e-02, -1.9917e-02, -6.7806e-02, -4.1248e-02,\n",
       "                        3.1071e-02, -5.4994e-02,  5.0320e-02,  4.4444e-02,  6.8076e-02,\n",
       "                        4.7785e-02,  2.8416e-02,  8.3436e-03,  5.5025e-02,  6.3416e-03,\n",
       "                       -4.3464e-02, -4.0373e-02,  6.3427e-02,  6.3152e-02,  5.8711e-02,\n",
       "                        2.5952e-02, -3.8940e-02,  3.4682e-02, -5.1030e-02, -4.2254e-02,\n",
       "                       -4.3980e-02, -1.5125e-02,  6.0823e-02, -5.0228e-02, -2.5605e-02,\n",
       "                        4.4452e-04, -4.8500e-02, -1.1925e-02,  6.7393e-03,  7.0891e-02,\n",
       "                        2.4874e-02,  7.2778e-03, -5.7455e-02,  1.0137e-02, -3.4466e-02,\n",
       "                        7.4217e-03, -7.7948e-03,  1.7029e-02,  6.8817e-02,  2.7074e-02,\n",
       "                       -3.0209e-02,  2.3663e-02, -5.0491e-02, -6.2892e-02, -3.4496e-02,\n",
       "                        6.9191e-02,  3.8275e-03, -5.5145e-03,  2.5948e-02,  6.6530e-02,\n",
       "                       -3.2154e-04,  3.1482e-02, -3.3296e-03, -1.7593e-02, -5.6180e-03,\n",
       "                        2.8586e-02, -5.6924e-02, -1.2286e-02, -1.0124e-02, -5.7628e-02,\n",
       "                        3.5390e-02, -7.7543e-03, -5.8969e-02,  6.3662e-02, -4.5402e-02,\n",
       "                       -5.5584e-02,  1.1846e-02,  3.3430e-02,  2.6170e-02, -4.2939e-03,\n",
       "                        6.4445e-02,  2.2497e-02,  4.6510e-02,  1.0964e-04, -3.7390e-03,\n",
       "                        2.7437e-02, -3.0270e-02,  5.8701e-02,  1.9176e-02,  1.9672e-02,\n",
       "                        3.0697e-02,  1.8138e-03,  1.5498e-02, -1.1571e-02, -6.2366e-02,\n",
       "                       -1.2665e-02,  1.6776e-02, -1.0338e-03, -5.7390e-02,  5.6243e-02,\n",
       "                        5.0888e-02,  4.0623e-02,  3.5757e-02,  6.4578e-02,  6.1487e-02,\n",
       "                       -6.4145e-02,  4.7728e-02,  3.3247e-02, -2.3144e-02,  3.7223e-02,\n",
       "                        1.7255e-02,  6.1523e-02,  4.8755e-02,  2.0879e-03,  2.0920e-02,\n",
       "                       -4.7398e-02, -1.9664e-02,  2.0584e-02,  7.6307e-03,  3.4378e-02,\n",
       "                        9.2786e-04, -6.1361e-02, -7.6049e-03, -4.2565e-02, -1.6697e-02,\n",
       "                       -4.1798e-02,  1.1059e-02,  5.9907e-02, -6.6106e-02,  2.6023e-02,\n",
       "                       -1.2044e-02,  3.6503e-02,  3.0697e-02,  4.4094e-02,  4.8753e-02,\n",
       "                       -1.7803e-02, -2.4232e-02, -4.7108e-02, -5.3121e-02,  2.0030e-02,\n",
       "                        3.1605e-02, -4.2375e-02, -3.2578e-02, -6.4133e-02,  2.2546e-02,\n",
       "                        6.7732e-02, -6.0449e-02,  2.8091e-02,  6.0794e-02,  3.2145e-02,\n",
       "                       -2.3625e-02,  3.2564e-02,  5.4236e-02,  4.8540e-04,  4.5923e-03,\n",
       "                        5.9598e-02,  5.5707e-02, -9.5516e-03,  4.9252e-02,  6.6254e-02,\n",
       "                       -3.3340e-02,  2.9189e-02,  1.4450e-02, -8.7141e-03,  4.3686e-02,\n",
       "                       -6.4417e-02,  5.8964e-03,  2.4867e-02,  2.0547e-03,  2.1107e-02,\n",
       "                        5.0484e-02, -2.0984e-02, -3.7808e-02,  1.0332e-02, -2.1481e-03,\n",
       "                        5.7426e-02, -1.3234e-02,  1.3867e-02,  2.2167e-02,  1.8768e-02,\n",
       "                        8.2291e-03,  3.8661e-02,  1.4131e-02, -5.1985e-02, -5.1430e-04,\n",
       "                       -2.3804e-02,  3.0366e-02,  2.0636e-02,  2.7378e-02,  4.1424e-02,\n",
       "                       -3.4974e-02, -9.0201e-03, -6.6247e-02, -4.5862e-02,  6.2241e-02,\n",
       "                        1.3052e-02, -4.8592e-02,  1.9327e-03,  6.1941e-02,  3.7200e-02,\n",
       "                       -2.6909e-02,  4.2956e-02,  3.5953e-02,  6.6037e-02,  4.6713e-02,\n",
       "                        4.6718e-02,  1.5583e-02,  4.9930e-02, -3.1417e-02,  7.2632e-02,\n",
       "                       -5.7835e-02, -3.5326e-02, -3.2954e-02,  6.7115e-02,  4.1424e-02,\n",
       "                       -5.8504e-02,  5.2891e-02,  5.8475e-02, -2.7049e-02,  1.4427e-02,\n",
       "                       -2.7498e-02,  4.2706e-03,  6.0139e-02,  3.6814e-02,  1.6512e-02,\n",
       "                       -1.7324e-02, -5.8318e-02, -2.1322e-02, -1.3276e-02,  1.2144e-02,\n",
       "                        1.0156e-02,  7.3363e-02,  5.2699e-02,  3.1749e-02,  5.0435e-02,\n",
       "                       -2.8882e-02,  6.0579e-02, -2.9219e-02, -7.9845e-05, -5.3179e-02,\n",
       "                        2.5227e-02,  5.8921e-02, -5.1591e-02,  5.3760e-02, -4.8900e-02,\n",
       "                        6.5343e-02, -3.5501e-02,  5.7294e-03, -2.3414e-02, -3.1753e-02,\n",
       "                       -3.8428e-02, -8.2757e-03, -2.9915e-02, -2.8183e-02,  5.9818e-02,\n",
       "                        3.5221e-02, -1.8484e-04, -4.2923e-02,  4.0623e-02,  5.4198e-03,\n",
       "                       -6.7839e-02,  3.0053e-02,  2.0796e-02,  5.6759e-02,  1.3067e-02,\n",
       "                        7.9802e-03, -7.2909e-03, -2.1773e-02, -2.2513e-02, -4.2738e-02,\n",
       "                        5.7696e-02,  9.9420e-03,  7.3268e-02, -2.2924e-02,  1.5915e-02,\n",
       "                       -2.4917e-02, -6.0682e-02, -4.0735e-03,  7.1911e-02,  3.3168e-02,\n",
       "                       -2.9596e-02,  7.1684e-02,  1.3945e-02,  1.1905e-02, -5.9587e-02])),\n",
       "              ('performer.net.layers.4.1.fn.fn.w2.weight',\n",
       "               tensor([[ 0.0287, -0.0159,  0.0276,  ..., -0.0276, -0.0135,  0.0286],\n",
       "                       [-0.0167, -0.0015,  0.0242,  ...,  0.0149,  0.0185, -0.0048],\n",
       "                       [-0.0200, -0.0315,  0.0284,  ..., -0.0247,  0.0137, -0.0250],\n",
       "                       ...,\n",
       "                       [-0.0046,  0.0297,  0.0096,  ..., -0.0077, -0.0316, -0.0159],\n",
       "                       [ 0.0035, -0.0086,  0.0180,  ...,  0.0142,  0.0185,  0.0219],\n",
       "                       [ 0.0383,  0.0218,  0.0103,  ..., -0.0272,  0.0105,  0.0184]])),\n",
       "              ('performer.net.layers.4.1.fn.fn.w2.bias',\n",
       "               tensor([-9.6516e-03, -2.7735e-02, -1.3324e-02, -4.5497e-03, -1.6810e-02,\n",
       "                        1.8211e-02,  3.5557e-02,  9.7964e-03, -3.1946e-02, -1.1024e-02,\n",
       "                       -9.3834e-03, -1.1985e-02,  3.0963e-02, -1.2219e-02, -6.9069e-03,\n",
       "                        2.1637e-02, -3.0882e-03, -1.4058e-02, -1.1735e-02, -1.1577e-02,\n",
       "                        8.5325e-03, -1.8950e-02,  3.6211e-02,  3.0453e-03,  2.4734e-02,\n",
       "                        3.5847e-02, -1.9710e-02, -8.3297e-03, -2.3478e-02,  2.6787e-02,\n",
       "                       -6.9393e-03,  2.5561e-02,  2.5246e-02,  8.6580e-03,  2.6985e-03,\n",
       "                       -1.9483e-02, -9.7614e-03, -2.3305e-03, -8.7527e-03, -8.1564e-03,\n",
       "                       -2.7406e-02,  1.0222e-02, -3.0803e-03, -1.2115e-02, -2.5025e-02,\n",
       "                       -2.4907e-02,  1.5849e-02,  1.8504e-04,  2.4357e-02, -2.4823e-02,\n",
       "                        1.8663e-02, -1.5394e-02,  2.9296e-02,  3.1656e-02,  1.3831e-02,\n",
       "                        8.2131e-03, -2.8006e-02, -1.6961e-02,  7.4791e-03,  2.9537e-02,\n",
       "                        1.3842e-02,  1.6540e-02,  1.8738e-02, -2.7792e-02, -2.3108e-02,\n",
       "                       -1.3622e-02, -2.7134e-02, -3.1523e-02,  2.2307e-02, -1.0898e-03,\n",
       "                        2.2261e-02,  2.3187e-02, -2.2470e-02,  2.5120e-02,  1.1905e-02,\n",
       "                        1.1916e-03, -1.9472e-02, -4.9561e-03,  1.6314e-02, -2.2629e-02,\n",
       "                        6.9127e-03,  2.5232e-02, -7.3203e-03, -2.3129e-02,  2.6578e-02,\n",
       "                       -7.0713e-03, -2.5046e-02,  3.0663e-02, -1.9925e-02, -2.1258e-03,\n",
       "                       -3.3664e-02, -3.2636e-02, -1.5315e-02,  1.8816e-02, -2.5992e-02,\n",
       "                       -3.1929e-02, -2.6613e-02,  2.3154e-03,  1.4395e-02, -1.0223e-03,\n",
       "                        2.6558e-02, -3.0551e-02, -2.6584e-02, -2.2502e-02, -9.6337e-03,\n",
       "                        1.9468e-03,  1.8214e-02, -9.9287e-03, -1.2625e-02,  1.9853e-02,\n",
       "                        1.2949e-02, -1.1939e-02,  1.9276e-03,  2.2114e-02, -1.1499e-02,\n",
       "                        1.3498e-03,  2.4460e-02, -2.6437e-03,  3.1502e-02,  1.1489e-02,\n",
       "                       -2.4534e-02,  1.0721e-02,  2.3060e-02,  2.4484e-02,  8.7536e-03,\n",
       "                        2.8276e-02, -2.3305e-02, -2.7656e-02, -8.8429e-03, -1.9535e-02,\n",
       "                        5.7056e-03,  1.0609e-02,  3.0059e-02, -1.4246e-02, -1.9063e-02,\n",
       "                       -3.7376e-02, -9.3593e-03, -3.2348e-02, -2.0156e-02,  4.0155e-03,\n",
       "                       -2.1616e-02,  2.9691e-02,  2.5622e-02, -6.9914e-03,  2.4287e-02,\n",
       "                       -1.2294e-02,  1.8998e-02, -1.3446e-02, -4.0930e-03, -4.0699e-03,\n",
       "                       -2.2822e-02, -2.2486e-02, -1.6412e-02, -2.2995e-03,  7.3900e-03,\n",
       "                        2.6676e-03,  3.3404e-02,  3.0757e-02, -2.4065e-02,  2.2404e-02,\n",
       "                        1.5004e-02,  1.6454e-02,  3.1858e-02,  1.4934e-02, -2.4155e-03,\n",
       "                       -7.2242e-03,  2.1598e-02, -1.8751e-02, -7.3632e-03,  1.5056e-02,\n",
       "                        2.6890e-02,  1.1593e-02, -2.5956e-02, -7.5771e-03, -1.4986e-02,\n",
       "                        1.7460e-02, -3.1586e-02, -1.7916e-02, -1.9093e-02, -1.3233e-02,\n",
       "                        1.1176e-02, -1.7870e-02,  3.9558e-03, -2.4628e-02, -1.6253e-02,\n",
       "                       -9.1649e-03, -2.7959e-03, -3.0914e-02, -1.5604e-02,  7.7266e-03,\n",
       "                       -2.5734e-02,  1.5783e-02,  2.8809e-02, -9.6494e-04, -3.4393e-05,\n",
       "                        6.8458e-03,  2.9813e-02, -8.7204e-03, -2.2268e-02, -3.0953e-02])),\n",
       "              ('performer.net.layers.5.0.norm.weight',\n",
       "               tensor([0.9991, 0.9977, 1.0020, 1.0009, 0.9999, 1.0008, 1.0007, 0.9990, 1.0022,\n",
       "                       0.9983, 0.9999, 1.0026, 0.9989, 0.9999, 1.0024, 0.9968, 0.9996, 0.9999,\n",
       "                       1.0000, 1.0007, 1.0012, 0.9939, 1.0003, 0.9990, 1.0001, 0.9980, 0.9997,\n",
       "                       0.9999, 1.0006, 0.9979, 0.9989, 0.9990, 1.0014, 0.9987, 1.0018, 0.9992,\n",
       "                       1.0003, 1.0001, 1.0003, 1.0006, 0.9981, 1.0006, 0.9990, 1.0002, 1.0021,\n",
       "                       0.9977, 1.0004, 0.9982, 1.0010, 0.9976, 0.9999, 0.9999, 0.9984, 0.9992,\n",
       "                       0.9969, 1.0006, 0.9958, 1.0027, 0.9997, 0.9990, 1.0006, 0.9977, 0.9957,\n",
       "                       0.9989, 0.9999, 1.0004, 0.9958, 0.9997, 0.9969, 0.9987, 0.9991, 0.9999,\n",
       "                       0.9988, 0.9966, 1.0008, 1.0003, 0.9999, 0.9982, 0.9983, 0.9943, 0.9995,\n",
       "                       0.9993, 0.9962, 0.9997, 1.0025, 0.9972, 0.9988, 1.0002, 1.0023, 1.0002,\n",
       "                       0.9984, 1.0004, 0.9985, 1.0000, 0.9987, 0.9998, 0.9992, 1.0006, 0.9996,\n",
       "                       0.9997, 0.9979, 0.9972, 0.9994, 1.0007, 0.9991, 0.9984, 1.0003, 0.9983,\n",
       "                       0.9983, 0.9980, 1.0023, 1.0007, 0.9990, 1.0002, 1.0044, 1.0005, 0.9986,\n",
       "                       1.0031, 1.0009, 0.9996, 0.9992, 0.9983, 0.9998, 0.9994, 0.9994, 0.9985,\n",
       "                       0.9987, 0.9989, 1.0007, 0.9999, 1.0008, 0.9999, 0.9986, 1.0019, 1.0000,\n",
       "                       0.9980, 0.9971, 0.9967, 0.9977, 1.0000, 0.9999, 0.9989, 0.9983, 0.9982,\n",
       "                       0.9982, 1.0006, 0.9992, 0.9987, 1.0006, 0.9998, 0.9976, 0.9981, 0.9998,\n",
       "                       0.9997, 0.9973, 1.0008, 0.9985, 0.9989, 0.9980, 0.9955, 0.9983, 1.0001,\n",
       "                       1.0004, 0.9962, 0.9973, 0.9987, 1.0003, 0.9999, 1.0017, 1.0002, 1.0012,\n",
       "                       1.0027, 1.0001, 1.0027, 0.9990, 0.9999, 0.9991, 0.9998, 0.9965, 1.0010,\n",
       "                       1.0002, 0.9964, 0.9975, 1.0001, 0.9993, 0.9998, 0.9999, 0.9996, 0.9981,\n",
       "                       0.9986, 0.9994, 1.0009, 0.9998, 1.0019, 0.9985, 1.0005, 0.9988, 0.9989,\n",
       "                       1.0001, 0.9997])),\n",
       "              ('performer.net.layers.5.0.norm.bias',\n",
       "               tensor([ 3.6591e-04, -3.6259e-03,  4.3290e-05,  3.3396e-04,  5.9582e-05,\n",
       "                        3.8064e-04,  1.6671e-03, -2.2194e-04, -5.9821e-05, -1.3032e-03,\n",
       "                        1.6946e-03,  7.2943e-04,  1.5255e-03,  4.0004e-04, -4.1516e-04,\n",
       "                       -2.1852e-03, -4.7164e-04, -2.8991e-04, -1.2941e-03, -2.2701e-04,\n",
       "                        6.3497e-04,  1.6720e-03,  1.1544e-03, -9.7339e-04,  2.4938e-05,\n",
       "                       -1.4107e-03,  2.5844e-03, -2.5710e-03, -9.6515e-04,  1.1653e-03,\n",
       "                        9.4390e-04, -2.6710e-04,  1.1668e-03, -1.4661e-04,  1.7942e-03,\n",
       "                       -2.2644e-03, -9.1254e-04,  1.6384e-03,  2.6574e-03, -5.8040e-04,\n",
       "                        1.9576e-03,  6.3906e-04,  1.6237e-04, -1.6407e-03,  6.6988e-04,\n",
       "                        4.0947e-04, -2.3311e-06, -6.2002e-04,  4.4291e-04,  1.3836e-03,\n",
       "                        2.1936e-03,  3.2110e-03,  6.9962e-04,  1.3654e-03,  2.4832e-03,\n",
       "                        1.0171e-03,  1.9725e-03,  3.1581e-04,  7.1669e-04,  2.8472e-03,\n",
       "                       -1.1368e-03,  8.4226e-04,  3.5135e-03,  4.5554e-04, -6.1546e-04,\n",
       "                       -8.3128e-04, -3.4685e-03, -1.3514e-04,  2.5269e-04, -5.6062e-04,\n",
       "                        8.0936e-04, -1.4439e-03,  2.0219e-04, -7.4613e-04, -8.8698e-04,\n",
       "                       -1.4239e-03, -8.5709e-04, -1.0503e-03, -6.8340e-04, -1.9650e-03,\n",
       "                        1.6196e-03, -1.1507e-03,  1.2053e-03, -9.1502e-04,  4.4196e-04,\n",
       "                       -1.3035e-03, -9.3810e-05,  1.0693e-03, -2.3010e-03,  1.0412e-04,\n",
       "                       -5.4730e-04, -3.1427e-04, -8.3033e-04,  2.6420e-04,  1.3560e-03,\n",
       "                        3.8605e-04,  3.9658e-04, -2.0167e-03,  1.8365e-03, -2.2744e-04,\n",
       "                       -2.4378e-03, -3.6726e-04,  9.3701e-08, -5.0628e-04, -7.2967e-04,\n",
       "                        1.3840e-03, -2.8873e-04,  1.4235e-03,  1.4877e-03,  2.2833e-03,\n",
       "                        9.3524e-04, -3.5603e-04,  1.0094e-03, -2.6768e-03, -8.0181e-04,\n",
       "                       -1.9482e-03, -8.4985e-04, -3.0010e-03,  6.2502e-04, -1.9951e-03,\n",
       "                       -2.2959e-03, -1.7305e-03, -1.2096e-03,  2.3522e-04, -4.3519e-04,\n",
       "                       -5.8038e-04,  1.4494e-03,  2.3913e-03,  9.1143e-04,  9.9097e-05,\n",
       "                       -1.4129e-03, -3.4804e-04,  2.2793e-05, -1.2497e-03, -1.2027e-03,\n",
       "                       -3.5963e-03, -1.4223e-03,  6.1389e-05,  1.3626e-03,  3.8918e-04,\n",
       "                        1.4114e-03,  2.7914e-04, -7.3392e-04, -2.3234e-03, -2.8093e-04,\n",
       "                        4.8664e-04, -2.5345e-06,  4.1157e-04, -1.5454e-03, -1.8765e-03,\n",
       "                       -3.0750e-03,  1.3506e-03,  1.0096e-03, -1.1432e-03, -2.4967e-03,\n",
       "                       -2.3243e-03,  2.7006e-03, -9.3026e-04,  1.4055e-03, -1.0326e-03,\n",
       "                        2.3629e-03, -1.4403e-03, -3.7976e-04,  1.9136e-03,  2.1135e-03,\n",
       "                        1.2432e-03,  1.9216e-03, -8.9636e-04, -5.2633e-04, -5.3496e-04,\n",
       "                       -7.8771e-04,  2.3429e-05,  1.1242e-04,  7.2440e-04, -9.9310e-04,\n",
       "                        3.8926e-04, -2.0112e-03,  3.1900e-05,  9.3756e-05,  4.6810e-04,\n",
       "                       -5.5536e-04,  1.7276e-03, -8.6019e-04,  1.2826e-03,  1.3641e-04,\n",
       "                       -4.3474e-04, -1.5502e-06,  5.6739e-04,  1.1563e-03, -9.6280e-04,\n",
       "                       -4.7847e-04,  5.2045e-04,  5.2220e-04,  3.1733e-04,  1.2837e-04,\n",
       "                       -2.7826e-05, -5.8610e-04,  5.4682e-04,  5.4937e-04,  1.5389e-03])),\n",
       "              ('performer.net.layers.5.0.fn.fast_attention.projection_matrix',\n",
       "               tensor([[-0.7588,  0.0648, -1.3984,  ..., -0.8262, -0.6377, -0.3684],\n",
       "                       [-1.0518, -1.8711, -1.1074,  ...,  0.4280,  1.6211, -0.6953],\n",
       "                       [-1.5254,  1.2383, -1.1113,  ..., -0.3523, -0.6992, -0.3367],\n",
       "                       ...,\n",
       "                       [-0.9829, -0.9180, -0.6616,  ...,  0.8599, -2.5449,  0.1344],\n",
       "                       [-2.0352, -0.5088,  0.5176,  ..., -1.5107,  0.7446, -0.5630],\n",
       "                       [-1.3184, -1.3066, -0.0225,  ...,  0.1338,  0.3601,  0.3630]])),\n",
       "              ('performer.net.layers.5.0.fn.to_q.weight',\n",
       "               tensor([[-0.0002, -0.0373, -0.0426,  ..., -0.0002,  0.0130,  0.0314],\n",
       "                       [-0.0486,  0.0202, -0.0165,  ...,  0.0374, -0.0357,  0.0107],\n",
       "                       [-0.0169,  0.0672, -0.0658,  ..., -0.0340, -0.0163, -0.0083],\n",
       "                       ...,\n",
       "                       [ 0.0656, -0.0590,  0.0135,  ..., -0.0498,  0.0475,  0.0287],\n",
       "                       [ 0.0654,  0.0172,  0.0283,  ..., -0.0579, -0.0028, -0.0166],\n",
       "                       [-0.0253, -0.0596,  0.0375,  ...,  0.0471, -0.0536, -0.0589]])),\n",
       "              ('performer.net.layers.5.0.fn.to_k.weight',\n",
       "               tensor([[ 0.0277, -0.0205, -0.0572,  ..., -0.0091, -0.0393,  0.0075],\n",
       "                       [-0.0267, -0.0106,  0.0461,  ..., -0.0151,  0.0215,  0.0609],\n",
       "                       [-0.0547, -0.0435, -0.0530,  ..., -0.0072,  0.0171, -0.0467],\n",
       "                       ...,\n",
       "                       [ 0.0220, -0.0531, -0.0524,  ..., -0.0695,  0.0251, -0.0426],\n",
       "                       [ 0.0246, -0.0037, -0.0375,  ..., -0.0323,  0.0431,  0.0006],\n",
       "                       [ 0.0656,  0.0208,  0.0429,  ..., -0.0069,  0.0605,  0.0473]])),\n",
       "              ('performer.net.layers.5.0.fn.to_v.weight',\n",
       "               tensor([[-0.0311, -0.0629, -0.0047,  ..., -0.0283, -0.0391,  0.0657],\n",
       "                       [-0.0553,  0.0410, -0.0381,  ...,  0.0585,  0.0707,  0.0375],\n",
       "                       [ 0.0517,  0.0067,  0.0496,  ...,  0.0336, -0.0574, -0.0254],\n",
       "                       ...,\n",
       "                       [-0.0186,  0.0548,  0.0461,  ..., -0.0348,  0.0372,  0.0414],\n",
       "                       [ 0.0199, -0.0677,  0.0346,  ..., -0.0118, -0.0474, -0.0377],\n",
       "                       [-0.0176, -0.0497,  0.0061,  ...,  0.0089, -0.0118, -0.0255]])),\n",
       "              ('performer.net.layers.5.0.fn.to_out.weight',\n",
       "               tensor([[-0.0379,  0.0063, -0.0290,  ...,  0.0015,  0.0397,  0.0018],\n",
       "                       [ 0.0088, -0.0106,  0.0218,  ...,  0.0243, -0.0080,  0.0042],\n",
       "                       [ 0.0042,  0.0046, -0.0335,  ...,  0.0377,  0.0123,  0.0131],\n",
       "                       ...,\n",
       "                       [-0.0128,  0.0370, -0.0135,  ...,  0.0413, -0.0176, -0.0152],\n",
       "                       [-0.0305,  0.0318,  0.0212,  ..., -0.0337,  0.0114,  0.0278],\n",
       "                       [ 0.0067, -0.0142, -0.0173,  ...,  0.0181, -0.0087, -0.0189]])),\n",
       "              ('performer.net.layers.5.0.fn.to_out.bias',\n",
       "               tensor([ 8.4367e-03,  6.1427e-03, -3.6232e-02,  2.9997e-02, -6.7970e-03,\n",
       "                        2.9666e-02, -2.7447e-02,  1.5998e-02, -2.9916e-02,  1.3313e-02,\n",
       "                        7.6992e-03,  2.6042e-02, -3.0515e-05, -4.0567e-03,  3.8019e-02,\n",
       "                        3.6584e-02, -1.4997e-02, -3.1546e-02, -1.8860e-03,  3.5448e-02,\n",
       "                        7.5977e-03,  1.3981e-02, -1.5088e-02,  3.3099e-02, -2.9053e-02,\n",
       "                       -3.6446e-02, -1.1797e-02,  1.8419e-02, -1.8057e-02, -3.1567e-02,\n",
       "                       -3.5357e-02,  9.5204e-03, -8.1287e-03, -2.1436e-02, -2.0367e-02,\n",
       "                       -4.4106e-03, -9.0066e-03, -1.4362e-02, -1.6437e-02, -2.6232e-02,\n",
       "                        1.7592e-02,  1.1060e-02,  1.8040e-02,  2.3016e-02,  1.9301e-02,\n",
       "                       -2.3908e-02,  1.2865e-02, -1.5634e-02,  3.2261e-02, -7.2892e-03,\n",
       "                        6.2798e-03,  2.6261e-02, -1.4328e-02,  3.2461e-02, -1.3874e-02,\n",
       "                       -2.7517e-02,  1.5077e-02, -3.9382e-02,  1.7222e-02,  2.3852e-03,\n",
       "                        2.9363e-02,  3.2937e-02, -1.0443e-03, -3.6806e-02,  1.9762e-02,\n",
       "                       -3.3078e-02,  1.3936e-02,  3.0879e-02, -2.3885e-02,  1.8167e-02,\n",
       "                       -9.2873e-04, -3.8469e-02,  3.4283e-02, -1.4754e-02, -3.0743e-02,\n",
       "                       -1.5473e-03, -1.8316e-02, -8.6141e-03,  2.4238e-02, -1.4637e-02,\n",
       "                        2.8517e-02,  2.5418e-02, -6.6328e-03, -1.2808e-03,  2.3302e-02,\n",
       "                       -3.2811e-02,  2.1918e-02, -8.7841e-03, -2.2528e-02,  3.6717e-02,\n",
       "                        3.0056e-02,  1.6714e-02,  1.7795e-02,  9.0279e-03, -3.2502e-02,\n",
       "                       -1.5252e-02,  7.9573e-03,  3.6072e-02, -2.7180e-04, -1.0548e-02,\n",
       "                       -8.7163e-03, -3.8900e-02,  2.8226e-02, -1.9156e-02, -3.0055e-02,\n",
       "                        2.6143e-02,  7.7713e-03, -1.6374e-02, -2.9693e-02, -3.1187e-03,\n",
       "                       -1.0585e-02, -1.3367e-02, -3.1356e-02,  5.2456e-03, -5.9159e-03,\n",
       "                       -1.7092e-02,  1.4056e-02,  2.4488e-02,  3.0243e-03, -1.1861e-02,\n",
       "                        3.0758e-02, -1.8200e-02,  2.0606e-03, -3.8017e-02, -2.9936e-02,\n",
       "                        6.9108e-03, -2.2423e-02,  2.2613e-02, -2.3678e-02, -2.6498e-02,\n",
       "                        2.8213e-02, -3.5077e-02,  6.0630e-03,  3.1142e-02, -1.7907e-02,\n",
       "                       -5.1340e-03,  2.5305e-02,  4.3580e-03,  6.3780e-03,  2.7466e-02,\n",
       "                        3.3289e-02, -1.8520e-02,  4.6609e-03,  9.2507e-03, -3.0165e-02,\n",
       "                        1.9775e-03, -1.6794e-02,  7.5747e-03,  2.4740e-02, -9.5132e-03,\n",
       "                       -3.0585e-02,  3.2115e-02,  1.7862e-02, -2.9046e-02,  2.6995e-02,\n",
       "                        8.4887e-03, -2.0284e-02, -3.4755e-02, -3.5030e-03,  5.8964e-03,\n",
       "                       -2.8026e-02, -2.5813e-02, -3.5259e-02, -1.5639e-02, -1.0427e-02,\n",
       "                       -1.4185e-02, -2.4340e-02,  3.8044e-02,  1.6876e-03, -1.4880e-02,\n",
       "                        1.9622e-02,  2.3637e-02,  1.0716e-02, -3.8125e-02, -3.1074e-02,\n",
       "                        3.6139e-02,  1.7821e-03, -3.4017e-03,  3.5873e-02,  1.3620e-02,\n",
       "                        1.6186e-02,  8.6667e-03, -1.9303e-02,  3.5296e-02, -2.6973e-02,\n",
       "                       -2.4283e-02,  5.4892e-03,  2.4749e-02,  2.5251e-02, -5.9730e-03,\n",
       "                        6.3911e-04, -1.4876e-03,  1.5588e-02,  2.4622e-02, -3.4642e-02,\n",
       "                        3.4650e-02,  1.8341e-02, -2.2811e-02, -2.7746e-02,  3.0565e-03])),\n",
       "              ('performer.net.layers.5.1.norm.weight',\n",
       "               tensor([1.0141, 1.0084, 1.0123, 1.0111, 1.0032, 1.0053, 1.0030, 1.0025, 1.0084,\n",
       "                       1.0115, 1.0068, 1.0173, 1.0063, 1.0056, 1.0058, 1.0050, 1.0063, 1.0164,\n",
       "                       1.0039, 1.0040, 1.0083, 1.0046, 0.9995, 1.0103, 1.0131, 1.0037, 1.0029,\n",
       "                       1.0068, 1.0077, 1.0037, 1.0052, 1.0028, 1.0023, 1.0028, 1.0004, 1.0019,\n",
       "                       1.0097, 1.0057, 1.0051, 1.0054, 1.0074, 1.0149, 1.0028, 1.0061, 0.9998,\n",
       "                       1.0011, 1.0066, 1.0085, 1.0115, 1.0012, 1.0102, 1.0039, 1.0021, 1.0034,\n",
       "                       1.0158, 1.0029, 1.0088, 1.0084, 1.0083, 1.0052, 1.0058, 1.0091, 1.0061,\n",
       "                       0.9984, 1.0111, 1.0069, 1.0110, 1.0029, 1.0028, 1.0059, 1.0139, 1.0036,\n",
       "                       1.0034, 1.0036, 1.0040, 1.0032, 1.0147, 1.0103, 1.0148, 1.0025, 1.0051,\n",
       "                       1.0042, 1.0017, 1.0024, 1.0206, 1.0070, 1.0080, 1.0100, 1.0116, 1.0080,\n",
       "                       1.0067, 1.0035, 1.0019, 1.0088, 1.0062, 1.0085, 1.0065, 1.0098, 1.0142,\n",
       "                       1.0013, 1.0017, 1.0126, 1.0029, 1.0053, 1.0024, 1.0032, 1.0060, 1.0049,\n",
       "                       1.0031, 1.0024, 1.0033, 1.0045, 1.0064, 1.0075, 1.0036, 1.0047, 1.0038,\n",
       "                       1.0040, 1.0149, 1.0112, 1.0089, 1.0146, 1.0027, 1.0034, 1.0058, 1.0238,\n",
       "                       1.0052, 1.0034, 1.0055, 1.0078, 1.0083, 1.0022, 1.0069, 1.0045, 1.0083,\n",
       "                       1.0006, 1.0093, 1.0110, 1.0060, 1.0041, 1.0062, 1.0136, 1.0061, 1.0029,\n",
       "                       1.0050, 1.0045, 1.0066, 1.0049, 1.0038, 1.0020, 1.0082, 1.0019, 1.0031,\n",
       "                       1.0088, 1.0036, 1.0111, 1.0039, 1.0090, 1.0017, 1.0075, 1.0051, 1.0039,\n",
       "                       1.0009, 1.0112, 1.0055, 0.9990, 1.0056, 1.0080, 1.0139, 1.0035, 1.0137,\n",
       "                       1.0040, 1.0069, 1.0085, 1.0008, 1.0092, 1.0053, 1.0002, 1.0063, 1.0062,\n",
       "                       1.0054, 1.0031, 1.0158, 1.0015, 1.0067, 1.0054, 1.0066, 1.0023, 1.0176,\n",
       "                       1.0040, 1.0101, 0.9996, 1.0054, 1.0046, 1.0079, 1.0029, 1.0067, 1.0141,\n",
       "                       1.0052, 1.0112])),\n",
       "              ('performer.net.layers.5.1.norm.bias',\n",
       "               tensor([ 3.3239e-03, -6.0584e-04,  1.8821e-03, -2.4285e-04, -1.8448e-03,\n",
       "                       -5.0956e-04,  9.2014e-04, -6.6041e-04,  2.4392e-03,  1.5812e-03,\n",
       "                        1.4665e-03, -9.4735e-04, -1.4246e-03,  2.6917e-03, -2.4487e-03,\n",
       "                       -6.4175e-04,  1.9585e-04,  2.3517e-04, -2.4588e-03,  4.1378e-04,\n",
       "                       -1.8919e-03,  2.2167e-03,  3.9052e-04,  8.7170e-04,  4.2268e-06,\n",
       "                        1.5892e-03, -2.6511e-04,  7.2959e-04, -2.1338e-04, -8.5380e-04,\n",
       "                       -6.7747e-04, -2.7359e-04, -5.9368e-04,  1.5903e-04, -1.0149e-03,\n",
       "                       -5.1637e-04,  1.1132e-04,  3.8164e-04, -1.4949e-03,  1.3264e-03,\n",
       "                        3.7496e-04,  1.3745e-03,  1.6064e-03,  2.3325e-03, -3.1832e-06,\n",
       "                       -4.0283e-05,  1.6296e-03,  3.5657e-04,  3.0045e-03, -1.2443e-03,\n",
       "                        7.4080e-04,  1.7961e-04,  2.1044e-04,  1.1996e-03,  1.3463e-03,\n",
       "                        1.4088e-03,  1.2838e-03,  6.3760e-04,  5.5991e-04,  1.2563e-03,\n",
       "                        1.8838e-05, -2.7109e-03,  1.7921e-03,  1.1397e-03,  5.5604e-04,\n",
       "                        1.1442e-04,  5.4329e-04, -6.3221e-04,  8.9977e-04, -5.1570e-04,\n",
       "                       -6.7423e-04, -1.0409e-03,  1.1599e-03,  1.3516e-04, -1.2088e-03,\n",
       "                        6.6141e-04, -5.5971e-04, -1.5067e-03,  1.6398e-03,  1.6702e-04,\n",
       "                       -1.5312e-03,  1.0225e-03, -1.9740e-03,  1.9274e-03, -9.4493e-04,\n",
       "                        1.8560e-03, -5.7719e-04, -2.2477e-03, -3.1423e-03,  1.4630e-03,\n",
       "                       -3.1767e-04,  1.8468e-03, -1.7116e-03,  2.5174e-03,  2.6067e-03,\n",
       "                       -2.7078e-03, -1.1627e-04, -1.6807e-03, -2.1345e-03,  1.5876e-03,\n",
       "                        9.4885e-04, -8.7232e-04, -1.3544e-03,  1.4508e-04, -5.0162e-04,\n",
       "                       -1.6828e-03, -3.9730e-04, -8.5386e-04,  2.7366e-04, -6.5559e-04,\n",
       "                       -7.9002e-04, -1.3971e-04,  1.1394e-05,  1.5103e-03,  1.3964e-03,\n",
       "                       -1.0321e-03,  1.5896e-03, -2.2415e-03,  4.6012e-05, -1.9593e-03,\n",
       "                       -1.9940e-03,  3.4623e-03,  8.7217e-04,  8.8108e-04,  9.5768e-04,\n",
       "                       -2.9412e-03,  5.0296e-04, -1.3597e-04,  1.7878e-04,  7.5174e-04,\n",
       "                        1.9129e-03,  7.7999e-04,  1.7802e-03, -1.3675e-03, -2.7528e-03,\n",
       "                       -1.3094e-03, -1.9942e-03,  7.8390e-04, -1.7106e-03,  7.8350e-04,\n",
       "                        1.7840e-03,  1.1271e-03, -1.0076e-03,  9.3530e-04, -6.6414e-04,\n",
       "                        1.0757e-03, -5.9714e-04,  1.3093e-03,  1.4475e-04,  5.7545e-04,\n",
       "                        1.6471e-03,  8.9637e-04,  5.5418e-04,  5.6576e-04, -1.0715e-03,\n",
       "                       -1.6341e-03,  1.2823e-03,  2.4188e-03,  4.9629e-04,  1.3606e-03,\n",
       "                        1.7768e-03, -1.0828e-03,  2.9644e-04,  3.2878e-03, -6.6773e-04,\n",
       "                       -2.0569e-03,  1.3880e-03,  1.7378e-03,  1.7120e-04,  7.5045e-05,\n",
       "                       -9.5634e-04,  1.7728e-04,  1.5120e-03,  3.4718e-04, -1.6786e-03,\n",
       "                        4.0234e-04, -4.8707e-04, -3.2818e-05,  1.1367e-03, -5.4648e-04,\n",
       "                       -3.6272e-04, -4.3503e-04,  7.3038e-04, -8.9557e-04,  2.4049e-03,\n",
       "                       -7.3072e-04, -1.2957e-03,  1.6524e-03,  1.3806e-03,  1.3088e-04,\n",
       "                        8.5824e-04,  4.5642e-04,  2.5738e-04,  1.2307e-03, -9.1504e-04,\n",
       "                       -2.0467e-03, -1.0436e-03,  3.5549e-04,  1.4252e-03,  7.8596e-05])),\n",
       "              ('performer.net.layers.5.1.fn.fn.w1.weight',\n",
       "               tensor([[ 0.0137, -0.0110,  0.0636,  ..., -0.0039, -0.0417,  0.0104],\n",
       "                       [-0.0115, -0.0509,  0.0588,  ..., -0.0542, -0.0667, -0.0384],\n",
       "                       [ 0.0190, -0.0175, -0.0485,  ...,  0.0223,  0.0241, -0.0250],\n",
       "                       ...,\n",
       "                       [ 0.0441, -0.0557,  0.0198,  ..., -0.0688, -0.0271,  0.0082],\n",
       "                       [-0.0427, -0.0077,  0.0311,  ...,  0.0615, -0.0291, -0.0464],\n",
       "                       [-0.0023,  0.0675, -0.0043,  ..., -0.0638,  0.0311, -0.0706]])),\n",
       "              ('performer.net.layers.5.1.fn.fn.w1.bias',\n",
       "               tensor([-3.5859e-02,  2.1791e-02, -5.5076e-02, -4.5337e-02, -1.2553e-02,\n",
       "                       -6.7883e-02, -3.9162e-02, -1.0233e-02,  5.3622e-02,  6.0818e-02,\n",
       "                       -2.2849e-02, -6.0010e-02, -3.0668e-02,  4.1682e-02,  1.6690e-03,\n",
       "                       -3.6743e-02, -5.9543e-02, -6.3459e-02, -4.1088e-02,  3.0064e-02,\n",
       "                        6.2069e-02, -6.2013e-02,  2.8520e-02, -4.1418e-02, -3.9412e-02,\n",
       "                        2.6853e-02,  5.8294e-02, -6.4894e-02,  2.8445e-02,  4.9187e-02,\n",
       "                        3.4739e-02, -2.8978e-02,  7.1851e-02, -4.2609e-02, -6.3599e-02,\n",
       "                        5.0623e-02, -3.8575e-02,  2.9644e-02,  1.1040e-02,  6.4880e-02,\n",
       "                        5.9879e-02,  1.6379e-02,  4.7896e-02,  5.2334e-03, -3.8429e-02,\n",
       "                        5.0637e-02, -6.9810e-03, -6.2699e-02,  3.7715e-02,  4.8147e-02,\n",
       "                       -4.1852e-02,  2.0876e-02, -6.6152e-02,  3.8119e-02,  2.9567e-02,\n",
       "                       -6.6989e-02,  4.4171e-02, -3.3833e-02,  5.0138e-02, -5.4448e-02,\n",
       "                       -6.8716e-03,  2.4806e-02,  3.1077e-02, -4.8649e-02,  3.0959e-02,\n",
       "                       -4.2967e-03,  5.3122e-03,  1.0454e-02,  6.4470e-02, -5.1063e-02,\n",
       "                        5.6278e-02, -4.2368e-02,  5.5289e-02,  6.5688e-02, -2.5689e-02,\n",
       "                       -7.6235e-03,  4.3875e-02, -1.4224e-02,  9.5205e-03,  6.5775e-02,\n",
       "                        6.3028e-02, -4.7062e-02, -8.1942e-03,  5.2795e-02,  5.2190e-02,\n",
       "                        7.1713e-02, -5.7239e-02, -3.5701e-02,  3.4617e-03, -2.9896e-02,\n",
       "                        1.2033e-02, -4.9526e-02,  5.9379e-02, -5.6831e-02,  6.1871e-02,\n",
       "                       -4.2148e-02,  5.1668e-02,  1.4524e-02,  3.3210e-02,  3.7716e-02,\n",
       "                       -8.7458e-03, -4.9235e-02, -2.0384e-02,  3.3006e-02, -3.4804e-03,\n",
       "                        4.3358e-02, -3.1644e-03, -5.4285e-02,  6.5384e-03, -6.0210e-02,\n",
       "                        6.3677e-02, -5.5954e-02,  4.3290e-02,  3.6686e-02,  2.2358e-02,\n",
       "                        1.9162e-02, -9.7368e-03, -4.9789e-02,  2.0222e-02,  2.9533e-02,\n",
       "                        4.7581e-02, -5.7997e-02,  6.2477e-02,  3.4428e-02,  7.2077e-02,\n",
       "                       -1.3028e-02,  6.0246e-02,  2.2436e-02,  1.3762e-03,  2.8559e-02,\n",
       "                        5.5536e-02,  2.8192e-02, -4.6577e-02, -3.5516e-02,  1.4002e-02,\n",
       "                       -7.6011e-03, -3.6649e-02,  4.6408e-02,  1.3868e-02,  2.9297e-02,\n",
       "                       -4.2981e-02,  4.5927e-02,  7.1869e-02,  4.3518e-02, -5.9750e-02,\n",
       "                        6.9165e-02,  6.9977e-02, -2.7105e-02,  7.0807e-03, -1.9102e-02,\n",
       "                       -6.7283e-02,  3.4338e-02, -2.8593e-02,  9.5215e-03,  1.2523e-02,\n",
       "                        3.6241e-02,  6.5938e-02,  2.8011e-02, -4.9983e-02, -2.8928e-04,\n",
       "                        6.4869e-02,  2.1373e-02, -5.1895e-02, -3.4440e-02,  3.5114e-02,\n",
       "                        6.7364e-03,  2.6417e-02, -3.7049e-02, -4.5176e-02, -5.3385e-02,\n",
       "                        4.5578e-02,  5.7191e-02,  5.0490e-02,  2.5351e-02,  5.2528e-02,\n",
       "                        3.8972e-02, -4.2125e-02,  2.6828e-02, -6.4476e-02,  4.8244e-02,\n",
       "                       -3.3500e-02, -5.6662e-02, -6.5596e-02,  4.7886e-02, -5.9208e-02,\n",
       "                       -6.1726e-02,  6.4709e-02,  3.9014e-02, -3.3502e-02,  2.5527e-03,\n",
       "                       -6.1854e-02,  3.1107e-02,  5.0856e-02, -2.9093e-02,  5.5032e-02,\n",
       "                       -3.9607e-02, -6.8811e-02, -2.1636e-03,  8.4628e-03,  5.1869e-02,\n",
       "                       -1.1186e-02,  3.1137e-02, -5.5664e-03,  5.0667e-02,  7.2304e-02,\n",
       "                       -3.1569e-02,  1.6722e-02, -2.8837e-02, -6.4905e-02,  4.0191e-02,\n",
       "                        3.6352e-02,  2.1057e-02, -4.4321e-03, -2.8431e-02, -2.9109e-02,\n",
       "                       -1.3764e-02, -1.9109e-02, -2.7911e-02,  7.5015e-02,  1.4576e-02,\n",
       "                        5.0838e-02, -1.6383e-02,  2.2137e-02,  2.8019e-02,  4.8755e-02,\n",
       "                       -4.1050e-02,  2.1444e-03, -2.3828e-02,  2.8268e-02,  5.7750e-02,\n",
       "                       -8.5577e-03,  2.2536e-02,  6.5900e-02,  3.9160e-03, -4.6015e-02,\n",
       "                        3.1010e-02,  1.3507e-02,  2.6713e-02, -8.2754e-03,  4.0406e-03,\n",
       "                       -8.8835e-03,  5.1582e-02,  2.1844e-02, -1.5488e-02,  5.4803e-04,\n",
       "                        4.3284e-02, -7.8421e-03, -7.2357e-02, -3.9731e-02, -3.0647e-02,\n",
       "                        6.2415e-05, -3.7276e-02, -5.1848e-03,  3.3893e-02,  3.0698e-02,\n",
       "                       -5.1603e-02, -4.0266e-02, -1.0731e-02, -6.2977e-02,  4.9819e-02,\n",
       "                       -7.8744e-03,  2.9305e-02, -6.1586e-02, -7.3794e-03, -3.4484e-02,\n",
       "                        5.0257e-02, -1.1424e-02,  3.7297e-02,  2.3430e-02, -2.8976e-02,\n",
       "                       -3.6882e-02, -5.6577e-02,  2.7543e-03,  2.8372e-02, -7.0217e-02,\n",
       "                        3.1142e-02,  5.9483e-02, -6.1719e-02,  2.9584e-02, -9.9352e-03,\n",
       "                        6.0029e-03,  3.3034e-02, -3.6835e-02, -2.4026e-02, -5.1379e-02,\n",
       "                        2.8764e-02,  4.2482e-02, -9.6461e-03,  3.1597e-02, -1.3090e-02,\n",
       "                       -1.3915e-02,  3.3658e-02,  6.4895e-02, -3.6080e-02, -3.1207e-02,\n",
       "                       -1.0327e-02,  1.8477e-02,  3.6889e-02, -6.6587e-02,  4.7100e-02,\n",
       "                       -6.0656e-03,  6.1350e-02,  1.7248e-02,  5.8684e-03, -3.1385e-02,\n",
       "                       -1.9028e-02, -3.8028e-02,  2.2190e-02, -1.7717e-02, -5.8360e-02,\n",
       "                        1.9246e-02,  5.1110e-02, -4.8116e-02,  2.1609e-02,  4.9753e-02,\n",
       "                       -4.0251e-02, -4.1984e-02, -5.5688e-03,  2.9843e-02,  4.9254e-02,\n",
       "                        3.2271e-02,  1.4808e-02, -3.6112e-02,  3.7197e-02,  1.7594e-02,\n",
       "                        6.8303e-02, -5.2857e-02, -2.2393e-02,  4.1369e-02,  5.0619e-02,\n",
       "                        4.4300e-02,  4.6059e-02, -2.4292e-02,  3.1489e-02, -2.8762e-02,\n",
       "                       -5.2577e-02,  1.5912e-02,  1.2254e-02,  6.0161e-02,  1.8896e-02,\n",
       "                        1.2270e-03,  4.2220e-02, -3.1514e-02,  4.0707e-02, -6.6408e-02,\n",
       "                        2.9855e-02, -4.9304e-02,  9.7380e-03, -5.7142e-03,  3.1839e-02,\n",
       "                        1.9300e-02, -6.9367e-02,  7.1084e-02, -1.3423e-02,  3.8780e-02,\n",
       "                       -3.1341e-02, -5.3244e-02,  1.7977e-02, -4.7908e-03, -6.5306e-02,\n",
       "                       -2.7223e-02,  6.4260e-02,  6.5622e-02, -4.9941e-03, -7.9174e-03,\n",
       "                       -4.7050e-02,  2.4270e-02, -5.8459e-02,  3.5373e-02, -3.3669e-02,\n",
       "                        7.1662e-03, -2.7023e-03, -1.7476e-02,  1.7092e-02,  3.7339e-02,\n",
       "                        6.9503e-02,  3.3498e-02,  1.9216e-02, -6.8016e-02,  6.2925e-02,\n",
       "                        8.6883e-03,  5.0158e-02, -6.4979e-02,  5.7676e-02, -7.1429e-02,\n",
       "                        5.9630e-02, -2.5127e-02,  3.6032e-02, -5.6571e-02,  1.1177e-02,\n",
       "                       -8.1867e-03, -6.3008e-02,  7.9968e-03, -3.0281e-03,  8.7387e-03,\n",
       "                        2.7939e-02,  6.8472e-02,  3.8902e-02, -2.9469e-02,  5.9680e-02,\n",
       "                       -6.3101e-03,  3.4674e-02,  2.2997e-03, -3.3981e-02, -4.2437e-02,\n",
       "                        6.7080e-02,  3.0398e-02,  5.5652e-02,  6.3561e-02,  2.9439e-02,\n",
       "                        3.0768e-02, -1.3897e-02,  4.9717e-02,  1.3543e-03,  1.3806e-02,\n",
       "                       -8.2791e-03, -3.8248e-02, -2.0978e-02,  1.8593e-02,  4.6965e-02,\n",
       "                       -5.4683e-02,  2.4878e-02, -3.0135e-02, -6.6248e-02,  5.2792e-02,\n",
       "                       -3.8658e-02, -2.3320e-02, -1.4641e-03, -4.2949e-02, -2.0805e-02,\n",
       "                       -2.8648e-02, -6.4300e-02, -6.0151e-02, -5.8619e-02, -3.7356e-02,\n",
       "                       -3.7395e-02,  5.3244e-02, -3.8205e-03, -5.4867e-02,  2.7742e-02,\n",
       "                       -2.1366e-03,  4.5432e-02,  3.2494e-02,  7.3208e-02,  4.6428e-02,\n",
       "                       -2.7191e-03,  4.8350e-02,  3.6785e-02,  5.6042e-02, -4.8658e-02,\n",
       "                        5.9512e-02, -4.0623e-02,  3.1668e-02, -5.5516e-02, -6.3305e-02,\n",
       "                        5.5632e-02, -3.8255e-02, -1.5003e-02,  2.5800e-03, -1.8090e-02,\n",
       "                        4.3656e-02, -5.9263e-02,  5.8148e-03,  2.5214e-02,  1.4681e-02,\n",
       "                        6.3469e-02, -1.3776e-02, -7.8025e-03,  9.6316e-03, -6.8573e-02,\n",
       "                       -8.9449e-03,  5.2170e-02,  3.4185e-02,  3.1422e-02,  6.0513e-03,\n",
       "                       -5.6894e-02, -2.0095e-02,  3.2540e-02, -6.7253e-02,  6.8666e-02,\n",
       "                       -3.4475e-02,  5.2452e-02, -5.3854e-02, -1.8595e-02, -3.4162e-02,\n",
       "                       -2.9030e-02,  4.1424e-02, -3.2289e-02, -6.6719e-02, -3.8151e-02,\n",
       "                       -4.9798e-02,  4.2954e-02, -1.7287e-02,  5.1972e-02,  3.4533e-02,\n",
       "                        9.8589e-03, -6.6824e-02, -3.1571e-02, -4.4701e-02, -1.7542e-02,\n",
       "                        2.4912e-02,  2.9546e-02,  1.2256e-02, -3.1612e-02,  5.2864e-02,\n",
       "                        1.7416e-02, -3.2368e-02,  1.3837e-02,  4.7731e-02,  5.5204e-03,\n",
       "                        2.0032e-02, -2.7367e-02,  1.3458e-02,  4.8426e-02, -2.9484e-03,\n",
       "                       -4.0007e-02, -3.0913e-02,  3.2301e-02,  3.4770e-02,  3.3921e-02,\n",
       "                        7.0952e-02, -4.1721e-02,  1.5434e-02, -5.6023e-02, -2.8411e-02,\n",
       "                       -4.3871e-02,  1.4108e-03,  1.5382e-02,  1.0797e-02,  5.8814e-02,\n",
       "                        3.7558e-02, -5.4269e-02, -6.1636e-02,  2.5793e-02,  4.8660e-02,\n",
       "                       -5.7114e-02, -4.4270e-02,  1.2586e-02,  4.8031e-02, -4.8662e-02,\n",
       "                        1.6895e-02,  6.5961e-02,  1.5738e-02,  1.7310e-02,  3.7465e-02,\n",
       "                        3.9719e-02, -5.9329e-02, -1.7597e-02,  4.4036e-02,  5.5699e-02,\n",
       "                       -6.4572e-02, -1.7208e-02, -2.4031e-02, -6.2688e-02, -6.7038e-02,\n",
       "                        2.7992e-02,  4.7713e-02,  6.7865e-02, -2.6709e-02, -4.7115e-02,\n",
       "                        4.4626e-05, -3.1933e-02,  2.0209e-02, -3.7029e-02,  3.4180e-02,\n",
       "                        4.7312e-02,  2.3997e-02,  2.4491e-03,  6.6189e-02,  5.1873e-02,\n",
       "                        2.8441e-03, -2.0449e-02, -3.6382e-02, -4.2788e-03, -5.4205e-03,\n",
       "                        4.9788e-02, -5.9088e-02, -1.9021e-03,  3.9841e-02,  1.5658e-02,\n",
       "                        2.9134e-02, -3.0972e-02,  6.6200e-02,  8.8831e-04,  8.0440e-03,\n",
       "                        1.7802e-02, -5.6026e-02, -1.9287e-02, -3.9337e-02, -5.8896e-03,\n",
       "                        4.1933e-02,  6.1804e-03, -3.5341e-02,  3.7193e-02, -5.6593e-02,\n",
       "                       -2.6780e-02,  5.7062e-02, -1.3224e-02,  6.8247e-02,  4.4227e-02,\n",
       "                       -4.0040e-02, -6.3344e-02, -4.9384e-02,  6.3444e-02, -6.3258e-02,\n",
       "                       -3.7936e-02, -3.2914e-02,  3.0084e-02, -1.2193e-02, -1.7568e-02,\n",
       "                       -6.8921e-02,  4.5034e-02,  2.7299e-02, -2.9026e-02, -4.9549e-03,\n",
       "                       -3.9146e-02, -3.0944e-02,  5.5421e-02,  1.2757e-02, -6.3576e-02,\n",
       "                        4.9354e-02, -3.4854e-02, -4.6196e-02,  2.1189e-02,  6.5273e-02,\n",
       "                       -4.2573e-02, -2.3858e-02,  6.3691e-02, -1.7397e-02,  2.4253e-02,\n",
       "                       -6.3105e-02,  6.3608e-02,  6.2514e-02, -5.1847e-02,  5.3667e-02,\n",
       "                        4.1949e-02,  6.7396e-02, -3.1716e-02,  6.2996e-02,  4.0445e-02,\n",
       "                        4.7950e-04,  2.2552e-02,  6.1927e-02, -3.9621e-02, -5.8358e-02,\n",
       "                        1.7657e-02, -5.1827e-02,  5.8833e-02,  9.0344e-03,  3.7700e-02,\n",
       "                       -2.5973e-02, -1.2822e-02,  1.1029e-02, -2.2074e-02,  5.0647e-02,\n",
       "                       -3.2110e-02, -4.2480e-02,  6.2987e-02, -6.3574e-02, -5.8853e-02,\n",
       "                       -5.9363e-02, -8.3539e-03,  2.4337e-02,  2.2335e-02, -5.1086e-02,\n",
       "                       -3.7907e-02,  3.6118e-02,  9.1188e-03, -1.2085e-02,  4.8942e-02,\n",
       "                        3.9818e-02, -6.4060e-02, -3.4395e-03, -2.3351e-02, -3.1744e-02,\n",
       "                       -9.1943e-03, -5.7592e-03,  6.1676e-02, -9.2347e-03,  2.2132e-02,\n",
       "                       -2.6441e-02,  1.2120e-02,  1.2648e-02, -6.4365e-02, -1.6201e-02,\n",
       "                       -4.5996e-02, -4.1227e-02,  8.2458e-03,  3.9360e-02,  1.4339e-02,\n",
       "                       -5.6418e-02,  6.5461e-02,  1.1782e-02,  1.9359e-02, -3.1835e-02,\n",
       "                       -1.2130e-02,  1.8148e-02,  3.9800e-02, -6.1153e-02, -1.4063e-02,\n",
       "                        3.9167e-02,  2.9514e-02,  5.6679e-02, -2.8227e-02, -5.3497e-02,\n",
       "                        2.2655e-02, -6.0323e-02, -3.5143e-02,  2.8769e-02,  2.6923e-02,\n",
       "                        6.9846e-02,  7.2084e-03,  4.8837e-02, -4.9621e-02,  4.4902e-02,\n",
       "                       -5.3422e-02,  1.8366e-02, -1.5515e-02,  4.2783e-02,  5.9362e-02,\n",
       "                        6.9787e-02,  5.3983e-02, -3.3074e-02, -1.6872e-02, -6.3117e-02,\n",
       "                        3.1180e-03, -3.8988e-02, -3.2311e-02,  5.9221e-02,  2.5696e-02,\n",
       "                        1.7870e-02,  6.7316e-02, -4.3882e-02,  2.4896e-02,  6.3814e-02,\n",
       "                       -6.4077e-02,  1.9052e-02, -5.8019e-02,  4.3645e-02,  4.8247e-02,\n",
       "                       -3.4624e-02,  1.6397e-02,  5.8707e-02,  1.3634e-02, -2.2174e-02,\n",
       "                       -2.4788e-02, -3.9047e-02,  5.8322e-02,  5.6206e-02, -6.3191e-02,\n",
       "                        6.4366e-02, -2.0351e-02, -2.4868e-02,  5.3546e-02, -6.5262e-02,\n",
       "                        3.4370e-02, -6.5842e-03, -5.3867e-02, -4.3320e-02, -2.7116e-02,\n",
       "                       -3.4120e-02,  6.0454e-02,  4.0871e-02,  3.9451e-02, -2.8378e-02,\n",
       "                        2.1319e-03,  3.9881e-02,  3.0777e-02,  6.7917e-02, -5.0765e-02,\n",
       "                        5.7326e-02, -4.3275e-02, -4.7322e-02, -5.3953e-02,  6.2763e-02,\n",
       "                       -4.9437e-02,  2.6253e-04,  3.9906e-02, -7.0234e-02,  8.6209e-03,\n",
       "                       -6.8465e-02,  4.2774e-02, -2.9594e-02,  4.0870e-02,  3.8336e-02,\n",
       "                        4.8845e-02,  4.9301e-02, -4.7518e-02, -5.2184e-02,  2.3782e-02,\n",
       "                        3.7302e-02, -2.3882e-02, -1.9143e-02,  4.6963e-02, -1.0646e-02,\n",
       "                        1.0394e-02,  8.9176e-04,  6.2892e-02, -6.5324e-02,  5.9870e-02])),\n",
       "              ('performer.net.layers.5.1.fn.fn.w2.weight',\n",
       "               tensor([[-0.0084, -0.0346,  0.0187,  ..., -0.0215,  0.0045, -0.0245],\n",
       "                       [ 0.0017, -0.0093,  0.0267,  ...,  0.0121, -0.0327, -0.0330],\n",
       "                       [-0.0132, -0.0095, -0.0127,  ...,  0.0236, -0.0047,  0.0055],\n",
       "                       ...,\n",
       "                       [-0.0331,  0.0039,  0.0075,  ...,  0.0337, -0.0137, -0.0287],\n",
       "                       [-0.0007, -0.0113,  0.0080,  ...,  0.0099,  0.0105, -0.0037],\n",
       "                       [-0.0065,  0.0139,  0.0381,  ...,  0.0056, -0.0307, -0.0189]])),\n",
       "              ('performer.net.layers.5.1.fn.fn.w2.bias',\n",
       "               tensor([ 5.2859e-04, -1.7697e-02,  1.1137e-02,  1.1833e-02, -6.8229e-03,\n",
       "                        3.4248e-02, -1.8726e-03,  1.6226e-03,  3.5994e-02, -4.9712e-03,\n",
       "                        2.9454e-05, -2.0738e-02,  1.2465e-02, -2.6901e-02, -2.1569e-02,\n",
       "                        1.7223e-02,  8.2269e-03, -1.4227e-02,  1.4416e-02,  1.3224e-02,\n",
       "                        2.1068e-02,  2.5954e-03, -5.7824e-04,  2.2195e-02,  1.6736e-02,\n",
       "                        1.6099e-02,  1.5860e-02, -7.0395e-03, -1.8247e-02, -1.1567e-02,\n",
       "                       -3.0400e-02, -1.4146e-02,  2.3882e-02,  3.3404e-02,  2.3426e-02,\n",
       "                        1.5221e-02,  3.1437e-02,  1.3473e-02,  1.5019e-02, -2.3648e-02,\n",
       "                        9.2426e-03, -7.6505e-03,  1.6733e-02, -3.4421e-03, -9.4685e-03,\n",
       "                        7.9573e-03,  1.2317e-02, -3.0002e-02,  5.5866e-03,  2.3641e-02,\n",
       "                       -1.8325e-02,  1.7060e-03, -3.5946e-02, -1.9702e-02, -2.4036e-02,\n",
       "                        2.0332e-02, -8.3388e-03, -3.2025e-02,  3.2230e-02, -2.0742e-02,\n",
       "                        1.8647e-02, -3.5320e-02,  8.3598e-03, -1.7935e-02, -2.9422e-02,\n",
       "                       -2.7650e-02, -3.1994e-02,  1.0784e-02, -2.9127e-02, -1.0654e-02,\n",
       "                       -1.9824e-02,  1.9312e-02,  3.1589e-02, -1.6717e-02, -3.9655e-03,\n",
       "                        3.2958e-03, -3.2513e-02, -3.5982e-02,  4.7065e-03, -1.7763e-02,\n",
       "                        3.5700e-03, -1.2278e-02,  2.8458e-02,  1.2559e-02,  4.2170e-03,\n",
       "                        1.1928e-02,  1.8511e-02, -2.6013e-02,  1.7051e-02, -2.2137e-02,\n",
       "                        8.0448e-03, -3.7749e-02,  2.3149e-02, -1.2310e-02,  9.7902e-03,\n",
       "                        5.9770e-03, -2.0410e-02, -2.5791e-02, -1.0211e-02, -1.2516e-02,\n",
       "                       -1.3201e-02,  5.1205e-03,  4.6593e-04,  2.5689e-02,  1.7526e-02,\n",
       "                       -3.2894e-02, -1.4154e-02,  1.6341e-02, -6.2858e-03,  1.8152e-02,\n",
       "                       -2.7638e-02,  9.7066e-03,  1.6050e-02,  5.3357e-03, -1.3758e-02,\n",
       "                        2.4250e-02, -2.3379e-02,  3.0758e-03,  1.9126e-02,  3.2769e-02,\n",
       "                        6.3286e-03, -1.7831e-02,  3.5454e-02,  3.5020e-02,  2.0835e-02,\n",
       "                       -1.7015e-02, -2.9863e-02, -9.4206e-03,  1.9057e-02,  1.6359e-02,\n",
       "                        2.9496e-02, -1.2225e-02,  2.3779e-02, -1.3793e-02,  2.9473e-03,\n",
       "                       -1.9332e-02,  1.3591e-02, -2.9119e-02,  3.0654e-02,  2.0696e-02,\n",
       "                        7.7871e-04,  2.0436e-03,  1.3220e-02,  2.3998e-03, -3.4669e-02,\n",
       "                       -1.8384e-02,  3.1907e-02,  2.1079e-02,  3.0423e-02,  2.6212e-02,\n",
       "                       -3.4009e-02, -4.6615e-03,  1.5199e-02,  2.9067e-02,  3.2260e-02,\n",
       "                       -2.0954e-02,  1.0232e-02, -3.1628e-02, -1.2656e-02, -2.3375e-02,\n",
       "                       -2.7078e-02, -1.6619e-02,  2.4023e-02, -2.2217e-02,  2.2540e-02,\n",
       "                       -1.2402e-02, -3.0549e-02, -3.1369e-02, -1.3534e-02, -5.0795e-03,\n",
       "                       -1.3345e-02,  2.9419e-02,  1.8663e-02,  3.5851e-02,  8.3981e-03,\n",
       "                        1.5271e-02, -1.1811e-02,  3.7121e-03,  6.8321e-03,  4.6958e-03,\n",
       "                        2.3609e-02,  2.7307e-02,  1.6070e-02,  2.9098e-02, -2.5168e-02,\n",
       "                       -2.6683e-02, -3.2193e-02, -8.8209e-03, -2.7480e-02, -1.4032e-02,\n",
       "                        2.1990e-02,  2.4140e-02, -2.4958e-02,  1.6754e-02, -8.7723e-04,\n",
       "                        1.4158e-02, -5.5679e-03, -2.5034e-03,  1.8474e-02, -6.3250e-03])),\n",
       "              ('norm.weight',\n",
       "               tensor([1.0074, 1.0084, 1.0085, 1.0048, 1.0096, 1.0081, 1.0120, 1.0023, 1.0079,\n",
       "                       1.0095, 1.0042, 1.0127, 1.0115, 1.0169, 1.0105, 1.0055, 1.0012, 1.0086,\n",
       "                       1.0083, 1.0072, 1.0043, 1.0193, 1.0046, 1.0117, 1.0070, 1.0093, 1.0083,\n",
       "                       1.0112, 1.0020, 1.0139, 1.0029, 1.0099, 1.0088, 1.0102, 1.0079, 1.0070,\n",
       "                       1.0072, 1.0052, 1.0040, 1.0153, 1.0018, 1.0137, 1.0056, 1.0111, 1.0165,\n",
       "                       1.0064, 1.0044, 1.0043, 1.0134, 1.0026, 1.0034, 1.0102, 1.0098, 1.0083,\n",
       "                       1.0138, 1.0094, 1.0098, 1.0146, 1.0110, 1.0015, 1.0114, 1.0044, 1.0107,\n",
       "                       1.0064, 1.0074, 1.0111, 1.0056, 1.0031, 1.0100, 1.0143, 1.0057, 1.0108,\n",
       "                       1.0042, 1.0085, 1.0067, 1.0101, 1.0072, 1.0054, 1.0103, 1.0061, 1.0065,\n",
       "                       1.0100, 1.0033, 1.0041, 1.0100, 1.0017, 1.0059, 1.0047, 1.0137, 1.0106,\n",
       "                       1.0124, 1.0102, 1.0046, 1.0038, 1.0060, 1.0094, 1.0152, 1.0103, 1.0120,\n",
       "                       1.0129, 1.0098, 1.0123, 1.0140, 1.0015, 1.0028, 1.0049, 1.0166, 1.0069,\n",
       "                       1.0064, 1.0111, 1.0129, 1.0166, 1.0128, 1.0127, 1.0046, 1.0102, 1.0062,\n",
       "                       1.0151, 1.0039, 1.0054, 1.0107, 1.0126, 1.0071, 1.0078, 1.0099, 1.0103,\n",
       "                       1.0044, 1.0097, 1.0061, 1.0091, 1.0047, 1.0069, 1.0069, 1.0060, 1.0013,\n",
       "                       1.0082, 1.0130, 1.0153, 1.0121, 1.0087, 1.0142, 1.0082, 1.0097, 1.0009,\n",
       "                       1.0077, 1.0076, 1.0094, 1.0093, 1.0129, 1.0073, 1.0070, 1.0089, 1.0089,\n",
       "                       1.0041, 1.0064, 1.0052, 1.0101, 1.0076, 1.0087, 1.0172, 1.0160, 1.0092,\n",
       "                       0.9999, 1.0050, 1.0171, 1.0039, 1.0084, 1.0093, 1.0119, 1.0095, 1.0065,\n",
       "                       1.0117, 1.0078, 1.0122, 1.0107, 1.0162, 1.0063, 1.0073, 1.0049, 1.0055,\n",
       "                       1.0070, 1.0066, 1.0081, 1.0043, 1.0093, 1.0037, 1.0063, 1.0026, 1.0062,\n",
       "                       1.0056, 1.0123, 1.0090, 1.0060, 1.0150, 1.0103, 1.0061, 1.0056, 1.0095,\n",
       "                       1.0098, 1.0056])),\n",
       "              ('norm.bias',\n",
       "               tensor([ 3.9578e-03,  5.0280e-03,  1.4559e-03,  2.6652e-03,  7.6925e-03,\n",
       "                       -6.8610e-03,  9.9726e-03,  1.5531e-05,  5.6556e-03, -5.3394e-04,\n",
       "                       -6.7767e-03,  1.3927e-03, -2.3160e-03,  4.0609e-03,  7.1611e-03,\n",
       "                        2.9993e-03, -2.8006e-03,  4.9228e-03,  4.9792e-05, -3.5376e-03,\n",
       "                       -3.5899e-03,  4.5262e-03,  6.4278e-03, -5.5188e-03,  2.4804e-03,\n",
       "                        1.2756e-03, -1.2341e-03,  5.9732e-03, -4.0158e-03,  7.6250e-03,\n",
       "                        4.8250e-03, -8.1750e-03,  4.7803e-03, -4.5736e-03,  5.6707e-04,\n",
       "                       -4.8531e-04, -5.4025e-03, -2.5919e-03,  3.7082e-03, -6.4797e-04,\n",
       "                        6.7828e-03, -1.5448e-03, -4.0981e-03,  8.6887e-04,  5.1984e-03,\n",
       "                       -4.1005e-03, -5.6933e-03,  1.7040e-03, -1.2204e-03,  3.0292e-03,\n",
       "                        5.0409e-03,  2.6813e-03,  3.0071e-04,  1.3256e-03,  5.7888e-03,\n",
       "                        6.9331e-03,  3.3737e-03, -5.6142e-03, -5.8352e-03,  2.4662e-04,\n",
       "                       -9.5423e-04, -6.4972e-04, -6.2257e-03, -2.9716e-03,  6.6701e-03,\n",
       "                        3.7168e-03, -4.6032e-03,  3.6756e-03, -5.3009e-03,  1.7376e-03,\n",
       "                        4.2176e-03,  3.0924e-03,  7.8089e-04,  5.9845e-03, -2.4835e-03,\n",
       "                        2.3888e-03,  4.2549e-03,  1.2998e-03,  1.6177e-03, -3.6737e-03,\n",
       "                       -1.7802e-03,  8.2325e-03,  8.0622e-03, -5.1896e-03, -4.6464e-03,\n",
       "                       -3.8097e-03,  2.2614e-03,  2.8753e-03,  3.4586e-03,  6.0742e-03,\n",
       "                       -5.4500e-03, -2.4813e-04, -2.0977e-03, -5.1525e-03, -4.8803e-03,\n",
       "                        1.7819e-03,  7.1360e-03, -3.2241e-03, -6.9467e-03,  1.0697e-03,\n",
       "                       -3.1348e-03, -5.0747e-03,  9.5475e-03,  2.7695e-03, -6.8160e-03,\n",
       "                        3.8089e-03, -2.4541e-03,  5.5042e-03, -2.3479e-03,  3.4024e-03,\n",
       "                       -5.5018e-04, -1.0110e-02,  2.7870e-03,  2.0860e-03, -1.2223e-03,\n",
       "                        5.2019e-03, -3.0247e-03, -3.6250e-03,  4.7872e-03,  1.0049e-04,\n",
       "                       -3.4984e-03, -6.2972e-03,  3.5821e-03,  9.3210e-03, -1.1546e-03,\n",
       "                        3.6991e-03, -8.5134e-04, -1.6628e-03,  3.2487e-03, -1.5791e-03,\n",
       "                        2.8069e-03,  3.7375e-03, -2.9508e-03, -3.8005e-03,  5.7998e-03,\n",
       "                       -6.4812e-03, -2.6534e-03, -4.4278e-03,  5.3321e-03,  2.9260e-03,\n",
       "                        7.4908e-03,  4.5955e-03,  9.0491e-04,  8.6646e-04, -6.3552e-03,\n",
       "                       -9.6804e-03, -1.5465e-03, -7.7954e-03, -9.1960e-03, -4.0360e-03,\n",
       "                       -4.2048e-03,  5.5467e-03, -6.8053e-03, -2.4897e-03,  1.1988e-03,\n",
       "                       -3.3579e-04, -3.0396e-03,  5.9922e-03, -2.7081e-03,  8.2536e-03,\n",
       "                       -9.8666e-03,  2.4251e-03,  1.2210e-03, -2.4780e-04, -3.8883e-03,\n",
       "                        4.0833e-03, -1.1131e-03, -3.5578e-03, -4.7857e-03, -7.9438e-04,\n",
       "                       -2.4632e-03, -7.9739e-03,  7.0006e-03, -1.5889e-03, -4.4230e-03,\n",
       "                       -5.7881e-03, -1.0528e-03, -4.0855e-03,  3.8175e-03, -4.6839e-03,\n",
       "                        2.6427e-03,  7.3399e-03,  1.5721e-03,  1.0571e-03, -3.7385e-03,\n",
       "                       -3.1289e-03,  5.9001e-03, -1.8321e-03,  2.2959e-03,  2.7975e-04,\n",
       "                        7.5400e-03,  2.6618e-03, -1.0749e-03,  8.3416e-04,  2.8008e-03,\n",
       "                       -2.1862e-03,  5.1944e-03,  5.5605e-03, -4.4812e-03,  3.0043e-03])),\n",
       "              ('to_out.proj.weight',\n",
       "               tensor([[ 0.0708, -0.0435, -0.0337,  ...,  0.0625,  0.0144,  0.0128],\n",
       "                       [-0.0165,  0.0551, -0.0670,  ..., -0.0623, -0.0127,  0.0560],\n",
       "                       [-0.0559, -0.0211,  0.0096,  ..., -0.0666, -0.0441,  0.0467],\n",
       "                       ...,\n",
       "                       [ 0.0205,  0.0126,  0.0198,  ..., -0.0535,  0.0114, -0.0323],\n",
       "                       [ 0.0515, -0.0223,  0.0019,  ...,  0.0526,  0.0549,  0.0592],\n",
       "                       [-0.0044,  0.0315, -0.0143,  ...,  0.0334,  0.0160,  0.0223]])),\n",
       "              ('to_out.proj.bias',\n",
       "               tensor([ 0.0191,  0.0600, -0.0425,  0.0233,  0.0191,  0.0568, -0.0526,  0.0098,\n",
       "                        0.0469,  0.0440, -0.0648, -0.0356, -0.0043,  0.0596, -0.0167, -0.0389,\n",
       "                        0.0311, -0.0318, -0.0708, -0.0115, -0.0194,  0.0117, -0.0176,  0.0516,\n",
       "                       -0.0267, -0.0626, -0.0682,  0.0290,  0.0380,  0.0022, -0.0256, -0.0053,\n",
       "                        0.0651,  0.0591, -0.0457,  0.0141,  0.0623,  0.0204,  0.0374,  0.0507,\n",
       "                       -0.0257,  0.0402,  0.0201, -0.0560, -0.0056, -0.0376, -0.0553, -0.0157,\n",
       "                        0.0600,  0.0654,  0.0332,  0.0221, -0.0318,  0.0035, -0.0004,  0.0460,\n",
       "                       -0.0379, -0.0432,  0.0598, -0.0237,  0.0328, -0.0150, -0.0196, -0.0685,\n",
       "                       -0.0689, -0.0102,  0.0053,  0.0456, -0.0648, -0.0117,  0.0117,  0.0125,\n",
       "                        0.0215,  0.0471, -0.0433, -0.0272, -0.0583,  0.0392,  0.0320,  0.0401,\n",
       "                        0.0598, -0.0068, -0.0085,  0.0367, -0.0238,  0.0042,  0.0571, -0.0331,\n",
       "                        0.0277, -0.0127,  0.0668,  0.0037, -0.0588, -0.0022, -0.0567,  0.0592,\n",
       "                       -0.0144, -0.0134, -0.0312, -0.0598,  0.0075,  0.0679,  0.0222, -0.0194,\n",
       "                       -0.0408, -0.0280, -0.0568,  0.0231, -0.0058, -0.0142,  0.0320,  0.0208,\n",
       "                        0.0064,  0.0541, -0.0197,  0.0131, -0.0587, -0.0200,  0.0077,  0.0310,\n",
       "                       -0.0364, -0.0397,  0.0319,  0.0152, -0.0660, -0.0358, -0.0492,  0.0371,\n",
       "                        0.0588, -0.0012, -0.0354,  0.0187,  0.0551,  0.0084,  0.0345, -0.0652,\n",
       "                       -0.0413,  0.0389, -0.0367,  0.0568, -0.0047, -0.0374, -0.0561, -0.0269,\n",
       "                       -0.0206,  0.0481, -0.0570,  0.0382,  0.0690,  0.0583, -0.0158,  0.0343,\n",
       "                        0.0366,  0.0072, -0.0096, -0.0068, -0.0009,  0.0236, -0.0134, -0.0159,\n",
       "                       -0.0163, -0.0009, -0.0545,  0.0480,  0.0092,  0.0662, -0.0062,  0.0344,\n",
       "                        0.0517, -0.0190,  0.0569, -0.0718,  0.0272, -0.0362, -0.0330, -0.0210,\n",
       "                       -0.0457, -0.0354,  0.0559,  0.0587,  0.0103,  0.0298, -0.0310,  0.0685,\n",
       "                        0.0211,  0.0025,  0.0050,  0.0006,  0.0422,  0.0122, -0.0617, -0.0506,\n",
       "                        0.0043,  0.0479,  0.0396, -0.0340,  0.0214,  0.0539,  0.0091,  0.0209,\n",
       "                        0.0133, -0.0193, -0.0261,  0.0092,  0.0283, -0.0454,  0.0388, -0.0249,\n",
       "                       -0.0078,  0.0146, -0.0516,  0.0710,  0.0527,  0.0572, -0.0435, -0.0198,\n",
       "                       -0.0307,  0.0053,  0.0302,  0.0318,  0.0645, -0.0170,  0.0564,  0.0123,\n",
       "                        0.0228,  0.0256, -0.0638, -0.0406,  0.0659,  0.0271,  0.0574, -0.0493,\n",
       "                       -0.0271, -0.0162,  0.0179, -0.0174, -0.0608,  0.0537, -0.0125, -0.0141,\n",
       "                        0.0290, -0.0020,  0.0349,  0.0562, -0.0458,  0.0624,  0.0716,  0.0575,\n",
       "                        0.0517, -0.0405, -0.0181, -0.0213, -0.0643,  0.0087,  0.0071,  0.0348])),\n",
       "              ('to_out.feature_extractor.0.weight',\n",
       "               tensor([[[-0.0178, -0.0077, -0.0353],\n",
       "                        [ 0.0130, -0.0231,  0.0306],\n",
       "                        [ 0.0294, -0.0038, -0.0182],\n",
       "                        ...,\n",
       "                        [ 0.0015,  0.0341,  0.0247],\n",
       "                        [-0.0174,  0.0324,  0.0142],\n",
       "                        [ 0.0166,  0.0331, -0.0262]],\n",
       "               \n",
       "                       [[ 0.0361, -0.0257,  0.0314],\n",
       "                        [-0.0058,  0.0350,  0.0003],\n",
       "                        [ 0.0003,  0.0358,  0.0355],\n",
       "                        ...,\n",
       "                        [-0.0016, -0.0339, -0.0193],\n",
       "                        [-0.0296, -0.0360, -0.0144],\n",
       "                        [ 0.0182,  0.0024,  0.0268]],\n",
       "               \n",
       "                       [[ 0.0267, -0.0241,  0.0326],\n",
       "                        [-0.0179,  0.0146, -0.0249],\n",
       "                        [ 0.0348, -0.0105,  0.0292],\n",
       "                        ...,\n",
       "                        [-0.0064, -0.0242, -0.0067],\n",
       "                        [ 0.0080, -0.0208,  0.0044],\n",
       "                        [ 0.0171, -0.0207, -0.0052]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0041, -0.0345,  0.0235],\n",
       "                        [ 0.0151, -0.0355, -0.0332],\n",
       "                        [ 0.0279, -0.0326, -0.0160],\n",
       "                        ...,\n",
       "                        [ 0.0300,  0.0202,  0.0144],\n",
       "                        [-0.0279, -0.0320, -0.0171],\n",
       "                        [ 0.0209, -0.0076, -0.0013]],\n",
       "               \n",
       "                       [[ 0.0062,  0.0059, -0.0081],\n",
       "                        [ 0.0102,  0.0179, -0.0321],\n",
       "                        [ 0.0020, -0.0173, -0.0269],\n",
       "                        ...,\n",
       "                        [ 0.0113, -0.0129,  0.0118],\n",
       "                        [-0.0271, -0.0251, -0.0150],\n",
       "                        [-0.0355, -0.0021, -0.0299]],\n",
       "               \n",
       "                       [[-0.0086, -0.0031,  0.0074],\n",
       "                        [-0.0305, -0.0365,  0.0034],\n",
       "                        [-0.0239, -0.0357, -0.0156],\n",
       "                        ...,\n",
       "                        [ 0.0225,  0.0155, -0.0245],\n",
       "                        [-0.0033, -0.0148,  0.0209],\n",
       "                        [-0.0076,  0.0256, -0.0128]]])),\n",
       "              ('to_out.feature_extractor.0.bias',\n",
       "               tensor([ 2.2112e-02, -1.1097e-02,  3.4486e-02, -7.0697e-03,  3.0176e-02,\n",
       "                        2.9000e-02, -3.3061e-02,  3.2506e-02, -3.6241e-02, -1.3341e-02,\n",
       "                        1.1975e-02, -1.8621e-02,  1.7728e-03,  2.8947e-02, -2.9297e-02,\n",
       "                        2.5540e-02,  3.5090e-02, -2.4736e-02,  3.4310e-02, -3.0740e-02,\n",
       "                        2.1888e-02, -1.5952e-03,  1.0735e-02,  3.5000e-02,  3.2521e-02,\n",
       "                       -1.3701e-02,  1.1589e-02, -3.4581e-02, -2.5177e-02, -9.4878e-03,\n",
       "                       -2.1333e-02, -2.6122e-02, -2.4743e-02,  1.7303e-03,  1.5581e-02,\n",
       "                       -1.3507e-02,  6.3428e-03,  9.6902e-03, -3.0438e-02, -8.4396e-04,\n",
       "                       -1.3543e-02,  1.9619e-02,  1.9613e-02, -1.6103e-02, -1.3079e-02,\n",
       "                       -3.2000e-02, -3.1502e-03, -3.2007e-02,  1.1839e-02,  9.1820e-03,\n",
       "                       -2.9671e-02,  1.5544e-02,  3.5079e-02, -1.8925e-02,  3.1926e-02,\n",
       "                       -2.2049e-02,  1.3851e-02, -5.2360e-03, -1.9768e-02, -2.1396e-02,\n",
       "                       -1.6412e-02, -3.0188e-02, -2.4836e-02,  3.1486e-02,  1.1575e-03,\n",
       "                       -2.8634e-02, -3.3261e-02,  3.0253e-02, -3.4259e-02, -8.2156e-03,\n",
       "                        1.6353e-02,  2.1611e-02,  1.2799e-02, -3.3532e-02,  2.7844e-02,\n",
       "                        1.1221e-02,  4.1149e-03,  2.4735e-02, -5.8931e-03, -3.5129e-02,\n",
       "                        2.1913e-02,  2.7545e-02,  1.3234e-02,  1.6869e-02, -8.5380e-03,\n",
       "                        3.0056e-03, -3.0629e-03,  2.8062e-02,  2.1295e-03, -1.8749e-02,\n",
       "                       -2.1803e-02, -1.0213e-02,  1.3582e-02, -2.1360e-02, -1.4217e-02,\n",
       "                        6.2733e-03,  2.2063e-02,  3.6305e-02,  8.7944e-03, -2.2755e-03,\n",
       "                        1.9452e-02,  1.0898e-02,  1.1086e-02, -2.7102e-02, -2.2908e-02,\n",
       "                        2.2518e-02, -1.0972e-02, -2.4039e-02,  8.2593e-03, -3.2449e-03,\n",
       "                       -3.4536e-02,  1.6147e-02, -1.9131e-02, -2.6502e-02, -1.3558e-02,\n",
       "                        3.0452e-02, -3.5147e-02,  3.3154e-02,  1.3085e-02, -5.0230e-03,\n",
       "                       -9.9245e-03, -2.9823e-02,  2.7406e-02,  2.9090e-02,  3.4896e-02,\n",
       "                       -6.5890e-03,  3.1499e-02,  3.6236e-02,  3.0839e-02,  1.1436e-02,\n",
       "                       -3.2932e-02,  2.6657e-02, -1.4397e-02, -1.2341e-02,  1.5714e-02,\n",
       "                        7.4260e-05, -2.6402e-02, -2.0497e-03,  1.5940e-02,  1.1149e-02,\n",
       "                       -9.0253e-03, -3.8866e-03, -3.7004e-03,  9.5073e-03,  2.0851e-03,\n",
       "                       -2.4973e-02, -1.5631e-02,  2.3169e-02, -2.1328e-02,  1.7878e-02,\n",
       "                        3.0222e-02, -4.5331e-03,  3.7467e-02,  8.0013e-03, -9.6007e-03,\n",
       "                        2.5731e-02,  8.4342e-03, -4.6023e-03,  1.9326e-02, -1.3988e-03,\n",
       "                        2.2131e-02, -3.0647e-02, -6.5852e-03, -1.6299e-03,  2.5308e-02,\n",
       "                       -1.4022e-02, -1.9352e-02, -3.6453e-03,  1.4910e-02, -1.7739e-02,\n",
       "                       -3.2430e-02, -1.4462e-02,  3.1062e-03, -3.3787e-02, -3.4324e-02,\n",
       "                        2.5806e-02,  8.8446e-04,  2.1991e-02,  1.8459e-02, -2.3664e-03,\n",
       "                        2.5575e-02, -2.1175e-02,  1.3472e-02, -2.0737e-02,  3.3151e-02,\n",
       "                       -3.3242e-02, -3.1808e-02, -1.8833e-02, -1.7681e-02,  7.8589e-03,\n",
       "                       -2.1443e-02,  1.5914e-02, -3.3510e-02,  2.7430e-02, -3.0142e-02,\n",
       "                        1.1084e-02,  1.5086e-02, -9.3650e-03, -2.7383e-02,  2.5419e-02,\n",
       "                        1.2496e-02,  2.9879e-02,  1.0940e-02, -2.4946e-02, -3.3566e-02,\n",
       "                       -3.1283e-02,  3.8204e-04, -2.8550e-02, -1.4976e-02,  1.4469e-02,\n",
       "                       -5.5681e-03,  1.3095e-02,  6.6495e-03, -3.3238e-02, -1.3760e-02,\n",
       "                        9.9234e-03,  3.1577e-02,  1.5112e-02, -6.3306e-04,  3.1991e-02,\n",
       "                        1.6919e-02, -1.1892e-02,  3.3901e-02, -2.3667e-02, -2.9340e-02,\n",
       "                       -1.2353e-02,  1.5017e-02,  1.4036e-02,  1.9323e-02, -1.9652e-03,\n",
       "                        1.2939e-02, -2.8509e-04,  9.1477e-03, -1.4052e-02,  1.0966e-02,\n",
       "                       -3.2698e-02, -1.3321e-02,  3.0366e-02, -2.5594e-02, -6.7261e-03,\n",
       "                       -6.3867e-03,  3.1612e-02, -2.3931e-02,  2.4559e-02,  3.3246e-02,\n",
       "                       -4.4126e-03,  2.9861e-04, -2.8064e-02,  7.4333e-03, -5.0202e-03,\n",
       "                        2.3833e-02, -3.0119e-02, -3.4118e-02, -4.8768e-04,  2.2668e-02,\n",
       "                       -1.7743e-02])),\n",
       "              ('to_out.feature_extractor.2.weight',\n",
       "               tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "                       [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "                       [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "                       ...,\n",
       "                       [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "                       [0.9999, 0.9999, 0.9999,  ..., 1.0000, 1.0000, 1.0000],\n",
       "                       [0.9999, 1.0000, 1.0001,  ..., 1.0000, 1.0000, 1.0000]])),\n",
       "              ('to_out.feature_extractor.2.bias',\n",
       "               tensor([[ 9.2637e-07,  9.2637e-07,  9.2637e-07,  ..., -4.8186e-07,\n",
       "                        -4.8186e-07, -4.8186e-07],\n",
       "                       [ 2.9086e-07,  2.9086e-07,  2.9086e-07,  ...,  4.0278e-07,\n",
       "                         4.0278e-07,  4.0278e-07],\n",
       "                       [-7.4413e-06, -7.4413e-06, -7.4413e-06,  ...,  2.9064e-06,\n",
       "                         2.9064e-06,  2.9064e-06],\n",
       "                       ...,\n",
       "                       [-1.0790e-05, -1.0790e-05, -1.0790e-05,  ..., -1.1251e-05,\n",
       "                        -1.1251e-05, -1.1251e-05],\n",
       "                       [ 2.6946e-05,  2.6946e-05,  2.6946e-05,  ..., -1.4842e-05,\n",
       "                        -1.4842e-05, -1.4842e-05],\n",
       "                       [-5.3368e-07, -5.3368e-07, -5.3368e-07,  ...,  1.0217e-05,\n",
       "                         1.0217e-05,  1.0217e-05]])),\n",
       "              ('to_out.feature_extractor.4.position_bias',\n",
       "               tensor([-3.4228e-01,  5.2439e-01, -7.8993e-01,  1.8301e+00, -1.5104e-01,\n",
       "                        1.1410e+00, -6.9989e-01,  2.5670e-01,  6.6337e-01, -2.0235e+00,\n",
       "                       -7.1011e-01, -1.1763e+00,  7.3708e-01,  4.0091e-01, -5.0010e-01,\n",
       "                        4.9643e-01,  2.0760e-01,  9.5228e-01,  2.5065e+00, -6.6710e-02,\n",
       "                        2.6994e+00,  2.0223e-01, -6.2546e-01, -3.1882e-01,  7.8978e-01,\n",
       "                       -1.9093e+00, -8.8913e-01, -1.9326e+00, -6.1595e-01,  5.7162e-01,\n",
       "                       -5.6241e-01, -7.2590e-01, -1.5182e+00, -2.0190e+00,  6.1073e-01,\n",
       "                       -1.6075e-01, -1.6776e+00, -4.2649e-01,  1.3327e+00,  6.7374e-01,\n",
       "                        1.4227e-01, -3.1755e-01,  2.3955e-02,  3.9096e-01,  7.7443e-02,\n",
       "                        1.0305e+00,  8.1573e-01,  1.1610e+00,  7.2114e-01,  4.0349e-01,\n",
       "                       -1.8080e-01, -6.0947e-01, -6.9503e-01, -2.6305e+00, -6.5658e-02,\n",
       "                       -1.0556e+00, -9.7210e-01,  3.5464e-02, -2.3226e-01, -4.0592e-01,\n",
       "                       -1.0103e+00,  4.8145e-01,  6.3626e-01,  7.0945e-01, -1.2639e-01,\n",
       "                        6.4535e-01,  8.0894e-01,  1.1888e+00,  5.5771e-01,  8.7680e-01,\n",
       "                        3.6438e-01,  1.3770e-01, -4.4230e-01, -2.9803e-01, -1.3841e+00,\n",
       "                        1.1106e+00, -2.4123e-01,  3.9467e-01,  2.2789e-01,  1.7385e-01,\n",
       "                       -7.4817e-01, -4.6174e-01, -5.1871e-01,  7.9273e-02,  1.5450e+00,\n",
       "                        4.2273e-01, -6.7182e-01,  6.6317e-01, -5.6723e-01,  1.9666e+00,\n",
       "                       -1.1804e+00, -7.6061e-01, -6.0735e-01,  2.9366e+00,  3.3176e-01,\n",
       "                       -3.7840e-01,  1.3345e-01,  6.3496e-01, -1.1627e+00,  2.5998e+00,\n",
       "                       -7.2029e-01, -7.3613e-01,  9.4065e-01,  8.3179e-04, -1.2625e-01,\n",
       "                        7.5553e-01,  1.1519e+00, -2.0112e-01,  7.9327e-01, -9.7862e-01,\n",
       "                        1.4281e-01, -1.8109e-01,  2.0220e+00, -1.7746e+00, -5.4223e-01,\n",
       "                       -8.1128e-01, -8.2977e-02,  1.3748e+00, -6.6210e-02, -6.1912e-01,\n",
       "                       -2.8828e-01, -9.3645e-02,  1.2851e+00, -1.1475e+00, -7.2714e-01,\n",
       "                        2.0493e+00, -5.5095e-01, -5.9185e-01,  2.8661e-01, -9.6160e-01,\n",
       "                       -3.0050e-01, -2.1490e-01,  1.0492e+00, -1.0045e+00, -3.7239e-01,\n",
       "                        7.4254e-01, -3.6852e-01,  5.1115e-01,  7.2694e-01, -1.4691e+00,\n",
       "                       -3.1584e-01, -5.2474e-02, -7.6656e-02,  1.9539e+00,  1.8139e+00,\n",
       "                       -8.1449e-01, -3.2440e-01, -1.2729e+00,  9.7598e-01,  4.4680e-01,\n",
       "                        1.0805e-01, -1.2653e+00, -1.7247e+00,  4.3562e-01, -2.2291e-02,\n",
       "                        2.4372e-01, -7.2865e-01,  2.4263e+00,  4.7363e-02, -4.5899e-01,\n",
       "                        8.0490e-01, -4.2866e-01,  6.9188e-01, -2.8836e-01, -1.4694e+00,\n",
       "                        1.4142e-02,  3.9772e-01,  2.1350e+00, -6.6538e-02,  2.1465e+00,\n",
       "                        1.4733e+00,  7.3404e-01,  6.4564e-01, -1.3732e+00,  1.3210e-01,\n",
       "                        4.1957e-01,  1.1114e-01, -9.4134e-01, -2.0805e-01,  2.4930e+00,\n",
       "                       -4.4478e-01, -4.6966e-01,  2.5525e-02, -1.2139e+00,  7.7650e-01,\n",
       "                        3.5040e-01,  8.5220e-01,  5.4161e-01,  3.9169e-03,  2.5115e+00,\n",
       "                       -9.6416e-01, -1.0601e+00, -1.5225e+00,  1.8209e+00,  1.3791e+00,\n",
       "                       -3.4978e-02,  1.7171e+00,  3.7245e-01, -3.5597e-01,  1.6334e-01,\n",
       "                        5.8265e-01, -8.8785e-01, -4.2858e-01, -1.0728e-01,  1.5755e+00,\n",
       "                        2.6772e+00,  9.2859e-01,  4.9422e-01, -1.3803e-01,  1.8356e-01,\n",
       "                       -1.9449e+00,  1.6986e+00, -4.0755e-01, -2.8287e-01,  3.4488e-01,\n",
       "                        1.8060e-01,  3.1795e-01,  1.7374e+00,  6.4372e-01, -9.0912e-01,\n",
       "                        1.1700e+00, -1.8139e+00,  7.7293e-01,  9.0893e-02, -1.3822e+00,\n",
       "                       -3.2422e-01,  1.1222e+00, -6.3368e-01,  1.9367e-01,  5.3778e-01,\n",
       "                        9.2406e-01,  1.9381e-01, -5.3508e-01,  2.1771e+00,  2.5281e-01,\n",
       "                       -4.8922e-01, -1.3432e-01,  1.6056e+00, -1.0081e-02, -4.0914e-01,\n",
       "                       -3.5020e-01, -7.0063e-01, -9.2884e-01,  4.6627e-01,  4.2164e-01,\n",
       "                        1.3594e-01,  5.5561e-01,  1.0283e-01,  4.5333e-01,  3.5005e-02,\n",
       "                        1.0128e+00,  1.5964e+00,  6.4121e-01, -9.9709e-01,  4.1516e-02,\n",
       "                        5.9744e-02,  6.8383e-02,  5.4835e-01, -1.9997e+00, -9.2790e-01,\n",
       "                       -1.5749e+00, -1.2995e+00, -4.9220e-01,  1.2516e+00,  1.4206e+00,\n",
       "                        1.6003e-01, -8.0715e-01, -1.0301e+00,  1.1652e+00, -1.7178e+00,\n",
       "                       -2.0963e+00,  9.8776e-01, -2.8080e-01, -5.8176e-01, -7.1949e-01,\n",
       "                       -8.0958e-01,  2.0965e-01,  1.0133e+00, -1.6510e+00, -2.3976e-01,\n",
       "                       -1.4192e+00, -2.6643e-01,  6.6888e-01, -8.6797e-01,  2.1609e-01,\n",
       "                       -8.5587e-02, -1.2227e+00,  1.3554e+00,  7.6372e-01, -1.1941e-01,\n",
       "                        6.4623e-01,  3.8805e-01, -8.8110e-01, -1.1563e+00, -1.3771e+00,\n",
       "                        4.0137e-01,  4.3351e-01,  1.6955e+00,  1.1775e+00, -2.9213e-01,\n",
       "                       -3.2001e-01,  1.3477e+00, -2.2119e+00, -1.1636e+00, -1.9627e+00,\n",
       "                       -7.1985e-01,  2.5193e-01,  9.1517e-01,  2.8805e-01,  5.4109e-01,\n",
       "                        1.4052e+00,  3.0482e-01,  1.4913e+00, -1.0392e+00, -6.7878e-01,\n",
       "                        4.7839e-01, -7.6468e-01,  8.4683e-01, -9.9788e-01,  8.8062e-01,\n",
       "                        1.4096e-01, -2.3944e+00, -6.3542e-01, -3.5869e-02, -4.5638e-01,\n",
       "                       -5.2480e-01, -1.0089e+00, -1.4260e+00,  7.2689e-01, -5.2701e-01,\n",
       "                        9.7508e-01, -1.8147e+00,  7.2901e-01, -5.9825e-01, -6.3450e-01,\n",
       "                       -3.3389e-01,  3.0645e-01,  2.1739e+00,  2.3268e-01, -8.6910e-01,\n",
       "                       -8.5757e-01, -2.4314e-01,  1.2328e+00,  5.9646e-01, -1.4922e-01,\n",
       "                        2.4772e+00,  1.2181e-01,  1.1633e+00,  1.8650e+00, -1.7436e+00,\n",
       "                       -4.7368e-01, -3.5266e-01,  7.2967e-01, -6.5761e-01, -1.7679e+00,\n",
       "                       -8.5268e-01, -8.2623e-02, -7.5359e-01, -1.2643e+00, -1.0217e+00,\n",
       "                       -1.0098e+00,  1.1596e-01,  8.2625e-01, -6.9443e-01,  3.2912e-01,\n",
       "                        6.6757e-01,  3.1689e+00, -5.2073e-02, -4.6548e-02, -3.1907e-01,\n",
       "                        1.0484e+00,  8.2445e-01,  1.4495e+00,  1.6722e+00, -2.3294e-01,\n",
       "                       -8.9974e-01, -9.3008e-01, -5.0332e-01, -2.6699e-02, -4.1758e-01,\n",
       "                        1.0797e+00,  1.1948e+00,  1.1777e+00, -3.0919e-01,  2.5710e+00,\n",
       "                       -6.8392e-01, -1.3183e+00, -1.6422e-01,  7.4629e-01,  8.5675e-01,\n",
       "                       -2.7907e-01,  7.6162e-01, -5.8568e-03,  6.9192e-01, -1.9627e-01,\n",
       "                       -2.2218e+00,  5.6773e-02,  1.7195e+00,  7.0389e-01,  6.4921e-01,\n",
       "                        1.9766e-01, -5.6512e-01, -8.8450e-01,  1.0362e+00, -2.7440e-01,\n",
       "                        6.8804e-01, -2.4769e-01,  1.2865e+00, -1.4340e+00, -1.3367e-02,\n",
       "                        4.5675e-01,  3.9420e-01, -1.2245e+00,  2.5006e-01, -1.6185e-01,\n",
       "                        1.2745e+00, -2.6108e-01,  4.5308e-01,  1.4760e+00, -4.4952e-01,\n",
       "                       -1.0314e+00,  5.3348e-02, -4.8891e-01, -5.8390e-01, -4.6578e-01,\n",
       "                        9.9919e-03,  5.0925e-01,  1.2265e+00,  2.7557e+00,  2.8883e-01,\n",
       "                       -6.0485e-01, -3.6307e-01, -1.9821e+00,  7.8714e-01,  1.0939e-01,\n",
       "                       -1.7182e+00, -1.0653e+00, -1.3683e-01, -3.1460e-01,  1.1111e+00,\n",
       "                        1.2051e+00, -1.0895e+00,  7.4169e-01,  1.6633e+00,  3.9139e-01,\n",
       "                        1.7004e+00, -1.3412e+00, -5.9937e-01,  1.0906e+00, -9.4813e-01,\n",
       "                        7.7186e-01, -7.8668e-01,  1.1831e+00,  1.7480e+00, -7.4018e-01,\n",
       "                        8.9188e-02,  3.7541e-02, -4.1256e-01,  3.2330e-01, -9.3697e-01,\n",
       "                       -1.1912e+00, -6.9353e-01,  1.9897e+00, -2.1213e-01,  1.0987e+00,\n",
       "                       -5.0617e-01, -1.3560e+00,  4.8252e-01,  1.8681e+00,  1.5604e+00,\n",
       "                       -1.6177e-01, -7.0782e-01, -5.0770e-01, -2.3933e-01,  1.3220e+00,\n",
       "                       -2.1814e+00,  5.4466e-01,  1.6663e+00,  1.2907e+00,  1.6023e+00,\n",
       "                       -1.5365e+00,  1.8562e-01,  1.0883e+00,  1.0129e+00, -6.4619e-01,\n",
       "                       -6.8501e-01,  8.0589e-01, -6.4788e-01, -9.4280e-02, -8.9689e-01,\n",
       "                        3.6416e-01,  9.0781e-01,  1.0841e+00, -5.2781e-01, -6.5542e-01,\n",
       "                        1.0666e+00, -6.9784e-01,  6.4200e-01,  6.1432e-01,  2.3727e-01,\n",
       "                        9.5253e-01, -7.0589e-01, -1.3892e+00,  1.0342e+00,  1.6730e-02,\n",
       "                        4.9616e-01,  7.8539e-01,  6.5584e-01, -1.8495e-01,  1.9938e-01,\n",
       "                       -8.2632e-01, -4.9356e-01])),\n",
       "              ('to_out.feature_extractor.4.channel_scale.0.weight',\n",
       "               tensor([[-0.0064, -0.0614, -0.0026,  ..., -0.0387,  0.0439,  0.0611],\n",
       "                       [ 0.0122, -0.0517,  0.0584,  ..., -0.0570, -0.0297,  0.0560],\n",
       "                       [-0.0407, -0.0150, -0.0102,  ..., -0.0514, -0.0459,  0.0535],\n",
       "                       ...,\n",
       "                       [ 0.0365, -0.0419, -0.0063,  ..., -0.0435, -0.0469,  0.0319],\n",
       "                       [ 0.0591, -0.0036,  0.0264,  ...,  0.0524, -0.0186, -0.0228],\n",
       "                       [-0.0380,  0.0623, -0.0536,  ...,  0.0453,  0.0014, -0.0558]])),\n",
       "              ('to_out.feature_extractor.4.channel_scale.0.bias',\n",
       "               tensor([ 0.0550, -0.0140,  0.0089,  0.0278, -0.0177,  0.0406, -0.0414,  0.0429,\n",
       "                       -0.0303,  0.0235, -0.0471,  0.0328, -0.0184, -0.0080, -0.0506, -0.0187,\n",
       "                       -0.0535,  0.0360,  0.0030,  0.0286,  0.0325, -0.0586,  0.0475,  0.0379,\n",
       "                        0.0426,  0.0220,  0.0231,  0.0278,  0.0434,  0.0571,  0.0597,  0.0311,\n",
       "                        0.0443, -0.0382,  0.0420,  0.0486, -0.0289,  0.0400,  0.0196,  0.0167,\n",
       "                        0.0444,  0.0464,  0.0407, -0.0138, -0.0203,  0.0027,  0.0004, -0.0193,\n",
       "                        0.0083,  0.0119, -0.0491, -0.0368,  0.0231, -0.0003,  0.0608, -0.0145,\n",
       "                        0.0199, -0.0603,  0.0209,  0.0395,  0.0591,  0.0372, -0.0263, -0.0136])),\n",
       "              ('to_out.feature_extractor.4.channel_scale.2.weight',\n",
       "               tensor([[ 0.0036,  0.0451, -0.0739,  ...,  0.0718, -0.1081,  0.0681],\n",
       "                       [ 0.1116,  0.0493,  0.0872,  ..., -0.0881, -0.1055,  0.0412],\n",
       "                       [-0.0719,  0.0154,  0.1073,  ..., -0.0412, -0.0069,  0.0649],\n",
       "                       ...,\n",
       "                       [-0.0823, -0.0225, -0.1042,  ...,  0.0859,  0.0838, -0.0642],\n",
       "                       [ 0.0613,  0.0225, -0.0941,  ...,  0.0572,  0.1203,  0.0940],\n",
       "                       [ 0.0466,  0.0206,  0.0801,  ..., -0.0773, -0.0329, -0.0205]])),\n",
       "              ('to_out.feature_extractor.4.channel_scale.2.bias',\n",
       "               tensor([-0.0150,  0.0061, -0.0350, -0.0968,  0.0632, -0.0023,  0.0025, -0.0480,\n",
       "                        0.0594,  0.0550,  0.0516, -0.0485, -0.1189, -0.0895, -0.0774,  0.0790,\n",
       "                        0.0724,  0.0085,  0.0211, -0.0114, -0.1065,  0.1036,  0.0751, -0.0670,\n",
       "                       -0.1056,  0.0193,  0.0523, -0.0919,  0.0826,  0.1100,  0.0544,  0.0881,\n",
       "                       -0.1081, -0.0348, -0.1181,  0.1139, -0.1010, -0.0182, -0.0617, -0.1013,\n",
       "                        0.0599, -0.1208, -0.0964,  0.0263, -0.0611, -0.0520,  0.0034, -0.0632,\n",
       "                        0.1148, -0.0889, -0.0451, -0.0254,  0.0592, -0.0873, -0.1129,  0.0995,\n",
       "                       -0.0636, -0.0453, -0.0736, -0.1144, -0.0928,  0.0700, -0.0347,  0.0875,\n",
       "                       -0.0614,  0.1168,  0.0137, -0.0214, -0.0487, -0.1159, -0.0261,  0.0973,\n",
       "                        0.0085,  0.0994,  0.0717,  0.1037, -0.0922, -0.1080, -0.0937,  0.0894,\n",
       "                       -0.0375, -0.1214, -0.0351,  0.0893, -0.0181,  0.0773, -0.0155,  0.1044,\n",
       "                       -0.0046,  0.0120, -0.1075,  0.0461,  0.0988, -0.1132,  0.1217, -0.1185,\n",
       "                       -0.0351, -0.0524, -0.0439, -0.1158, -0.0090,  0.0362, -0.0282, -0.0416,\n",
       "                       -0.0794,  0.0455, -0.1205,  0.0513,  0.0382, -0.0857,  0.1066,  0.1076,\n",
       "                        0.1173,  0.0183, -0.0026,  0.0148, -0.1100, -0.1226,  0.0887,  0.0031,\n",
       "                        0.0835, -0.0123, -0.0513, -0.0775,  0.0035, -0.1097, -0.1192, -0.0256,\n",
       "                       -0.0006,  0.0617, -0.1097, -0.1069,  0.0032, -0.0559,  0.0550, -0.0005,\n",
       "                       -0.0351, -0.1090,  0.0725, -0.0247,  0.0676, -0.0258, -0.0034, -0.0667,\n",
       "                        0.0088,  0.0700,  0.0775, -0.0067,  0.1159, -0.0084, -0.0617,  0.0176,\n",
       "                        0.0581,  0.0261,  0.0842,  0.0728, -0.0443, -0.0378, -0.0879,  0.0900,\n",
       "                        0.0784,  0.0433, -0.0558, -0.1014, -0.0142,  0.1057,  0.0902, -0.0073,\n",
       "                        0.0661, -0.0275,  0.0020,  0.0117, -0.0987,  0.0275,  0.0892, -0.0548,\n",
       "                       -0.0087, -0.0454, -0.0212,  0.0132, -0.0369, -0.1095, -0.0863, -0.1074,\n",
       "                        0.1006, -0.0287,  0.0873,  0.0366, -0.0865,  0.0748,  0.0024,  0.0405,\n",
       "                        0.0622, -0.0852,  0.0487, -0.0749, -0.0959,  0.0032,  0.1221, -0.0911,\n",
       "                        0.0115,  0.0357, -0.0068, -0.0842, -0.0835, -0.0990, -0.0070, -0.0874,\n",
       "                       -0.0985, -0.0245,  0.1168, -0.1111, -0.0468,  0.0651,  0.0523, -0.0825,\n",
       "                        0.1235,  0.0447, -0.1069,  0.0561, -0.0957, -0.0026,  0.0614,  0.0828,\n",
       "                       -0.1037, -0.1223, -0.1119,  0.0436,  0.0603,  0.0427, -0.0627, -0.0171,\n",
       "                        0.0885, -0.0131, -0.0859,  0.1215,  0.0493,  0.0470, -0.0558,  0.0743,\n",
       "                        0.0178, -0.0874,  0.0507, -0.1023,  0.0573,  0.0608,  0.0800,  0.1031,\n",
       "                        0.1013, -0.0645,  0.0747,  0.0271,  0.0447, -0.0003, -0.0624,  0.1065])),\n",
       "              ('to_out.classifier.0.weight',\n",
       "               tensor([[-1.9726e-03,  7.7531e-05,  5.1569e-04,  ..., -2.7003e-03,\n",
       "                        -6.6376e-04,  1.2089e-03],\n",
       "                       [-2.7236e-03, -1.7110e-03,  9.1205e-04,  ...,  1.0585e-03,\n",
       "                        -1.0141e-03, -2.0183e-03],\n",
       "                       [-1.3955e-03,  1.1611e-03, -1.0165e-03,  ..., -2.3648e-04,\n",
       "                        -1.8115e-03, -2.2397e-03],\n",
       "                       ...,\n",
       "                       [ 2.6743e-03, -1.3327e-03,  1.9023e-03,  ..., -2.7384e-03,\n",
       "                        -2.4213e-04, -1.5871e-03],\n",
       "                       [-8.4417e-04, -1.9688e-03,  5.9484e-04,  ...,  1.8447e-03,\n",
       "                         1.5381e-03, -2.4706e-03],\n",
       "                       [-6.2541e-05, -3.3608e-04,  1.2003e-03,  ...,  2.2266e-03,\n",
       "                        -9.9827e-04, -8.6691e-04]])),\n",
       "              ('to_out.classifier.0.bias',\n",
       "               tensor([ 0.0018, -0.0007, -0.0019,  ..., -0.0025, -0.0012, -0.0020])),\n",
       "              ('to_out.classifier.1.weight',\n",
       "               tensor([0.9983, 0.9991, 1.0023,  ..., 1.0000, 1.0019, 1.0021])),\n",
       "              ('to_out.classifier.1.bias',\n",
       "               tensor([-0.0018, -0.0012,  0.0022,  ...,  0.0002,  0.0017,  0.0022])),\n",
       "              ('to_out.classifier.1.running_mean',\n",
       "               tensor([-0.5450,  1.8050,  1.7589,  ...,  1.0670, -0.2716,  1.3030])),\n",
       "              ('to_out.classifier.1.running_var',\n",
       "               tensor([0.0930, 0.0325, 0.0990,  ..., 0.0508, 0.0117, 0.1346])),\n",
       "              ('to_out.classifier.1.num_batches_tracked', tensor(4965)),\n",
       "              ('to_out.classifier.4.weight',\n",
       "               tensor([[ 0.0279,  0.0238,  0.0176,  ...,  0.0253,  0.0127,  0.0160],\n",
       "                       [-0.0137, -0.0228,  0.0014,  ...,  0.0249,  0.0195,  0.0234],\n",
       "                       [ 0.0133,  0.0331,  0.0211,  ..., -0.0299, -0.0113,  0.0278],\n",
       "                       [-0.0073, -0.0130, -0.0329,  ...,  0.0067, -0.0037, -0.0047],\n",
       "                       [ 0.0110, -0.0053,  0.0004,  ..., -0.0025,  0.0159, -0.0238],\n",
       "                       [-0.0177, -0.0323, -0.0165,  ..., -0.0128,  0.0132, -0.0255]])),\n",
       "              ('to_out.classifier.4.bias',\n",
       "               tensor([-0.0022, -0.0293, -0.0248,  0.0168, -0.0086,  0.0229]))]),\n",
       " 'optimizer_state_dict': {'state': {52: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 3.8048e-08, -2.4945e-08,  3.3466e-08,  4.6124e-07, -3.1701e-08,\n",
       "             3.1224e-08,  2.7481e-08,  2.6102e-07, -4.2863e-08, -9.0851e-08,\n",
       "            -8.4575e-08,  1.7856e-08,  1.1731e-08,  9.1762e-08,  8.3276e-08,\n",
       "             1.0605e-07,  9.3911e-08,  1.1010e-07, -1.7844e-08,  4.1406e-08,\n",
       "             4.4576e-08,  9.3018e-08,  2.1049e-07,  6.1447e-08,  5.2285e-08,\n",
       "             1.6937e-08,  1.8038e-07,  9.6257e-08,  3.2464e-08,  5.9316e-09,\n",
       "             1.5357e-07,  1.8300e-07,  3.0276e-08,  1.6904e-08,  2.6065e-07,\n",
       "             3.2665e-07, -8.0663e-08,  5.3290e-08,  4.6181e-08,  6.9383e-08,\n",
       "             9.4821e-08,  4.3863e-08,  1.5251e-07,  2.7221e-09,  4.8497e-08,\n",
       "            -4.3510e-09, -4.8541e-09, -7.7243e-08,  2.7074e-07,  1.6495e-08,\n",
       "             2.8345e-07,  2.0790e-08,  2.3131e-08,  1.0679e-07,  2.6091e-08,\n",
       "             3.2140e-08,  4.6645e-08,  8.0557e-09,  2.5048e-07,  1.8571e-07,\n",
       "             4.7496e-08,  7.0377e-08,  9.9701e-08,  2.0988e-08,  5.0880e-07,\n",
       "            -1.2056e-07,  4.1624e-08, -7.6515e-10,  1.5875e-07, -5.0852e-09,\n",
       "             2.1908e-08,  6.0947e-08,  1.7567e-07,  3.2108e-09, -1.8947e-09,\n",
       "             2.5518e-08, -3.3961e-08,  8.9183e-08,  3.4489e-08,  3.9646e-08,\n",
       "             3.1393e-08,  3.9428e-08,  4.9819e-08, -2.2794e-09,  1.8610e-08,\n",
       "             5.2584e-07,  1.2083e-07, -1.0463e-08, -9.6568e-09,  2.8569e-08,\n",
       "             3.9024e-07,  7.3439e-08,  8.9193e-08,  1.3179e-07,  1.3575e-07,\n",
       "            -5.5826e-08,  2.9129e-07, -5.5357e-08,  5.0108e-07,  3.3627e-08,\n",
       "             1.1274e-07,  9.7041e-08,  1.3125e-07,  2.1712e-07,  1.1482e-07,\n",
       "             1.2066e-07, -1.8201e-08, -4.9028e-10,  1.0692e-07,  2.2005e-07,\n",
       "             3.6856e-08,  1.3144e-08, -2.0837e-09,  1.2963e-08,  4.5518e-08,\n",
       "             1.6047e-07,  2.0765e-08,  6.0384e-08, -3.5525e-09,  1.2995e-07,\n",
       "             9.0198e-08,  5.5194e-09,  6.7054e-08,  5.5581e-08,  9.2394e-08,\n",
       "             9.6312e-08,  5.1195e-08, -4.8864e-08,  7.4675e-09,  4.2818e-08,\n",
       "             6.4242e-08,  3.3463e-08,  1.0000e-07,  8.9027e-08,  3.3547e-07,\n",
       "             1.4640e-07,  3.3617e-09,  2.0280e-08,  2.7645e-09,  2.2591e-07,\n",
       "             7.8399e-08,  2.8876e-07,  1.0654e-07,  2.9156e-07,  5.2075e-08,\n",
       "             9.4184e-08,  6.8867e-08, -4.8590e-08,  7.3065e-08,  8.6325e-08,\n",
       "             1.9770e-07,  6.1321e-08,  1.4934e-07,  3.1490e-07,  1.4744e-07,\n",
       "             1.6434e-07,  1.7378e-07, -2.4746e-08, -7.5763e-09,  2.0655e-08,\n",
       "            -1.1483e-08,  2.7473e-07,  1.3865e-07, -3.7215e-08,  2.5374e-07,\n",
       "             2.3431e-07,  6.8191e-08,  2.9074e-08,  1.4644e-07,  3.6317e-08,\n",
       "             3.5701e-08,  1.2372e-07,  1.9915e-07,  1.3265e-07, -1.9371e-08,\n",
       "             1.0304e-07,  1.1360e-07,  8.4041e-08,  5.9022e-08,  1.0759e-07,\n",
       "             1.9420e-07,  1.3579e-07,  2.0097e-07,  5.3974e-08,  4.4742e-08,\n",
       "             1.1891e-07, -5.8324e-08,  1.0536e-08,  7.1927e-08, -3.0439e-08,\n",
       "             5.7081e-09, -3.5955e-08,  3.8769e-08,  2.5965e-09,  6.0432e-07,\n",
       "             5.5517e-08,  1.2528e-07,  6.5673e-10, -1.2388e-07, -1.6320e-08]),\n",
       "    'exp_avg_sq': tensor([8.8106e-15, 9.5790e-15, 9.0493e-15, 2.6059e-13, 1.0568e-14, 4.1121e-15,\n",
       "            3.3229e-14, 4.5677e-14, 2.9119e-14, 3.1093e-14, 1.6732e-14, 9.2687e-15,\n",
       "            1.0688e-13, 5.1396e-15, 2.6534e-14, 4.5150e-14, 1.1326e-14, 3.1649e-14,\n",
       "            4.8964e-14, 2.3960e-15, 5.7229e-15, 9.0200e-14, 1.6220e-13, 1.8619e-15,\n",
       "            3.8815e-14, 3.8223e-15, 3.1587e-14, 1.1818e-14, 1.3877e-13, 3.4490e-16,\n",
       "            1.2367e-13, 1.6232e-13, 7.5336e-16, 3.5718e-15, 6.8745e-14, 5.5862e-14,\n",
       "            2.0024e-14, 4.7730e-15, 4.9164e-14, 4.5546e-15, 3.0148e-14, 1.1712e-14,\n",
       "            2.1510e-13, 9.1734e-15, 3.8296e-15, 2.6498e-15, 1.0871e-14, 1.1557e-14,\n",
       "            2.8385e-14, 8.4823e-15, 2.1920e-13, 7.2743e-16, 5.1618e-16, 1.2759e-14,\n",
       "            1.6661e-15, 6.3570e-15, 8.1594e-15, 2.2722e-15, 4.9362e-14, 1.1054e-13,\n",
       "            3.3695e-15, 1.9589e-14, 5.1868e-14, 3.5153e-15, 2.3159e-13, 2.9359e-14,\n",
       "            4.8895e-14, 7.6093e-16, 1.3248e-14, 6.1655e-15, 3.1599e-15, 3.7971e-14,\n",
       "            2.9377e-14, 3.8086e-15, 1.8594e-15, 5.8268e-15, 1.9703e-14, 2.9918e-14,\n",
       "            1.2018e-14, 5.9634e-15, 3.3961e-15, 1.5769e-14, 6.9256e-14, 1.9357e-14,\n",
       "            2.9893e-15, 1.6128e-13, 1.6105e-14, 8.3038e-17, 7.7545e-15, 2.7329e-15,\n",
       "            7.4112e-14, 1.2360e-14, 7.8193e-15, 1.0462e-14, 3.1745e-14, 1.3746e-15,\n",
       "            1.9438e-14, 7.5499e-15, 1.2620e-13, 3.8863e-15, 1.9286e-14, 4.4962e-15,\n",
       "            7.0750e-15, 1.2687e-13, 1.2200e-14, 6.0798e-15, 5.4252e-16, 7.8227e-16,\n",
       "            9.2330e-14, 2.1518e-14, 2.1450e-15, 2.9619e-15, 2.9908e-14, 1.0392e-15,\n",
       "            5.9600e-14, 5.3109e-14, 3.6556e-15, 9.1033e-15, 4.2795e-15, 3.7918e-14,\n",
       "            3.9618e-14, 1.6651e-15, 4.7659e-14, 2.6370e-15, 9.8920e-14, 1.3992e-14,\n",
       "            3.9864e-15, 2.1857e-14, 9.2099e-15, 2.6427e-15, 1.0483e-14, 3.7975e-14,\n",
       "            1.0847e-14, 9.1479e-15, 4.7832e-14, 2.4590e-14, 1.1726e-14, 1.0147e-14,\n",
       "            1.1969e-15, 2.6261e-13, 2.6237e-14, 2.6104e-14, 5.6971e-14, 4.2385e-13,\n",
       "            7.3356e-15, 1.8534e-14, 2.8640e-15, 2.4402e-14, 8.9023e-15, 1.5395e-14,\n",
       "            1.1932e-14, 3.3974e-14, 2.5913e-14, 1.8640e-13, 3.2773e-14, 2.7696e-14,\n",
       "            1.2142e-13, 5.3794e-14, 2.4587e-15, 9.9196e-15, 3.5512e-15, 5.7666e-14,\n",
       "            6.5964e-14, 2.7909e-15, 3.1870e-13, 3.3660e-14, 1.1121e-13, 1.3956e-15,\n",
       "            2.5940e-14, 3.8050e-15, 8.9192e-15, 6.3929e-14, 9.1305e-14, 3.5237e-14,\n",
       "            1.0867e-14, 2.2032e-14, 1.5329e-13, 2.1299e-14, 3.8226e-15, 9.1719e-14,\n",
       "            1.4572e-13, 1.5904e-14, 3.4158e-14, 2.3343e-14, 2.4633e-15, 1.9592e-14,\n",
       "            6.6854e-15, 1.7202e-14, 5.3944e-15, 8.3959e-15, 2.8192e-15, 1.0982e-15,\n",
       "            5.7569e-15, 1.3657e-14, 6.0122e-13, 5.5019e-15, 4.7070e-15, 2.8712e-15,\n",
       "            6.2357e-13, 2.4354e-14])},\n",
       "   53: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 1.0637e-07, -8.2539e-08, -7.1896e-08,  2.3078e-07, -1.2340e-08,\n",
       "             3.8236e-08,  6.6936e-09, -1.6912e-07, -3.7644e-08, -2.5131e-08,\n",
       "             8.2621e-08, -5.3784e-08, -3.3109e-08,  8.0509e-08, -1.3812e-07,\n",
       "             6.8660e-08,  1.0415e-07,  1.1704e-07, -1.6445e-08,  2.2032e-07,\n",
       "            -5.5732e-08, -8.0556e-08, -8.1580e-08,  2.0943e-08,  3.2391e-08,\n",
       "             3.6178e-08, -9.7815e-08,  1.2951e-07,  4.5291e-08,  2.0060e-08,\n",
       "            -1.8624e-07, -2.4555e-07,  9.9838e-08,  3.6683e-08, -1.5094e-07,\n",
       "             1.7240e-07,  6.4507e-08, -1.0159e-07, -1.8397e-08,  6.1002e-09,\n",
       "            -1.8222e-08, -2.7713e-08, -7.5016e-08,  3.1998e-08, -1.7747e-07,\n",
       "            -7.3603e-08,  9.6247e-08, -5.7107e-08, -1.8817e-07,  1.8583e-08,\n",
       "            -4.5305e-08, -6.2269e-09, -1.2768e-07, -2.4046e-07,  6.0132e-09,\n",
       "            -7.3627e-08, -7.8930e-08, -9.2950e-08, -7.9080e-08, -9.6406e-08,\n",
       "            -3.9311e-08, -9.6122e-08, -1.0576e-07, -1.0049e-07,  2.1950e-07,\n",
       "            -1.5605e-07, -4.5801e-08, -5.1117e-08,  2.7064e-07, -1.6659e-08,\n",
       "             4.8042e-08,  1.0891e-08,  1.7298e-07,  2.8545e-08,  3.7826e-09,\n",
       "             6.6242e-08, -2.6681e-08,  1.3629e-07,  7.9523e-08,  1.4722e-07,\n",
       "            -6.1912e-08, -2.7812e-08, -2.7270e-08,  2.9280e-08, -9.8576e-09,\n",
       "             1.8475e-07, -1.4939e-07,  1.8971e-07, -6.4046e-08, -1.4712e-08,\n",
       "            -2.0561e-07,  9.1103e-08,  1.8882e-07,  6.4962e-08, -8.9744e-08,\n",
       "             1.5197e-08, -1.1253e-07,  9.4643e-08, -2.6731e-07,  3.6062e-08,\n",
       "             8.8656e-08,  2.8567e-08, -4.5257e-08, -6.4238e-08, -1.2021e-08,\n",
       "             1.3855e-07,  5.3535e-08, -4.3957e-08, -6.8410e-08, -1.7451e-07,\n",
       "            -8.9117e-08,  1.7037e-07,  2.3513e-08, -4.2320e-08,  2.3202e-08,\n",
       "             2.9563e-08,  6.0259e-08,  1.1078e-07, -1.4227e-07,  2.5641e-08,\n",
       "             7.5050e-08,  1.3149e-07,  1.7250e-08,  6.0278e-08,  5.9438e-08,\n",
       "            -9.1135e-08,  4.0867e-08,  5.9975e-08,  1.0183e-07, -2.1076e-07,\n",
       "            -8.6486e-08,  5.9930e-08,  9.1369e-08, -5.9747e-08,  2.2050e-07,\n",
       "             4.1627e-08, -9.3472e-11,  2.3095e-08, -5.6812e-09,  7.1884e-08,\n",
       "             1.2725e-07,  2.4179e-08,  1.3937e-08,  1.8683e-07,  7.3420e-08,\n",
       "            -6.4962e-08, -1.2336e-07,  4.0247e-08,  7.9875e-08, -1.1914e-07,\n",
       "             2.0629e-07, -6.5340e-08, -1.1518e-07,  1.6765e-07,  9.7686e-08,\n",
       "             2.9662e-07, -9.0041e-08,  1.4212e-08,  4.1356e-08, -7.6531e-09,\n",
       "            -2.4859e-07,  1.5811e-07, -1.1264e-07,  1.5374e-07, -7.7151e-08,\n",
       "            -1.5767e-07, -5.5630e-08, -1.5582e-07, -6.5226e-08,  7.2821e-08,\n",
       "             8.7022e-09,  6.5877e-09, -5.4574e-08,  1.1079e-07,  9.9502e-08,\n",
       "            -7.5256e-08,  7.7112e-08, -9.7239e-09,  2.0471e-08,  7.4569e-08,\n",
       "             1.1383e-07, -1.5597e-07,  6.7415e-08, -2.7389e-08, -9.9979e-08,\n",
       "             1.6986e-07, -1.3700e-08,  5.4606e-08, -6.4733e-08, -7.5014e-08,\n",
       "             1.1211e-07,  6.0716e-08, -1.2144e-07, -6.6509e-08,  2.2511e-07,\n",
       "            -5.2176e-08,  9.8044e-08, -1.0904e-07, -6.6503e-08, -3.2619e-08]),\n",
       "    'exp_avg_sq': tensor([4.0898e-14, 1.9180e-14, 1.3153e-13, 8.3718e-14, 2.4975e-14, 1.1370e-13,\n",
       "            6.4271e-14, 2.7278e-14, 5.4814e-14, 2.3694e-14, 1.9588e-14, 5.6341e-15,\n",
       "            9.3160e-14, 6.2720e-14, 3.6866e-14, 3.8663e-14, 1.3493e-13, 1.9157e-14,\n",
       "            4.8834e-14, 3.2652e-14, 2.0447e-14, 7.3608e-14, 1.2229e-13, 1.7222e-14,\n",
       "            3.3550e-14, 1.0830e-14, 2.2759e-14, 1.2274e-14, 4.9176e-14, 1.5217e-14,\n",
       "            1.7507e-14, 1.6758e-13, 2.4276e-14, 1.7965e-14, 2.1816e-14, 1.3744e-14,\n",
       "            6.3237e-14, 5.8658e-14, 7.2362e-14, 1.7038e-13, 1.4430e-14, 1.7238e-14,\n",
       "            6.3353e-14, 2.1662e-14, 1.7498e-14, 1.3405e-14, 3.0937e-14, 1.5401e-14,\n",
       "            1.0278e-14, 8.7789e-15, 1.4858e-13, 2.1886e-14, 1.2360e-14, 6.6971e-14,\n",
       "            1.1101e-13, 1.2791e-14, 3.6024e-14, 7.1320e-14, 1.8485e-14, 1.8689e-14,\n",
       "            1.4144e-13, 2.0071e-14, 4.8656e-14, 8.0888e-14, 4.0226e-14, 1.4416e-13,\n",
       "            9.3692e-14, 6.0627e-15, 1.2121e-13, 1.8604e-14, 3.3923e-14, 4.1748e-14,\n",
       "            1.4526e-13, 9.9382e-15, 1.2246e-14, 2.7220e-14, 3.0181e-14, 4.0497e-14,\n",
       "            3.6245e-14, 1.2315e-13, 3.6434e-14, 1.5566e-14, 1.8308e-14, 2.4352e-14,\n",
       "            5.9523e-14, 1.5963e-13, 3.8800e-14, 1.5609e-14, 3.2689e-14, 1.2383e-14,\n",
       "            1.0930e-13, 1.5806e-14, 4.3786e-14, 2.0453e-13, 1.6364e-14, 2.5948e-14,\n",
       "            2.7413e-13, 1.3287e-14, 3.9685e-13, 4.5654e-14, 1.0568e-14, 3.8880e-14,\n",
       "            1.0532e-13, 7.8897e-14, 1.4371e-13, 8.9774e-15, 9.2063e-15, 1.5693e-14,\n",
       "            1.8072e-14, 1.3121e-14, 4.5316e-14, 1.5176e-14, 5.8211e-14, 7.7015e-14,\n",
       "            8.8960e-14, 6.2669e-14, 4.5784e-15, 4.0145e-14, 2.7755e-14, 1.3533e-14,\n",
       "            4.4156e-14, 3.2952e-14, 4.2521e-14, 1.5784e-13, 9.1260e-14, 9.8196e-14,\n",
       "            5.2340e-14, 6.1757e-14, 5.3076e-14, 2.1767e-14, 1.3941e-14, 1.5508e-14,\n",
       "            1.8980e-14, 1.3075e-14, 1.7653e-14, 4.5536e-15, 2.3742e-14, 1.4514e-14,\n",
       "            2.5195e-14, 2.4995e-13, 1.3977e-13, 1.4053e-13, 6.0257e-15, 1.4790e-13,\n",
       "            1.3242e-13, 1.6606e-14, 1.6468e-13, 2.6248e-14, 1.0631e-14, 2.1316e-14,\n",
       "            1.4526e-14, 3.4125e-14, 1.4395e-14, 9.3510e-14, 2.4667e-14, 1.0572e-13,\n",
       "            5.4622e-14, 2.8613e-14, 4.7629e-14, 2.9146e-14, 9.1440e-14, 3.8406e-14,\n",
       "            4.9152e-14, 3.1913e-14, 1.9246e-13, 1.6163e-14, 4.2031e-14, 4.2922e-14,\n",
       "            2.4467e-13, 9.8371e-14, 1.0287e-14, 5.5580e-14, 3.1021e-14, 4.2172e-14,\n",
       "            3.4182e-14, 7.2228e-15, 7.0440e-14, 3.6045e-14, 1.9006e-14, 5.6920e-14,\n",
       "            6.5252e-14, 2.3573e-14, 1.2553e-13, 3.7905e-14, 1.9633e-14, 2.0900e-14,\n",
       "            3.3111e-14, 2.4117e-14, 3.3181e-14, 1.0024e-14, 6.5093e-14, 1.4443e-14,\n",
       "            8.6908e-14, 1.3073e-14, 1.9759e-13, 1.2537e-14, 1.2761e-13, 3.5894e-14,\n",
       "            1.5704e-13, 4.7226e-14])},\n",
       "   54: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 3.6656e-09,  2.6029e-09, -2.7533e-10,  ...,  5.7356e-09,\n",
       "              1.7108e-08, -8.3746e-09],\n",
       "            [ 1.7098e-09,  4.6501e-09,  6.2324e-09,  ...,  4.4324e-09,\n",
       "              1.0836e-08, -6.3979e-09],\n",
       "            [-3.4467e-09, -1.4313e-08, -1.9410e-08,  ..., -7.1576e-09,\n",
       "             -1.5501e-08,  5.0033e-09],\n",
       "            ...,\n",
       "            [ 2.9864e-09,  1.0477e-08,  6.5589e-09,  ...,  7.3814e-09,\n",
       "              2.7252e-08, -1.5085e-08],\n",
       "            [-1.1752e-09, -1.8382e-09, -2.0694e-09,  ..., -1.4797e-09,\n",
       "             -6.8361e-09,  4.0856e-09],\n",
       "            [-3.0102e-09, -6.7984e-09, -3.2221e-09,  ..., -3.0123e-09,\n",
       "             -1.4216e-08,  5.4142e-09]]),\n",
       "    'exp_avg_sq': tensor([[8.3897e-17, 6.2357e-16, 1.8334e-16,  ..., 3.2882e-16, 4.4147e-15,\n",
       "             1.0333e-15],\n",
       "            [1.6188e-16, 1.3323e-15, 2.7413e-16,  ..., 5.4735e-16, 8.7910e-15,\n",
       "             2.0297e-15],\n",
       "            [1.8282e-16, 1.6632e-15, 4.3994e-16,  ..., 7.1951e-16, 1.1415e-14,\n",
       "             2.5957e-15],\n",
       "            ...,\n",
       "            [1.0972e-17, 7.1240e-17, 1.3574e-17,  ..., 3.1300e-17, 4.9967e-16,\n",
       "             1.3127e-16],\n",
       "            [2.8736e-17, 2.6257e-16, 4.1023e-17,  ..., 9.9838e-17, 1.7041e-15,\n",
       "             3.8239e-16],\n",
       "            [3.4900e-17, 2.2821e-16, 3.4465e-17,  ..., 8.3842e-17, 1.6042e-15,\n",
       "             3.3903e-16]])},\n",
       "   55: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 6.2317e-09,  2.3605e-09, -1.2892e-08,  ..., -3.6549e-10,\n",
       "              7.9082e-09,  2.4065e-08],\n",
       "            [ 1.9447e-08,  1.9416e-08,  7.1162e-09,  ..., -1.9731e-08,\n",
       "              2.6203e-08, -1.0993e-08],\n",
       "            [-1.5299e-08, -2.5957e-08, -2.9489e-08,  ...,  1.5993e-08,\n",
       "             -2.8816e-08,  4.5098e-08],\n",
       "            ...,\n",
       "            [ 9.0626e-10,  3.9305e-09,  2.5040e-09,  ...,  1.0673e-09,\n",
       "              6.8103e-12,  5.6865e-09],\n",
       "            [ 2.2042e-09, -6.4826e-10, -3.2565e-09,  ..., -7.2965e-09,\n",
       "             -9.0227e-09,  1.8060e-09],\n",
       "            [-8.7097e-10,  5.3954e-09,  7.8582e-09,  ...,  7.9992e-09,\n",
       "              1.7094e-08, -1.0109e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.7206e-16, 7.6194e-16, 4.6201e-16,  ..., 3.5562e-16, 2.5541e-15,\n",
       "             1.6751e-15],\n",
       "            [5.1146e-16, 9.9150e-16, 1.7109e-15,  ..., 2.2418e-15, 7.8955e-15,\n",
       "             4.0619e-15],\n",
       "            [4.5523e-16, 9.8771e-16, 1.4596e-15,  ..., 2.1577e-15, 5.6287e-15,\n",
       "             4.8235e-15],\n",
       "            ...,\n",
       "            [3.1131e-17, 3.0180e-17, 2.2730e-17,  ..., 7.0267e-17, 1.1802e-16,\n",
       "             7.4649e-17],\n",
       "            [2.3295e-16, 2.4372e-16, 5.9808e-17,  ..., 1.7513e-16, 6.4063e-16,\n",
       "             1.9230e-16],\n",
       "            [2.3656e-16, 1.8939e-16, 1.1693e-16,  ..., 3.2743e-16, 7.0472e-16,\n",
       "             2.6185e-16]])},\n",
       "   56: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-4.1216e-09, -1.7662e-08, -2.3788e-08,  ...,  4.2685e-08,\n",
       "              8.7167e-08, -4.2366e-08],\n",
       "            [-7.5049e-09, -8.0974e-10,  1.0869e-09,  ..., -1.9390e-08,\n",
       "             -6.7561e-08,  2.5673e-08],\n",
       "            [ 1.0652e-08,  3.0280e-08,  1.9078e-08,  ...,  1.7628e-08,\n",
       "              6.0883e-08, -1.6221e-08],\n",
       "            ...,\n",
       "            [-2.4435e-08, -8.1044e-08, -2.6459e-08,  ..., -1.2766e-08,\n",
       "             -1.3880e-07,  7.0850e-08],\n",
       "            [ 2.4446e-08,  6.5640e-08,  1.1300e-08,  ...,  2.9940e-08,\n",
       "              1.7934e-07, -1.0314e-07],\n",
       "            [ 6.0924e-09,  1.4226e-08,  7.2017e-08,  ..., -2.5475e-08,\n",
       "             -1.0468e-07,  7.5690e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.3958e-15, 7.4204e-15, 8.6273e-16,  ..., 3.9154e-15, 6.6655e-14,\n",
       "             1.4967e-14],\n",
       "            [4.4713e-15, 2.5327e-14, 4.5398e-15,  ..., 5.8214e-15, 1.3817e-13,\n",
       "             3.0064e-14],\n",
       "            [1.2237e-15, 7.2745e-15, 3.0583e-15,  ..., 1.2676e-15, 2.7258e-14,\n",
       "             6.9507e-15],\n",
       "            ...,\n",
       "            [1.2104e-15, 7.7872e-15, 1.6936e-15,  ..., 2.3094e-15, 4.7199e-14,\n",
       "             1.3266e-14],\n",
       "            [1.5617e-15, 1.3202e-14, 6.0196e-15,  ..., 1.8079e-15, 4.2931e-14,\n",
       "             1.2939e-14],\n",
       "            [8.4451e-15, 5.3726e-14, 7.0499e-15,  ..., 1.8774e-14, 3.5440e-13,\n",
       "             8.0476e-14]])},\n",
       "   57: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 9.7425e-09, -7.6222e-08,  2.3801e-08,  ...,  1.9583e-08,\n",
       "              2.9800e-08,  5.2845e-09],\n",
       "            [ 5.6525e-09, -4.2979e-08,  3.0960e-08,  ..., -3.4947e-09,\n",
       "              6.2528e-08,  2.0728e-08],\n",
       "            [ 1.3107e-07, -1.6004e-07,  1.3780e-07,  ..., -4.3590e-09,\n",
       "              2.2617e-07,  1.9583e-08],\n",
       "            ...,\n",
       "            [ 1.1525e-07, -4.1954e-08,  7.1638e-08,  ..., -9.7715e-09,\n",
       "              8.9915e-08, -5.5979e-08],\n",
       "            [-2.0704e-07,  1.2459e-07, -1.6520e-07,  ...,  1.0843e-08,\n",
       "             -2.4203e-07,  5.0084e-08],\n",
       "            [ 5.9839e-09, -4.3104e-08,  1.7827e-08,  ...,  6.0222e-09,\n",
       "              3.8332e-08,  2.5432e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.6814e-14, 6.5029e-14, 4.1998e-14,  ..., 2.1570e-15, 9.6800e-14,\n",
       "             3.2669e-15],\n",
       "            [9.7053e-14, 7.0829e-14, 5.6284e-14,  ..., 1.7340e-15, 1.3763e-13,\n",
       "             5.7766e-15],\n",
       "            [1.2851e-13, 1.1427e-13, 8.1292e-14,  ..., 2.7188e-15, 1.9441e-13,\n",
       "             6.0890e-15],\n",
       "            ...,\n",
       "            [6.1185e-14, 9.3808e-14, 4.9116e-14,  ..., 1.6466e-15, 1.2894e-13,\n",
       "             4.6814e-15],\n",
       "            [1.2331e-13, 1.1177e-13, 8.4229e-14,  ..., 1.5198e-15, 2.0212e-13,\n",
       "             2.8314e-15],\n",
       "            [3.6834e-14, 1.9789e-14, 1.5370e-14,  ..., 1.6918e-15, 3.4930e-14,\n",
       "             8.9882e-15]])},\n",
       "   58: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 4.9403e-08,  9.2832e-08,  3.2418e-07, -2.5758e-07,  3.3640e-07,\n",
       "             2.7595e-07, -2.0660e-07, -1.8196e-07,  3.3551e-08,  1.2822e-07,\n",
       "             3.7752e-07,  6.1084e-08,  1.6625e-07, -6.6255e-08,  3.5688e-08,\n",
       "            -2.4803e-07, -3.7320e-07, -2.1005e-07, -1.0580e-07, -2.8539e-07,\n",
       "             2.6784e-07,  6.8791e-08, -4.3039e-07,  1.3520e-08, -1.0020e-07,\n",
       "            -4.0294e-07,  3.7537e-07, -3.2947e-07,  9.2393e-09,  1.9049e-07,\n",
       "             1.9600e-07,  2.2108e-07, -3.0133e-07,  8.2098e-08,  1.8069e-07,\n",
       "            -8.9753e-08, -2.4048e-07,  9.8457e-08, -1.3340e-07,  1.0711e-07,\n",
       "             2.6488e-08,  1.1327e-07,  3.4928e-07,  1.5756e-07,  3.9219e-07,\n",
       "             3.2437e-07,  1.8519e-07, -2.4258e-07,  1.0158e-07, -1.8020e-07,\n",
       "            -8.9351e-08,  1.4208e-07,  1.4496e-07,  3.7641e-08, -3.6106e-08,\n",
       "             1.6789e-07, -1.7118e-08, -2.6528e-07, -2.2514e-08,  9.2920e-08,\n",
       "            -1.7414e-07, -6.2953e-08,  3.6861e-07,  3.2911e-07, -4.8876e-07,\n",
       "            -1.6719e-07,  2.2222e-07,  4.3979e-08, -3.9526e-07, -1.8287e-07,\n",
       "            -4.2775e-08, -3.6688e-07, -5.0179e-08,  8.1194e-08, -1.2354e-07,\n",
       "             3.9287e-08, -4.1849e-07, -2.3268e-07, -6.7163e-08, -1.0259e-09,\n",
       "            -5.6273e-08,  4.4760e-08,  6.8953e-08,  1.2356e-07,  1.8638e-07,\n",
       "             7.1899e-08,  1.1730e-07, -2.9425e-07, -2.0108e-07,  3.9063e-08,\n",
       "            -5.9627e-09,  9.8706e-08, -2.5420e-07,  2.0473e-07,  1.3941e-07,\n",
       "             1.2366e-07, -1.4311e-07,  1.8630e-07,  6.2398e-07, -4.5999e-07,\n",
       "            -3.4211e-08,  9.1071e-08,  1.6523e-07,  5.1237e-07,  2.2240e-07,\n",
       "            -5.1194e-07,  3.5820e-08, -5.6670e-08, -1.1541e-07,  1.3150e-07,\n",
       "             3.5773e-07,  5.7240e-08,  1.3605e-07, -3.6044e-09, -6.0914e-07,\n",
       "            -8.3627e-08,  8.3499e-08, -2.4695e-07, -6.8102e-09,  8.1208e-08,\n",
       "            -5.4005e-08, -3.6020e-07, -1.8530e-07, -3.1198e-07, -1.0242e-07,\n",
       "            -5.7791e-08,  1.0543e-07,  2.3922e-08, -3.4575e-07, -3.6872e-07,\n",
       "             2.1834e-08,  7.4533e-08, -1.0596e-07,  3.2500e-07, -4.8525e-08,\n",
       "            -2.8152e-07,  3.4762e-08,  1.2785e-07,  1.1314e-07, -5.7609e-08,\n",
       "            -3.5554e-07,  9.8206e-08,  1.7749e-07, -2.5000e-07,  1.9542e-07,\n",
       "             2.2985e-07,  1.8124e-07,  1.6105e-07, -6.9998e-08,  1.3025e-08,\n",
       "            -4.0184e-07, -9.8028e-08,  1.2404e-07,  2.3786e-08,  5.5916e-08,\n",
       "            -1.9835e-08,  3.3938e-07, -3.1017e-07,  8.3210e-08, -1.7603e-07,\n",
       "            -8.0214e-08, -3.6630e-07,  1.9993e-07, -4.3086e-07,  2.6099e-07,\n",
       "            -2.8167e-08, -1.0268e-07,  3.2112e-07,  3.1154e-08, -4.1105e-07,\n",
       "             2.8581e-07,  1.2591e-07,  2.9554e-07,  4.0903e-07, -1.4171e-07,\n",
       "             7.5126e-08,  7.5660e-08,  9.0155e-08,  9.7586e-09,  1.1336e-07,\n",
       "             9.0166e-08,  1.2840e-07, -3.0010e-07,  1.6751e-07,  1.1922e-07,\n",
       "            -9.7332e-08, -8.3564e-08,  6.6708e-09,  3.3380e-08, -5.9484e-08,\n",
       "            -2.6675e-07, -2.8684e-07,  3.9428e-07,  4.9176e-07,  2.0832e-07,\n",
       "            -4.6361e-08,  1.3955e-07,  1.5011e-07, -3.5748e-07,  4.6702e-08]),\n",
       "    'exp_avg_sq': tensor([1.8516e-13, 2.4739e-13, 3.5864e-13, 1.4334e-13, 7.8780e-14, 1.8816e-13,\n",
       "            4.2139e-14, 6.6260e-14, 1.1715e-13, 5.8876e-14, 1.0780e-13, 1.0552e-13,\n",
       "            1.6456e-13, 8.7736e-14, 2.2430e-13, 1.7862e-13, 7.0156e-14, 3.0220e-13,\n",
       "            1.4874e-13, 1.3407e-13, 7.9941e-14, 1.0087e-13, 8.7597e-14, 1.6332e-13,\n",
       "            8.2356e-14, 3.5263e-13, 5.2632e-14, 1.6985e-13, 6.0090e-14, 2.3573e-13,\n",
       "            9.2039e-14, 2.3029e-13, 3.3618e-13, 5.6446e-14, 1.3939e-13, 2.7759e-13,\n",
       "            8.6537e-14, 5.3855e-14, 2.0456e-13, 2.5174e-13, 5.0554e-14, 2.5182e-13,\n",
       "            2.3647e-13, 1.1997e-13, 5.4616e-13, 1.6017e-13, 1.1508e-13, 1.9931e-13,\n",
       "            1.0075e-13, 5.4436e-14, 9.7017e-14, 1.5434e-13, 3.2336e-13, 7.7784e-14,\n",
       "            1.0310e-13, 5.5401e-13, 8.9150e-14, 3.8369e-13, 1.1749e-13, 3.7512e-13,\n",
       "            8.6686e-14, 8.0340e-14, 8.6550e-14, 1.5070e-13, 3.5333e-13, 1.5346e-13,\n",
       "            3.5930e-13, 3.1570e-14, 1.1354e-13, 1.9653e-13, 1.0260e-13, 8.9288e-14,\n",
       "            9.6254e-14, 4.5613e-14, 9.6270e-14, 8.3601e-14, 1.0980e-13, 1.2969e-13,\n",
       "            1.0154e-13, 8.3716e-14, 1.2127e-13, 1.2545e-13, 5.7299e-14, 1.0795e-13,\n",
       "            7.6207e-14, 1.2508e-13, 4.7234e-13, 1.2047e-13, 8.3996e-14, 1.9681e-13,\n",
       "            1.3761e-13, 1.1358e-13, 1.3228e-13, 2.4193e-13, 6.4716e-14, 1.0638e-13,\n",
       "            9.1116e-14, 1.3815e-13, 4.2365e-13, 1.6585e-13, 1.4781e-13, 4.8563e-14,\n",
       "            8.4971e-14, 3.3706e-13, 1.1667e-13, 1.1785e-13, 7.8303e-14, 1.2210e-13,\n",
       "            8.3127e-14, 1.6638e-13, 1.3332e-13, 1.3070e-13, 2.1673e-13, 3.5832e-14,\n",
       "            2.5119e-13, 5.6062e-14, 1.7401e-13, 9.1394e-14, 9.5603e-14, 8.1824e-14,\n",
       "            2.3195e-13, 1.1385e-13, 8.9869e-14, 2.9749e-13, 1.3032e-13, 7.1401e-14,\n",
       "            2.3958e-13, 5.4993e-14, 5.9692e-14, 9.8214e-14, 4.8761e-14, 5.1284e-14,\n",
       "            1.7499e-13, 2.9210e-13, 8.3866e-14, 3.1435e-13, 8.1764e-14, 1.8725e-13,\n",
       "            2.4397e-13, 9.7227e-14, 1.1364e-13, 1.7772e-13, 9.8722e-14, 1.4789e-13,\n",
       "            4.9142e-14, 7.6922e-14, 7.4080e-14, 5.7183e-14, 7.8773e-14, 4.4996e-14,\n",
       "            3.5629e-13, 1.2820e-13, 1.6726e-13, 1.6507e-13, 8.3059e-14, 1.7854e-13,\n",
       "            1.5739e-13, 1.0089e-13, 6.9975e-14, 2.0048e-13, 3.4659e-13, 9.5265e-14,\n",
       "            4.7604e-14, 8.0038e-13, 2.0321e-13, 1.0805e-13, 2.3470e-13, 2.5424e-13,\n",
       "            4.4199e-13, 9.6155e-14, 2.7865e-13, 1.3042e-13, 1.3116e-13, 9.4311e-14,\n",
       "            1.6794e-13, 2.5998e-13, 4.8801e-14, 2.0937e-13, 1.1782e-13, 8.3222e-14,\n",
       "            1.9540e-13, 7.1511e-14, 1.5530e-13, 6.7021e-14, 7.2343e-14, 1.0071e-13,\n",
       "            1.7929e-13, 1.4279e-13, 3.9985e-14, 2.0658e-13, 1.0453e-13, 8.3492e-14,\n",
       "            3.8421e-13, 1.7850e-13, 8.0914e-14, 8.9492e-14, 7.3389e-14, 2.5340e-13,\n",
       "            3.8457e-13, 6.7244e-14])},\n",
       "   59: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 3.1745e-08,  2.6296e-08,  4.4840e-08, -2.2130e-07,  8.5175e-08,\n",
       "             6.7633e-08, -2.2609e-08,  6.0458e-08, -1.8688e-08, -8.5059e-08,\n",
       "            -4.5024e-08,  3.0971e-08, -1.3430e-07, -1.0525e-07,  1.2926e-07,\n",
       "            -3.7843e-08, -8.3573e-08,  1.6301e-07, -2.1467e-08,  1.4619e-07,\n",
       "            -1.3134e-07, -4.7392e-08, -5.6870e-08,  2.4557e-07,  2.4013e-08,\n",
       "            -1.4774e-07, -2.6561e-07,  6.5874e-08, -8.7398e-08,  1.3156e-07,\n",
       "            -1.7252e-07, -8.9759e-08, -1.3431e-07, -1.3785e-07, -6.8899e-08,\n",
       "            -4.5805e-08, -5.6730e-09,  5.5752e-09, -9.1006e-08,  1.0009e-07,\n",
       "            -6.8106e-08, -1.3486e-07, -2.0752e-08, -3.0175e-08,  1.0126e-07,\n",
       "             8.1194e-08,  2.9440e-08,  1.8466e-07, -1.7626e-08, -2.7534e-08,\n",
       "            -3.9580e-08,  1.1257e-08,  3.8022e-10, -1.2946e-08,  2.8189e-08,\n",
       "            -2.7302e-08,  9.6879e-08,  1.4316e-07, -2.1582e-08,  4.1870e-08,\n",
       "            -2.2573e-08,  1.0543e-07,  5.7843e-08,  4.8942e-08, -3.2573e-07,\n",
       "            -9.4547e-08,  8.7015e-08,  2.3172e-08, -8.9790e-08,  6.0798e-08,\n",
       "             3.0577e-08, -2.9355e-07, -4.4282e-08,  1.9934e-08, -4.3796e-08,\n",
       "            -7.2891e-09, -1.2333e-07, -9.4299e-08, -1.8392e-07,  4.1518e-08,\n",
       "            -2.9907e-08, -1.5413e-07, -4.5324e-08,  3.1287e-08,  6.5118e-08,\n",
       "             1.0233e-07,  3.0428e-09,  9.6276e-09,  3.1359e-08, -1.7708e-09,\n",
       "            -6.6499e-08, -2.4629e-08,  2.8660e-08,  9.9321e-08,  4.2565e-08,\n",
       "            -1.3247e-08, -2.0329e-08, -2.1385e-08, -1.9456e-07, -5.1390e-08,\n",
       "             6.0816e-08,  3.2028e-08,  2.0109e-08, -3.9230e-07,  2.4721e-07,\n",
       "             6.3106e-08,  5.6374e-08, -5.2571e-08,  4.0030e-08, -2.0987e-08,\n",
       "            -1.5437e-08,  1.2302e-07,  8.9415e-09,  3.6004e-08, -2.3008e-07,\n",
       "             8.6095e-09,  1.4431e-08, -1.9744e-08, -3.5137e-08, -1.3895e-07,\n",
       "             2.9702e-08,  1.8467e-08, -5.6968e-08,  4.3882e-08, -7.5592e-08,\n",
       "            -2.4737e-08,  1.5714e-07, -8.8791e-09, -4.8751e-08, -3.5746e-08,\n",
       "            -2.5181e-08, -1.6944e-08,  4.6166e-08, -2.3166e-09, -4.9559e-08,\n",
       "             9.1888e-08,  3.5862e-08,  2.7074e-08,  1.4566e-07,  3.7543e-08,\n",
       "            -1.8731e-07,  2.6755e-07,  5.4001e-09, -7.8806e-08,  1.8291e-08,\n",
       "            -2.5408e-08,  9.5021e-08, -1.2455e-08,  3.3508e-08,  4.5811e-08,\n",
       "            -1.4448e-08,  5.4129e-09, -1.2491e-07, -1.6840e-07, -3.9111e-08,\n",
       "             8.8323e-08, -1.4172e-07, -5.1473e-08,  7.1244e-08, -6.3416e-08,\n",
       "             7.2641e-08,  1.9313e-08, -6.4772e-08, -3.0786e-08, -2.2228e-07,\n",
       "            -2.3091e-08,  1.1387e-07, -2.3937e-08,  7.6197e-08,  3.5167e-08,\n",
       "            -4.2890e-08, -1.3907e-07, -9.1361e-08, -5.5261e-08,  1.4460e-07,\n",
       "            -6.1934e-09,  1.0280e-09,  1.1935e-08,  9.3748e-09, -9.5440e-08,\n",
       "             2.7764e-07, -3.0777e-08, -1.2565e-07, -3.3662e-08, -2.6961e-08,\n",
       "            -4.7687e-08,  1.2207e-08,  3.4959e-08, -2.2023e-08,  3.4597e-08,\n",
       "             1.7505e-08, -6.6403e-08, -1.4231e-08, -2.9926e-08, -8.1051e-08,\n",
       "            -4.5191e-08,  6.6382e-09,  1.3198e-07, -1.6490e-07,  9.7117e-09]),\n",
       "    'exp_avg_sq': tensor([1.5073e-14, 9.9857e-15, 6.2757e-15, 5.4831e-14, 2.7053e-15, 6.0257e-15,\n",
       "            2.0602e-15, 4.8882e-15, 3.5496e-15, 6.4514e-15, 1.0593e-14, 3.3597e-14,\n",
       "            2.1291e-14, 9.7286e-15, 1.1512e-14, 2.8006e-14, 2.8174e-15, 1.0293e-13,\n",
       "            8.9632e-15, 1.5631e-14, 6.3327e-15, 3.3455e-15, 3.3373e-15, 3.7039e-14,\n",
       "            1.7694e-14, 4.3598e-14, 2.1160e-14, 7.2455e-15, 3.8551e-14, 3.5228e-14,\n",
       "            1.2480e-14, 9.1284e-14, 2.7891e-14, 1.5101e-14, 5.7826e-14, 1.8563e-14,\n",
       "            4.7021e-15, 1.7696e-14, 3.4841e-14, 1.5007e-14, 3.7543e-14, 1.0293e-14,\n",
       "            4.5457e-15, 8.0982e-16, 2.0550e-14, 5.4184e-15, 1.8993e-15, 2.0659e-14,\n",
       "            1.0160e-14, 1.0993e-15, 1.0999e-15, 2.9168e-15, 3.9194e-14, 9.1925e-15,\n",
       "            7.4391e-15, 4.5127e-16, 2.5161e-14, 1.2504e-14, 1.9201e-14, 7.7892e-14,\n",
       "            1.7384e-14, 5.4349e-15, 4.6529e-15, 8.2907e-15, 1.2078e-13, 1.1629e-14,\n",
       "            2.9689e-14, 1.2561e-15, 4.6171e-15, 7.1268e-15, 5.5038e-15, 2.6263e-14,\n",
       "            8.4672e-15, 3.5068e-16, 1.2132e-15, 2.7965e-15, 2.6491e-14, 4.7046e-15,\n",
       "            4.3619e-14, 4.3670e-15, 1.1847e-14, 3.2566e-14, 2.8444e-14, 1.3170e-14,\n",
       "            3.5811e-15, 1.0188e-14, 7.7817e-15, 7.2979e-15, 1.6060e-15, 3.3889e-15,\n",
       "            7.8251e-15, 4.0365e-15, 1.0928e-15, 1.4331e-14, 9.2947e-15, 3.7288e-15,\n",
       "            2.4199e-15, 4.0242e-15, 1.7769e-14, 5.4610e-15, 2.3386e-15, 2.4267e-15,\n",
       "            2.5668e-15, 5.4585e-14, 1.8488e-14, 2.9314e-15, 1.9147e-14, 1.8014e-15,\n",
       "            4.3322e-14, 5.5221e-14, 5.7268e-15, 1.8438e-14, 4.1975e-15, 1.1169e-14,\n",
       "            1.3081e-14, 9.0470e-15, 4.9531e-16, 4.2825e-15, 1.5025e-15, 1.4645e-13,\n",
       "            5.6265e-15, 1.3120e-15, 3.2267e-15, 1.4748e-14, 1.1596e-14, 1.2815e-14,\n",
       "            1.4141e-14, 4.9065e-15, 3.8606e-15, 3.9642e-15, 2.3703e-15, 3.9129e-15,\n",
       "            4.8754e-15, 1.0029e-14, 1.1647e-14, 4.4397e-14, 4.3281e-15, 2.5091e-15,\n",
       "            9.6267e-15, 1.3440e-15, 1.1652e-14, 1.2810e-13, 1.3417e-14, 5.1767e-15,\n",
       "            1.5390e-15, 7.7069e-15, 1.5720e-14, 7.5762e-15, 1.8411e-14, 3.6419e-15,\n",
       "            3.5101e-14, 6.9968e-15, 9.9994e-15, 2.5672e-14, 2.3080e-15, 4.9122e-15,\n",
       "            2.0381e-14, 1.7787e-14, 1.6964e-14, 2.0214e-15, 1.3600e-13, 4.0950e-15,\n",
       "            2.6354e-15, 1.0491e-14, 1.0018e-14, 1.9796e-14, 1.8929e-13, 2.7091e-15,\n",
       "            7.0157e-15, 3.5204e-15, 2.7646e-15, 5.2618e-15, 6.1979e-15, 3.0781e-15,\n",
       "            1.0397e-14, 1.1736e-14, 4.6505e-15, 2.8531e-14, 1.6944e-15, 1.9375e-14,\n",
       "            2.3688e-13, 5.0476e-15, 1.9319e-14, 1.2030e-14, 1.5483e-15, 4.7402e-15,\n",
       "            3.5454e-14, 1.1709e-14, 1.0161e-14, 1.2821e-13, 3.4054e-15, 2.7462e-15,\n",
       "            5.5067e-14, 2.4285e-15, 1.2485e-14, 4.0274e-15, 2.5230e-15, 3.2654e-14,\n",
       "            6.6300e-14, 2.2228e-14])},\n",
       "   60: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 9.9233e-08,  4.7367e-08,  1.5887e-07, -1.4190e-07,  6.2520e-09,\n",
       "            -8.6561e-08, -2.0714e-08, -8.1854e-08, -4.5034e-08, -1.0999e-07,\n",
       "             1.3885e-07, -7.0851e-08,  9.7197e-08, -1.1697e-07,  2.3692e-08,\n",
       "             5.0005e-08, -1.6351e-07,  4.5438e-08, -1.9207e-08, -1.5908e-07,\n",
       "             9.4803e-08,  9.6329e-08, -2.2418e-08, -7.3000e-08,  7.9988e-08,\n",
       "            -1.2689e-07,  1.1928e-07, -1.4814e-07, -1.0255e-07,  9.4187e-08,\n",
       "             1.1021e-07,  2.5725e-08, -1.1964e-07,  1.4202e-07,  7.2576e-08,\n",
       "            -1.6319e-08, -1.0848e-07,  4.8640e-08, -1.1782e-07,  7.4356e-08,\n",
       "            -3.0042e-09,  1.0245e-07,  3.9026e-08, -2.0666e-08,  7.2834e-08,\n",
       "            -7.6885e-08,  1.6697e-08,  1.3668e-07, -1.1477e-08,  2.2469e-08,\n",
       "             1.0796e-07, -6.4432e-08, -6.7436e-08, -8.9777e-09,  1.7476e-08,\n",
       "             1.1290e-07,  1.0453e-07, -1.4378e-07, -9.0483e-10,  7.0494e-09,\n",
       "            -4.1785e-08,  1.9647e-07,  9.9827e-08,  1.0036e-08, -1.9535e-07,\n",
       "             7.8401e-08, -4.0612e-08,  7.0698e-09, -1.4818e-07,  2.2570e-09,\n",
       "             8.6019e-09, -1.9820e-07, -6.9518e-08, -7.1979e-08, -1.7925e-08,\n",
       "             1.9766e-08, -1.1779e-07, -9.9048e-08, -1.2443e-07, -6.3672e-08,\n",
       "             2.2723e-08, -4.5624e-08,  7.7918e-08, -4.1739e-08,  1.3236e-07,\n",
       "            -5.8113e-09, -6.7601e-08, -5.3865e-08, -1.6790e-08, -3.6624e-08,\n",
       "             1.2444e-07, -6.2635e-09, -4.3806e-08, -2.4250e-08, -3.5206e-09,\n",
       "             1.3436e-07, -2.5659e-08,  2.3420e-08,  2.7432e-07, -1.5912e-07,\n",
       "            -1.7225e-07,  1.0922e-08, -6.0925e-08,  2.2950e-07,  5.6529e-08,\n",
       "            -1.5146e-07,  1.2206e-07,  2.9504e-08, -2.1492e-08,  3.6895e-08,\n",
       "             2.3686e-08, -1.9475e-08, -3.8628e-08, -4.0629e-08, -1.8931e-07,\n",
       "             5.1830e-08,  1.1136e-08, -7.2977e-08,  1.1583e-07,  3.4770e-08,\n",
       "             1.2805e-07, -1.9935e-09, -4.1855e-08,  5.9731e-10, -2.5342e-08,\n",
       "             1.9341e-07,  1.1879e-08,  1.5720e-07, -2.8206e-08, -2.3709e-08,\n",
       "            -3.0146e-10, -1.9316e-08, -5.7503e-08,  2.4080e-08, -6.8857e-08,\n",
       "             3.6890e-08, -1.1350e-08, -4.6068e-08,  1.1252e-07, -1.8755e-07,\n",
       "            -1.8842e-07,  8.2079e-08,  1.9597e-08, -5.7284e-08,  4.8048e-08,\n",
       "             1.8554e-08, -6.6452e-08,  5.4059e-08,  1.6844e-08, -3.1827e-08,\n",
       "            -5.1692e-08, -2.1254e-08,  1.1253e-07, -1.5811e-08, -7.9026e-08,\n",
       "            -7.2706e-09,  7.6291e-08, -7.6156e-08,  4.3189e-08, -5.5115e-08,\n",
       "             4.8094e-08, -2.8796e-08,  7.1380e-08, -1.6774e-07,  2.2302e-07,\n",
       "            -4.1063e-09, -1.0674e-07,  8.4850e-08,  1.5392e-07, -1.5051e-07,\n",
       "            -1.2375e-08,  6.9482e-08,  1.1522e-07,  8.9818e-08, -1.5022e-08,\n",
       "             9.5034e-08,  3.1663e-08, -2.7143e-08, -6.5165e-08,  3.6578e-08,\n",
       "             1.1733e-07,  5.1065e-08, -1.3696e-07,  6.0126e-08, -1.6983e-08,\n",
       "            -1.4322e-07,  4.2968e-09, -6.3081e-08,  3.4853e-08,  9.4430e-09,\n",
       "            -1.7183e-08, -7.1535e-08,  6.2297e-08,  1.7393e-08, -5.0333e-08,\n",
       "            -8.5822e-09,  2.9173e-08,  1.8609e-07, -7.5145e-08, -2.6270e-08]),\n",
       "    'exp_avg_sq': tensor([3.4100e-14, 1.6433e-14, 2.0280e-14, 1.8899e-14, 2.5236e-14, 4.0411e-14,\n",
       "            1.0187e-14, 1.3644e-14, 2.7953e-14, 1.0079e-14, 1.3749e-14, 2.3623e-14,\n",
       "            9.6517e-15, 1.1957e-14, 1.4763e-14, 3.3620e-15, 1.0270e-14, 2.8428e-14,\n",
       "            4.2920e-15, 2.4271e-14, 4.1828e-15, 7.5740e-15, 4.2830e-15, 2.1459e-14,\n",
       "            1.7108e-14, 3.5480e-14, 1.0146e-14, 2.8534e-14, 2.0317e-14, 4.5764e-14,\n",
       "            5.7034e-15, 6.9915e-14, 3.0337e-14, 1.6160e-14, 1.0192e-14, 2.7545e-15,\n",
       "            2.0568e-14, 7.1319e-15, 6.6694e-14, 4.4372e-14, 2.5454e-14, 9.9164e-15,\n",
       "            1.9018e-15, 4.5604e-15, 8.6328e-14, 2.5353e-15, 2.8247e-15, 1.0570e-14,\n",
       "            2.5716e-15, 7.6553e-15, 6.5134e-15, 1.2507e-14, 3.1930e-14, 1.1156e-14,\n",
       "            4.3661e-15, 3.1273e-14, 5.3532e-14, 5.7411e-14, 9.5757e-15, 2.9018e-14,\n",
       "            1.1009e-14, 1.0979e-14, 8.8428e-15, 2.1528e-14, 5.0330e-14, 1.5718e-14,\n",
       "            4.8389e-14, 5.0473e-15, 6.1279e-15, 4.7277e-15, 5.5093e-14, 1.4161e-14,\n",
       "            1.0230e-14, 5.4797e-15, 9.9102e-15, 7.7789e-15, 4.0562e-14, 6.6165e-15,\n",
       "            2.2816e-14, 4.0793e-15, 3.0046e-14, 7.9730e-15, 1.4525e-14, 1.3952e-14,\n",
       "            7.8285e-15, 3.8977e-14, 8.2263e-14, 3.9129e-14, 3.9297e-15, 7.0538e-15,\n",
       "            1.2765e-14, 5.1984e-15, 4.8857e-15, 2.7611e-14, 3.0064e-15, 1.4481e-14,\n",
       "            4.1299e-15, 1.3253e-14, 5.7421e-14, 1.1664e-14, 1.3345e-14, 9.4100e-15,\n",
       "            4.6729e-15, 2.0273e-14, 1.0218e-14, 2.3436e-14, 4.7542e-14, 1.3324e-14,\n",
       "            1.5735e-14, 2.5199e-14, 1.1765e-14, 6.7390e-15, 4.6751e-15, 1.6169e-14,\n",
       "            8.1094e-15, 1.7774e-14, 1.8173e-15, 8.1859e-15, 1.4312e-14, 3.8286e-14,\n",
       "            2.7536e-14, 6.6375e-15, 6.9337e-15, 2.1107e-14, 9.5389e-15, 1.3886e-14,\n",
       "            3.2357e-14, 1.4064e-14, 6.4291e-15, 5.1565e-15, 2.3651e-14, 9.7761e-15,\n",
       "            4.2112e-15, 2.4921e-14, 1.2867e-14, 6.7650e-15, 4.0177e-15, 7.9863e-15,\n",
       "            4.2374e-14, 1.0783e-14, 1.1780e-14, 5.8734e-14, 1.9476e-14, 4.0004e-15,\n",
       "            3.7083e-15, 3.1119e-15, 1.8993e-14, 4.1226e-15, 9.7147e-15, 1.8373e-14,\n",
       "            5.2506e-14, 1.9560e-14, 6.5042e-15, 3.3054e-14, 4.6624e-15, 7.1626e-15,\n",
       "            3.8582e-15, 2.7366e-14, 9.7761e-15, 6.0138e-15, 7.1678e-14, 5.3709e-15,\n",
       "            3.1465e-15, 9.6035e-14, 1.6183e-14, 9.0912e-15, 7.2507e-14, 6.2937e-15,\n",
       "            3.4233e-14, 4.2006e-14, 6.7266e-15, 3.5906e-15, 3.5178e-15, 1.2245e-14,\n",
       "            1.9986e-14, 3.7035e-14, 6.5680e-15, 3.6872e-14, 1.5374e-14, 2.0750e-14,\n",
       "            7.4378e-14, 1.9264e-14, 1.2736e-14, 1.0702e-14, 4.6764e-15, 1.3168e-14,\n",
       "            3.1759e-14, 1.9193e-14, 1.7465e-14, 7.2287e-14, 6.6612e-15, 1.1596e-14,\n",
       "            3.9473e-14, 1.6826e-14, 1.6142e-14, 1.5747e-14, 1.8801e-14, 3.2211e-14,\n",
       "            1.0749e-14, 6.9024e-15])},\n",
       "   61: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-1.0004e-08,  6.3900e-08,  6.5786e-08,  ..., -1.0250e-07,\n",
       "             -7.6449e-08,  1.1827e-07],\n",
       "            [-3.7605e-08,  1.3717e-09, -2.8105e-08,  ..., -5.8344e-08,\n",
       "             -1.7042e-07,  1.3773e-07],\n",
       "            [ 3.9407e-08,  4.0565e-08, -2.5749e-08,  ..., -1.4767e-08,\n",
       "              2.2865e-08, -4.8546e-08],\n",
       "            ...,\n",
       "            [-2.9137e-08, -2.3737e-08,  1.2221e-08,  ..., -6.0958e-09,\n",
       "             -2.7771e-08,  4.3966e-08],\n",
       "            [-3.7095e-09, -1.4872e-10,  1.9188e-10,  ...,  3.1475e-09,\n",
       "              8.6188e-09,  1.6844e-10],\n",
       "            [ 8.2864e-10, -8.8084e-09, -7.3261e-09,  ..., -8.8668e-11,\n",
       "             -7.6305e-09,  1.5437e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.1066e-14, 1.3279e-14, 1.1191e-14,  ..., 2.8523e-14, 1.1587e-13,\n",
       "             5.7741e-14],\n",
       "            [4.3005e-15, 3.7005e-15, 6.5833e-15,  ..., 6.1111e-15, 4.9930e-14,\n",
       "             2.4453e-14],\n",
       "            [4.0958e-15, 5.2918e-15, 4.8283e-15,  ..., 1.0150e-14, 4.3592e-14,\n",
       "             2.2219e-14],\n",
       "            ...,\n",
       "            [8.0168e-16, 7.2865e-16, 9.8040e-16,  ..., 2.8824e-15, 1.0849e-14,\n",
       "             5.1818e-15],\n",
       "            [3.9937e-16, 3.2648e-16, 8.7374e-17,  ..., 2.5366e-15, 4.8351e-15,\n",
       "             3.4003e-15],\n",
       "            [3.1806e-17, 4.1698e-17, 1.2096e-16,  ..., 7.8206e-17, 7.1055e-16,\n",
       "             4.0421e-16]])},\n",
       "   62: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([-9.9683e-08, -7.9416e-08,  1.9286e-08,  1.5503e-08, -6.4018e-08,\n",
       "            -4.1407e-09,  3.9969e-08,  4.2777e-09, -1.1387e-08, -1.6062e-08,\n",
       "            -1.1197e-07, -2.4030e-08, -5.6554e-08,  1.8452e-08,  1.1198e-08,\n",
       "             1.0400e-08, -1.0689e-09, -1.4034e-07,  6.7032e-08, -2.9967e-09,\n",
       "             1.0436e-08,  1.3683e-08,  4.0682e-08,  4.3814e-08,  2.0790e-08,\n",
       "            -1.2858e-07, -5.9497e-08,  8.0596e-08, -4.6550e-08,  3.8229e-08,\n",
       "            -1.8374e-08, -5.2371e-08,  2.1013e-08, -1.1900e-08,  3.5089e-08,\n",
       "            -2.6096e-08,  1.9542e-08,  9.1878e-09, -3.0715e-08,  3.2336e-08,\n",
       "            -8.2822e-08, -1.7438e-08, -3.6842e-08,  7.8081e-09,  2.7351e-09,\n",
       "            -4.1740e-10,  5.2026e-08,  1.1086e-07,  2.5811e-08,  3.9859e-09,\n",
       "             2.6057e-08, -3.7978e-08, -2.8270e-08,  2.5459e-08,  2.7475e-08,\n",
       "             1.1275e-07, -1.4796e-07, -8.3203e-08,  8.9999e-09, -1.3485e-08,\n",
       "            -7.6228e-08, -1.5139e-09, -5.2549e-09, -1.5717e-07, -7.2991e-08,\n",
       "             7.7411e-09, -3.4895e-09, -6.9777e-08,  1.6646e-08,  4.0981e-09,\n",
       "             2.6199e-08, -2.7584e-08,  1.8483e-08, -2.5456e-08,  2.7253e-08,\n",
       "            -1.4832e-07,  7.1464e-11,  2.1921e-08, -2.4127e-08,  8.5967e-08,\n",
       "            -3.3008e-08, -5.5761e-09,  7.0453e-09,  1.3395e-07,  8.5657e-08,\n",
       "            -6.7162e-08,  1.1310e-07,  2.1730e-08,  2.4984e-08, -4.2367e-08,\n",
       "             2.4480e-08,  5.0926e-08, -5.0443e-08, -5.9989e-08,  4.7931e-08,\n",
       "            -1.3305e-08, -6.0932e-08, -1.6199e-08, -5.7923e-08, -1.0129e-08,\n",
       "             2.6137e-09,  4.3502e-08, -6.1627e-09, -8.3225e-08,  1.4039e-07,\n",
       "             3.4873e-09, -9.4086e-08, -9.7979e-08, -3.9689e-08,  4.2710e-09,\n",
       "             2.3077e-08, -2.2112e-09,  5.4768e-08,  5.5584e-09,  2.1997e-08,\n",
       "             1.6757e-08,  3.6841e-08, -2.0534e-08,  5.3307e-08,  1.4251e-07,\n",
       "             3.0022e-08,  6.0401e-09, -9.4906e-09,  1.2563e-08,  7.1830e-09,\n",
       "            -2.5298e-08, -8.6122e-08,  2.0790e-08,  2.0631e-09, -2.6386e-08,\n",
       "            -1.0009e-08,  4.0136e-08,  9.6938e-09, -2.9947e-08,  7.1272e-09,\n",
       "             3.2304e-08,  8.9567e-08,  7.6159e-08, -2.5004e-08,  9.5597e-09,\n",
       "            -4.5695e-08, -1.6654e-08,  4.5307e-08, -1.0520e-08,  7.0547e-08,\n",
       "             2.5300e-09,  7.8244e-10,  8.5287e-09,  3.3755e-08,  1.4478e-08,\n",
       "            -3.6671e-08, -1.2967e-08,  8.5268e-09,  5.3365e-10,  5.6810e-08,\n",
       "             3.4041e-08, -6.7910e-08,  5.8068e-09,  3.4305e-09,  1.1291e-07,\n",
       "             2.3213e-08, -2.4398e-08,  5.8094e-08,  4.8467e-08,  9.3456e-09,\n",
       "             3.0635e-08,  1.7508e-08,  7.1469e-09, -1.7994e-08,  9.6003e-09,\n",
       "             1.9598e-08,  5.3924e-08, -1.0814e-08,  7.7684e-08,  2.1898e-08,\n",
       "             4.1153e-08, -3.1822e-08,  6.2738e-09,  2.9994e-08,  1.1153e-07,\n",
       "            -3.5775e-08,  7.0537e-08, -5.2347e-08,  7.0386e-09, -9.0155e-09,\n",
       "             1.5857e-07, -1.3796e-08,  5.5058e-08, -1.6628e-08,  4.0216e-08,\n",
       "            -3.4090e-08,  5.9359e-08,  2.1478e-08,  1.1752e-08, -2.2204e-08,\n",
       "             6.8075e-08, -2.7830e-08,  1.6367e-07, -3.8256e-09,  1.9018e-08,\n",
       "            -5.0473e-08,  1.6660e-09,  1.0753e-07,  1.3043e-07,  2.9572e-08,\n",
       "             3.5381e-08, -1.1693e-07, -1.1309e-08, -1.0199e-08, -5.6735e-09,\n",
       "            -5.7194e-08,  9.7256e-08, -1.3318e-08, -5.8019e-08, -5.3600e-09,\n",
       "             3.1848e-08,  9.3204e-09,  4.3025e-09, -8.7286e-09, -2.0764e-08,\n",
       "             1.1724e-09, -4.9226e-09, -3.1486e-08,  5.6418e-09,  3.6447e-09,\n",
       "            -4.6795e-08,  3.8033e-08,  1.1500e-09,  6.9955e-08,  1.8578e-08,\n",
       "            -3.3590e-08, -1.5331e-08,  5.5382e-08,  1.1332e-07, -6.1692e-09,\n",
       "            -6.0107e-08,  9.3567e-09, -6.2089e-08,  9.7265e-09,  4.1993e-08,\n",
       "             1.1427e-08, -1.1401e-07,  8.1451e-08, -6.2093e-09, -1.9540e-09,\n",
       "             7.2171e-09,  7.9446e-10, -3.5448e-08,  1.0152e-07, -2.0849e-08,\n",
       "             6.7053e-09,  7.3281e-10,  8.7961e-10,  5.3676e-09,  1.9010e-08,\n",
       "            -2.8446e-08,  1.9948e-08,  4.8449e-09, -3.5759e-08,  2.6080e-08,\n",
       "            -8.6652e-09,  8.3146e-09,  1.2312e-08, -2.4680e-08, -2.9509e-08,\n",
       "             1.1831e-08,  7.9783e-08,  9.8190e-09,  5.9661e-08,  8.9201e-08,\n",
       "             5.3479e-08, -3.1841e-08,  5.5354e-09,  1.2234e-08, -8.5675e-08,\n",
       "             9.5646e-09, -1.1341e-08, -2.3697e-09,  3.2696e-08, -1.9823e-08,\n",
       "            -2.0664e-08,  5.4148e-08,  2.0797e-08,  6.8287e-08, -2.1556e-08,\n",
       "             4.1523e-08,  1.1886e-08, -8.4052e-08,  6.1376e-09, -4.9511e-08,\n",
       "            -8.7771e-08, -6.0915e-08, -8.1088e-08,  1.2004e-08,  2.0366e-09,\n",
       "             4.1156e-08, -9.7704e-08,  7.9362e-08, -3.6721e-08,  5.3298e-08,\n",
       "            -1.2995e-08, -1.9793e-08,  1.1543e-08, -6.2727e-08, -1.6289e-07,\n",
       "            -4.2640e-09, -8.5789e-08, -1.0354e-08,  2.2406e-08, -6.4684e-08,\n",
       "            -5.1855e-08,  7.0804e-08,  3.2945e-08,  1.3754e-07,  1.5709e-08,\n",
       "            -3.0014e-08, -2.5384e-08, -6.3706e-08, -9.2150e-08,  6.4324e-08,\n",
       "             4.3844e-08,  1.2813e-07,  1.6103e-08,  1.1328e-08,  1.6905e-08,\n",
       "             1.8730e-08,  5.0347e-08, -1.4173e-07,  2.4865e-08,  6.8904e-08,\n",
       "             6.9547e-08, -9.5625e-08,  6.1837e-09,  2.8315e-08,  4.2313e-09,\n",
       "            -6.0389e-08,  1.5719e-08,  2.6076e-08,  3.4211e-08, -1.8465e-08,\n",
       "             4.2284e-08, -1.3315e-08, -1.4719e-08,  6.9287e-08,  1.8887e-08,\n",
       "             4.0599e-08, -5.2342e-08,  4.3565e-08,  9.0070e-08, -2.2359e-08,\n",
       "             7.2359e-08,  3.7469e-08,  1.9058e-08, -5.3787e-09,  2.0810e-08,\n",
       "             4.2025e-08,  2.5554e-08, -1.6463e-08,  4.0233e-09, -2.4129e-08,\n",
       "             1.8799e-08,  5.7812e-08,  4.6824e-08, -3.2813e-09, -6.0451e-08,\n",
       "            -8.7542e-08,  9.8745e-09, -1.0205e-07, -3.9553e-08,  3.6110e-08,\n",
       "            -6.6627e-08, -1.4104e-07,  4.3398e-08, -2.5668e-08, -2.3702e-08,\n",
       "            -9.3544e-09, -6.4574e-08,  7.0137e-08,  3.6968e-08, -4.0015e-08,\n",
       "             6.7166e-08,  1.7121e-08,  1.5576e-08, -1.8620e-08,  5.3561e-08,\n",
       "             1.4791e-08, -2.1058e-09, -4.6871e-08,  7.9705e-08,  2.3866e-08,\n",
       "            -1.2120e-08,  1.6961e-08, -1.1032e-07,  1.0434e-08, -7.3607e-08,\n",
       "             1.2543e-08, -2.9041e-09, -7.0867e-09,  5.6039e-08,  7.3975e-08,\n",
       "            -5.8199e-08, -7.8700e-08, -3.2965e-08, -4.0205e-10,  2.0980e-08,\n",
       "            -5.7340e-08, -4.6513e-08,  6.6660e-09, -7.4112e-08, -1.2390e-08,\n",
       "             1.7753e-07,  6.7756e-08, -2.3907e-08, -1.9613e-08, -7.7924e-09,\n",
       "            -5.5572e-08,  2.3169e-08,  3.7665e-08, -3.8246e-08,  1.4883e-08,\n",
       "            -5.2900e-08, -6.3407e-08,  9.0784e-09,  9.9105e-09,  2.1796e-09,\n",
       "            -1.5974e-08, -1.5400e-08,  4.1766e-09, -2.1938e-09, -2.0008e-08,\n",
       "            -4.1089e-10, -6.1681e-09, -2.9396e-10,  1.5403e-08,  6.0302e-09,\n",
       "             2.2822e-08, -1.5743e-09,  1.5814e-07,  2.4643e-08,  6.9488e-09,\n",
       "             6.4437e-08,  1.0359e-09, -4.3629e-08,  9.0634e-08,  5.0441e-08,\n",
       "             2.6758e-08, -4.4082e-09, -2.6965e-09, -1.0647e-07, -5.2055e-08,\n",
       "             3.7566e-08, -3.5094e-08,  2.1668e-09,  9.7634e-09, -3.4304e-08,\n",
       "             2.3454e-08,  3.4692e-09,  2.5383e-08,  2.1467e-09,  9.7852e-08,\n",
       "            -5.3630e-08,  3.8176e-08,  1.4436e-08, -3.6440e-08,  8.4263e-09,\n",
       "            -4.6477e-08, -1.5099e-08,  6.8723e-08,  2.8033e-09,  5.1769e-08,\n",
       "             2.4624e-08, -6.7754e-08,  1.0097e-08, -1.3230e-07,  1.8443e-08,\n",
       "            -3.6315e-08,  2.9031e-08, -8.4068e-09, -8.6461e-08,  8.9739e-09,\n",
       "             1.5295e-08,  6.7038e-10, -6.1612e-08,  1.3203e-07, -9.1020e-09,\n",
       "            -1.0828e-08, -3.7457e-08,  3.1056e-08,  2.2947e-08,  2.3087e-08,\n",
       "            -8.3342e-08,  3.2087e-08, -1.8372e-08, -1.9631e-08,  2.5748e-08,\n",
       "             1.2323e-08,  1.2164e-08,  2.3566e-10, -1.4565e-09, -6.2687e-09,\n",
       "             2.4200e-08,  8.0856e-09, -6.5645e-09,  8.2613e-09,  3.1298e-08,\n",
       "            -2.3110e-08, -3.6431e-08, -5.4039e-08, -5.5977e-08, -1.4945e-08,\n",
       "            -3.7406e-08, -2.7063e-08,  2.0595e-08, -3.5245e-08, -1.9268e-08,\n",
       "            -5.3686e-08, -5.4125e-08, -9.4075e-09, -1.0089e-08, -4.1229e-08,\n",
       "             9.9159e-09,  1.1491e-07, -9.0023e-09, -1.6032e-08, -3.1372e-08,\n",
       "            -2.5979e-09,  1.4120e-08,  4.5175e-08, -5.7447e-08, -3.7500e-09,\n",
       "            -1.9060e-08, -3.1350e-08, -1.5723e-08,  4.1728e-09, -2.7814e-10,\n",
       "             9.5701e-09, -1.8696e-08, -2.3724e-08,  3.2696e-08, -4.9033e-08,\n",
       "             9.8842e-09, -2.6935e-08, -1.2278e-08, -7.0643e-08,  2.1755e-09,\n",
       "             3.3649e-08, -1.4225e-08,  6.0402e-08,  6.2646e-09,  5.1528e-08,\n",
       "             4.5441e-08, -6.7995e-09, -4.1314e-08,  1.0419e-08,  2.3608e-08,\n",
       "             7.7074e-08, -3.7881e-08, -1.0255e-08,  6.7911e-08,  2.7336e-08,\n",
       "            -2.4194e-08,  4.4206e-09,  7.7795e-08,  4.4286e-09,  5.9936e-09,\n",
       "             2.5861e-08, -6.4720e-09, -9.3648e-09,  2.0947e-08, -5.9695e-08,\n",
       "             1.0185e-08, -8.9654e-09,  9.6535e-09,  1.2279e-08,  5.0782e-09,\n",
       "            -4.0844e-08,  1.9815e-08,  8.9934e-09, -2.1680e-08,  1.6895e-08,\n",
       "            -3.5403e-09, -7.5708e-08, -2.5647e-09, -5.0499e-09,  1.1391e-07,\n",
       "            -1.4411e-09,  2.5195e-08, -1.8564e-07,  3.6797e-08,  8.4273e-09,\n",
       "             1.6140e-08, -1.3029e-07,  2.5610e-08, -1.4577e-08,  1.8105e-08,\n",
       "            -3.2524e-08,  3.1995e-08,  4.1791e-08,  6.6777e-09,  5.4866e-08,\n",
       "             3.3037e-10, -4.2258e-09, -4.8849e-08, -2.5705e-08,  9.0139e-09,\n",
       "             5.8746e-09, -1.2344e-09, -3.2681e-08, -6.4625e-08, -7.1491e-08,\n",
       "            -5.5286e-08,  3.6482e-08,  2.6473e-08, -1.3291e-07,  1.3454e-08,\n",
       "             1.2889e-07,  6.9034e-08, -2.7455e-09, -3.2577e-08, -2.6690e-08,\n",
       "             5.3312e-08, -7.0688e-09, -4.8855e-08,  1.1363e-08, -4.7679e-08,\n",
       "             2.2680e-08,  2.7527e-08, -5.9292e-09,  6.3861e-09, -2.6203e-08,\n",
       "             2.6340e-08, -6.3358e-08,  2.3444e-08, -1.4622e-08, -1.5191e-08,\n",
       "             6.5595e-08,  5.2453e-08, -1.0089e-08, -1.1785e-08, -2.6563e-08,\n",
       "            -3.3174e-08, -2.1836e-08,  2.9459e-08,  1.5894e-08, -1.0961e-07,\n",
       "             8.2287e-08,  6.0951e-09,  5.6053e-08, -1.8740e-09,  7.5152e-08,\n",
       "             2.7611e-08,  6.6783e-09, -3.9900e-08, -2.0614e-08, -5.9875e-08,\n",
       "             5.8690e-09, -2.9515e-08,  6.7473e-09, -1.7448e-08, -1.3582e-07,\n",
       "             1.6394e-08, -6.3962e-08,  1.9723e-08, -3.1296e-08,  8.6056e-09,\n",
       "             1.1656e-08, -3.5341e-08,  7.8705e-09, -8.4777e-08,  1.5716e-08,\n",
       "             9.6222e-10, -3.3279e-08, -8.1465e-08,  1.6442e-08,  7.5084e-09,\n",
       "            -4.6722e-08,  8.7417e-09,  5.9372e-08, -2.6095e-08,  9.5647e-09,\n",
       "            -4.2630e-09, -3.5422e-08, -1.7896e-08,  6.8271e-09,  1.3898e-08,\n",
       "            -6.0490e-08, -1.9089e-08,  4.9091e-08, -1.7027e-08, -7.8599e-08,\n",
       "             7.4892e-08, -5.8711e-08, -6.3413e-08,  2.9654e-08,  2.1028e-08,\n",
       "             8.5768e-08, -1.4101e-08, -2.4329e-08, -1.2011e-08, -5.3836e-09,\n",
       "            -7.0986e-08,  3.8306e-08, -4.3250e-08,  3.5297e-10,  1.7075e-08,\n",
       "             4.7497e-11,  1.5706e-07, -3.5758e-08,  3.6670e-09, -2.5310e-09,\n",
       "            -6.3605e-08, -9.4255e-09, -2.1262e-08, -1.2943e-08, -1.4444e-08,\n",
       "             2.0065e-08, -1.4580e-08,  3.2430e-08, -3.3012e-08,  9.7239e-08,\n",
       "             8.3454e-08, -2.4677e-08,  6.4180e-08,  1.2717e-09,  4.7714e-08,\n",
       "             5.9685e-09, -1.2428e-08,  1.2670e-07,  5.4942e-08, -1.0855e-07,\n",
       "            -1.3176e-08,  3.9268e-08, -1.9453e-08, -2.1393e-08, -1.2307e-07,\n",
       "             6.4928e-08,  3.8458e-08,  2.3723e-08, -4.5213e-08, -6.8803e-09,\n",
       "             1.5198e-10, -7.1653e-08, -8.9344e-09,  1.8108e-08, -8.2359e-08,\n",
       "             2.2992e-08, -9.7177e-09,  5.3267e-08,  8.8507e-08, -8.0053e-08,\n",
       "             5.8493e-08,  2.4904e-08,  1.4135e-08, -1.7963e-08, -3.5842e-10,\n",
       "            -2.2588e-08, -2.4929e-08,  6.3189e-08, -3.4597e-08, -5.9787e-08,\n",
       "             5.4175e-08,  3.1816e-08, -3.7104e-08, -2.9991e-08,  2.4852e-08,\n",
       "            -3.6331e-08, -4.4701e-08, -9.0117e-09, -8.8204e-08, -5.2978e-08,\n",
       "             3.3396e-08,  3.3340e-08,  2.0737e-08,  3.3946e-08,  1.4128e-08,\n",
       "             1.2947e-08, -1.0574e-08,  3.2275e-08, -1.4653e-08,  3.4336e-09,\n",
       "            -1.1658e-08,  2.5793e-08,  4.9407e-08, -1.6617e-08,  1.2580e-08,\n",
       "             5.5505e-10, -7.4965e-09, -5.4725e-08,  1.8706e-08,  2.5103e-08,\n",
       "             3.6819e-08, -1.1854e-07, -1.2154e-08,  9.3976e-08, -1.1473e-08,\n",
       "            -4.1944e-08, -5.3748e-08, -2.1925e-08, -6.6739e-09,  1.6469e-08]),\n",
       "    'exp_avg_sq': tensor([1.6020e-14, 6.6769e-15, 7.1517e-15, 1.5462e-16, 1.9400e-15, 2.4672e-15,\n",
       "            6.7839e-15, 5.1825e-15, 2.1811e-15, 3.0151e-15, 5.5798e-15, 7.2064e-15,\n",
       "            3.6653e-15, 1.6309e-14, 1.2483e-15, 1.2772e-16, 2.1926e-15, 6.6398e-15,\n",
       "            5.1270e-15, 1.0619e-15, 8.6889e-15, 4.2747e-15, 1.0365e-13, 3.2061e-15,\n",
       "            1.5026e-15, 8.4067e-15, 1.1717e-14, 1.2315e-14, 1.2449e-14, 5.1811e-15,\n",
       "            8.6869e-15, 5.3474e-15, 5.1724e-15, 1.6091e-15, 7.6834e-15, 2.0885e-14,\n",
       "            2.8736e-15, 8.4507e-16, 2.1667e-16, 6.0620e-15, 3.5154e-15, 1.1742e-14,\n",
       "            3.6732e-15, 4.9880e-17, 4.4295e-15, 1.7380e-15, 4.7427e-15, 1.3877e-14,\n",
       "            8.7675e-16, 3.4795e-16, 2.1351e-15, 2.1470e-15, 5.3428e-15, 3.6828e-15,\n",
       "            1.4956e-15, 1.1746e-14, 7.9907e-15, 2.3102e-15, 5.3711e-16, 2.3162e-16,\n",
       "            3.8079e-15, 8.7360e-16, 1.2250e-15, 1.7004e-14, 1.1155e-14, 2.1142e-16,\n",
       "            1.5669e-15, 4.5313e-15, 3.5106e-16, 1.5493e-15, 1.4476e-16, 5.9105e-15,\n",
       "            1.0857e-16, 7.0077e-16, 2.2426e-16, 6.5091e-15, 2.9086e-15, 3.2519e-16,\n",
       "            1.8682e-14, 6.0981e-15, 3.3338e-15, 3.9471e-15, 1.0861e-16, 3.8198e-15,\n",
       "            1.0237e-14, 8.7073e-15, 1.1330e-14, 1.5921e-15, 4.0523e-16, 2.7459e-15,\n",
       "            1.4636e-15, 3.0086e-15, 6.1870e-15, 2.7745e-15, 3.9780e-15, 1.2781e-14,\n",
       "            6.9391e-15, 3.7091e-15, 9.5353e-15, 4.7783e-15, 2.2267e-15, 6.8487e-15,\n",
       "            6.4869e-15, 1.6435e-14, 4.2960e-14, 1.1390e-14, 7.4618e-15, 7.2410e-15,\n",
       "            1.9615e-15, 1.3514e-15, 4.4063e-16, 4.2889e-15, 4.7838e-15, 9.1190e-16,\n",
       "            3.7557e-16, 4.8204e-16, 1.2094e-14, 4.9107e-16, 2.0721e-14, 3.9885e-15,\n",
       "            1.3184e-15, 4.3324e-15, 7.4622e-15, 4.1432e-15, 4.1822e-16, 7.4490e-15,\n",
       "            1.4158e-14, 2.4654e-16, 4.6920e-17, 1.2649e-14, 2.8762e-16, 9.9288e-15,\n",
       "            6.8130e-16, 1.5109e-15, 6.6919e-17, 4.1204e-15, 6.8228e-15, 3.3074e-15,\n",
       "            1.0554e-15, 3.8900e-15, 6.4478e-15, 2.7893e-16, 1.8356e-15, 1.7973e-16,\n",
       "            7.8636e-15, 9.1501e-17, 1.1085e-14, 7.1853e-15, 3.2984e-15, 7.4532e-15,\n",
       "            5.3792e-15, 1.4268e-14, 1.2493e-16, 4.5628e-17, 1.5121e-14, 4.4808e-15,\n",
       "            4.4709e-15, 3.8858e-15, 2.1370e-15, 4.0539e-14, 2.5290e-14, 2.9798e-14,\n",
       "            2.5502e-15, 1.7155e-15, 1.1070e-15, 3.3413e-15, 1.3314e-16, 1.9759e-15,\n",
       "            4.5117e-16, 3.1612e-15, 6.6354e-16, 1.5819e-14, 5.3276e-15, 6.2233e-15,\n",
       "            5.9736e-16, 3.2128e-15, 6.3661e-15, 9.8846e-16, 1.0496e-14, 1.0831e-14,\n",
       "            5.5512e-15, 3.4368e-15, 5.7350e-15, 2.6964e-16, 1.2641e-14, 6.0724e-15,\n",
       "            1.0567e-14, 2.6512e-15, 5.8665e-15, 2.6484e-15, 3.4735e-16, 1.1846e-14,\n",
       "            1.2192e-15, 6.0240e-15, 1.7591e-14, 4.3771e-15, 2.8663e-16, 1.9335e-14,\n",
       "            3.8908e-16, 2.2248e-16, 1.9924e-15, 5.7367e-16, 7.5712e-15, 1.3494e-14,\n",
       "            7.0135e-15, 7.9000e-15, 1.5749e-14, 9.2735e-17, 2.5854e-15, 9.0936e-17,\n",
       "            1.1300e-14, 4.1078e-15, 1.2382e-15, 1.7088e-15, 1.0193e-14, 5.5773e-15,\n",
       "            8.7853e-16, 1.5104e-16, 4.3020e-17, 9.6346e-16, 1.2795e-15, 4.5928e-16,\n",
       "            1.4707e-15, 4.0885e-16, 1.7867e-16, 1.7529e-15, 6.0507e-15, 6.9289e-15,\n",
       "            1.8776e-15, 4.9694e-15, 5.5218e-15, 1.1177e-14, 5.0964e-15, 2.9109e-15,\n",
       "            1.4271e-16, 2.2758e-14, 7.3405e-15, 4.5613e-15, 1.6606e-15, 8.0595e-16,\n",
       "            1.2700e-15, 6.1207e-15, 2.9703e-14, 4.8094e-17, 1.0289e-15, 1.6544e-15,\n",
       "            1.9563e-14, 2.6647e-15, 3.8988e-14, 5.3705e-16, 1.3334e-15, 5.1230e-16,\n",
       "            3.9120e-16, 5.2040e-16, 1.1608e-15, 3.4396e-16, 4.7428e-15, 2.7348e-15,\n",
       "            7.7370e-16, 3.0577e-15, 2.1413e-16, 3.0092e-15, 3.4455e-16, 1.8232e-14,\n",
       "            4.2188e-15, 4.4363e-15, 1.8696e-14, 5.9700e-15, 1.6701e-14, 9.6744e-15,\n",
       "            1.0122e-14, 4.5582e-15, 4.2907e-15, 5.0679e-16, 1.8049e-14, 2.6893e-16,\n",
       "            9.3787e-16, 4.4271e-15, 9.1481e-15, 2.7836e-15, 1.8943e-15, 5.8971e-14,\n",
       "            1.0134e-15, 3.2059e-15, 1.5498e-16, 2.0265e-14, 2.3228e-14, 6.0978e-15,\n",
       "            3.5112e-14, 1.0562e-14, 5.6375e-15, 5.8752e-15, 6.5422e-15, 2.4927e-16,\n",
       "            5.5303e-15, 6.2678e-15, 1.2158e-14, 4.3410e-15, 7.8678e-15, 1.5378e-14,\n",
       "            4.5569e-15, 6.6287e-15, 1.7127e-16, 7.6296e-15, 8.9783e-15, 3.4477e-15,\n",
       "            4.2279e-15, 1.2199e-15, 1.0302e-14, 5.5071e-15, 7.1171e-15, 8.3612e-15,\n",
       "            2.6100e-15, 2.5110e-14, 1.7695e-16, 7.6849e-15, 1.0458e-14, 5.1190e-15,\n",
       "            9.3889e-15, 2.4232e-14, 3.5017e-15, 4.8665e-15, 7.5761e-15, 1.9550e-16,\n",
       "            1.3280e-16, 6.6234e-16, 4.6108e-15, 3.3841e-14, 7.6732e-15, 3.8323e-15,\n",
       "            6.9714e-15, 3.5602e-15, 2.4685e-15, 4.6315e-15, 2.8329e-15, 4.8730e-15,\n",
       "            1.2202e-14, 4.9065e-16, 9.8763e-16, 3.8115e-16, 3.0051e-15, 2.1407e-15,\n",
       "            1.3869e-16, 4.8027e-15, 7.9451e-16, 1.2144e-15, 1.1293e-14, 3.4206e-15,\n",
       "            1.2852e-14, 3.0174e-16, 4.2762e-15, 8.3067e-15, 3.8004e-15, 1.3020e-16,\n",
       "            5.3781e-15, 1.4436e-15, 3.1773e-15, 2.8083e-16, 2.2494e-15, 2.2363e-15,\n",
       "            1.3082e-14, 2.7950e-14, 3.9297e-15, 2.6029e-15, 6.8781e-15, 4.8968e-15,\n",
       "            6.3061e-15, 1.5181e-14, 4.3860e-15, 1.1252e-14, 7.3179e-15, 1.5053e-14,\n",
       "            5.2066e-15, 2.5051e-14, 2.8365e-15, 1.9717e-14, 8.5229e-15, 6.3758e-15,\n",
       "            3.8198e-15, 8.4268e-15, 7.5969e-15, 4.5518e-16, 2.2575e-15, 2.1727e-15,\n",
       "            6.3846e-15, 7.0353e-16, 1.9238e-15, 1.1257e-14, 1.5460e-14, 1.1932e-15,\n",
       "            1.7674e-15, 4.3027e-16, 1.0499e-14, 1.5046e-15, 6.7984e-15, 8.6666e-16,\n",
       "            3.3088e-16, 1.4077e-16, 5.4563e-15, 8.9328e-15, 6.0750e-15, 3.5894e-15,\n",
       "            3.9675e-15, 5.2382e-15, 7.4203e-15, 5.2434e-15, 2.4088e-15, 3.3934e-16,\n",
       "            1.3454e-15, 1.3534e-15, 1.3920e-14, 2.0590e-15, 7.8767e-15, 1.8418e-15,\n",
       "            1.1955e-16, 2.3117e-15, 4.4092e-15, 5.1643e-16, 8.8334e-15, 1.2661e-14,\n",
       "            1.0791e-14, 5.4999e-15, 1.7277e-16, 1.3352e-14, 4.6665e-16, 1.8003e-15,\n",
       "            3.8617e-15, 5.1094e-16, 9.7552e-16, 1.0790e-15, 4.7997e-15, 1.0407e-16,\n",
       "            1.9116e-14, 7.7886e-15, 6.7493e-15, 1.1232e-15, 9.9725e-15, 2.9566e-14,\n",
       "            1.1718e-14, 6.0975e-16, 9.4295e-15, 6.9269e-16, 5.0373e-15, 4.5872e-15,\n",
       "            6.2102e-15, 4.0437e-14, 6.2575e-15, 5.4329e-16, 9.5223e-15, 3.7240e-15,\n",
       "            3.8740e-15, 1.4356e-14, 2.9370e-16, 8.8713e-16, 4.9262e-15, 2.8477e-15,\n",
       "            1.8335e-15, 8.9388e-16, 2.3173e-15, 1.7403e-14, 6.7954e-15, 7.8678e-16,\n",
       "            9.3161e-16, 3.8195e-15, 4.8116e-16, 4.1500e-15, 1.7682e-14, 4.4040e-15,\n",
       "            2.3804e-14, 3.3543e-15, 2.0034e-15, 2.6534e-15, 1.2483e-15, 8.9139e-15,\n",
       "            4.3764e-15, 1.1801e-14, 1.1798e-15, 4.7559e-16, 6.3686e-15, 3.2370e-15,\n",
       "            3.9640e-15, 3.3167e-15, 4.3270e-15, 3.7936e-15, 1.0222e-14, 1.3635e-16,\n",
       "            8.1763e-15, 1.4599e-15, 1.1328e-15, 5.8363e-15, 2.2828e-14, 7.1918e-15,\n",
       "            1.7323e-16, 2.8338e-16, 8.7778e-15, 1.0803e-14, 6.1105e-15, 1.2385e-15,\n",
       "            1.2542e-15, 1.4077e-14, 9.8282e-15, 3.9955e-16, 6.6677e-16, 5.2284e-15,\n",
       "            9.5582e-15, 2.5846e-15, 2.3756e-14, 3.5183e-15, 2.9835e-15, 2.4440e-14,\n",
       "            1.9791e-16, 2.8087e-15, 2.9024e-15, 1.4674e-14, 4.9529e-15, 2.3086e-15,\n",
       "            1.7674e-14, 3.3143e-16, 2.3621e-16, 6.0429e-15, 1.4400e-15, 5.4594e-15,\n",
       "            7.3528e-16, 9.6729e-16, 3.5554e-15, 9.0564e-15, 9.2058e-15, 6.9089e-15,\n",
       "            4.1967e-15, 5.9481e-15, 6.8476e-16, 1.6322e-16, 3.9693e-16, 5.6211e-16,\n",
       "            7.9246e-16, 7.7685e-15, 1.2972e-16, 7.0721e-16, 3.7291e-16, 3.8169e-15,\n",
       "            1.2075e-15, 8.3545e-16, 5.8257e-16, 1.8797e-14, 4.6500e-17, 6.8393e-15,\n",
       "            5.8697e-15, 4.7529e-15, 3.6101e-15, 9.7878e-15, 5.2145e-16, 6.1470e-15,\n",
       "            6.1984e-15, 8.1517e-15, 1.0476e-15, 8.4266e-15, 5.5487e-16, 3.6823e-16,\n",
       "            1.0183e-14, 3.5646e-15, 1.0472e-15, 3.8751e-15, 1.2335e-14, 1.6117e-16,\n",
       "            8.2874e-15, 2.3671e-16, 1.3860e-15, 3.5317e-16, 6.4546e-17, 3.6452e-15,\n",
       "            4.6168e-15, 5.3931e-16, 3.7064e-16, 1.6499e-16, 2.1400e-15, 2.3640e-14,\n",
       "            5.5237e-15, 2.8948e-15, 4.9423e-15, 8.5751e-15, 9.7636e-15, 4.6723e-15,\n",
       "            5.1963e-17, 1.9742e-15, 3.3831e-14, 8.4021e-15, 1.5184e-15, 1.1633e-14,\n",
       "            6.8869e-15, 1.9648e-15, 4.8309e-15, 1.6630e-14, 5.9836e-15, 1.1959e-14,\n",
       "            8.2060e-17, 6.5127e-15, 2.5842e-15, 1.4987e-14, 1.4754e-14, 3.0709e-15,\n",
       "            8.2891e-16, 4.1596e-16, 2.3310e-15, 1.4134e-15, 1.6767e-15, 3.0246e-15,\n",
       "            5.4690e-15, 1.7301e-15, 7.0804e-15, 3.8652e-15, 1.7533e-15, 3.6034e-15,\n",
       "            4.0097e-15, 7.7201e-15, 4.4587e-15, 1.3572e-14, 8.0842e-15, 1.4909e-15,\n",
       "            2.8815e-14, 2.6197e-15, 3.8547e-15, 1.0344e-16, 3.9824e-15, 2.3335e-16,\n",
       "            2.0200e-15, 1.5796e-15, 5.5249e-15, 1.1200e-15, 6.9275e-16, 3.6716e-14,\n",
       "            4.3802e-16, 3.5853e-15, 6.1302e-15, 3.9976e-17, 9.7986e-15, 1.8619e-15,\n",
       "            8.5544e-15, 3.2898e-16, 2.8341e-16, 2.8929e-16, 1.7033e-16, 2.2345e-15,\n",
       "            2.2057e-14, 1.9980e-15, 8.8204e-15, 7.2841e-15, 2.4540e-15, 4.9660e-15,\n",
       "            7.4043e-17, 6.1634e-15, 1.8070e-15, 6.0888e-15, 2.0099e-15, 1.2210e-14,\n",
       "            1.7464e-15, 2.4169e-15, 1.8657e-15, 1.2690e-15, 1.3981e-15, 1.1805e-14,\n",
       "            4.5037e-15, 7.5235e-15, 9.4062e-17, 1.5369e-15, 3.9019e-15, 1.9305e-16,\n",
       "            9.0663e-15, 4.0240e-15, 8.9753e-15, 6.3576e-16, 1.0929e-15, 7.7947e-15,\n",
       "            5.4747e-15, 2.6005e-15, 1.9144e-15, 4.0572e-15, 1.7151e-15, 3.2759e-15,\n",
       "            8.6042e-16, 2.5127e-16, 1.5417e-16, 5.8338e-15, 2.1150e-16, 3.8291e-16,\n",
       "            1.5393e-16, 8.9052e-16, 4.3318e-16, 4.7657e-15, 1.7696e-15, 7.4249e-15,\n",
       "            1.0099e-14, 4.6293e-15, 1.5666e-14, 4.6649e-15, 6.8410e-15, 5.5217e-15,\n",
       "            1.7252e-15, 1.6076e-15, 1.0997e-16, 6.3054e-16, 1.9821e-14, 1.0982e-14,\n",
       "            4.8977e-16, 9.6638e-15, 6.3634e-15, 1.1223e-14, 1.4103e-14, 5.3126e-15,\n",
       "            2.6606e-17, 1.9721e-16, 1.1781e-15, 9.0999e-14, 2.2674e-14, 3.0422e-14,\n",
       "            6.8542e-15, 2.8959e-15, 9.0562e-17, 3.0427e-15, 9.5377e-15, 7.3322e-15,\n",
       "            5.4770e-15, 4.7636e-16, 4.0310e-15, 1.2881e-16, 7.9145e-15, 2.4477e-16,\n",
       "            5.1626e-15, 2.4743e-14, 9.1031e-15, 1.3551e-14, 3.7154e-17, 7.7966e-15,\n",
       "            7.9522e-16, 1.5374e-14, 5.6762e-15, 1.2219e-14, 2.6011e-15, 1.7649e-15,\n",
       "            7.7405e-15, 3.6957e-16, 3.6714e-15, 1.6761e-14, 1.0030e-15, 3.8986e-16,\n",
       "            1.0858e-14, 2.0899e-15, 4.6397e-16, 1.4594e-15, 4.1784e-15, 1.1229e-14,\n",
       "            1.4962e-14, 6.9303e-15, 5.5458e-15, 1.6439e-15, 5.2646e-16, 1.4320e-14,\n",
       "            4.3722e-15, 3.3065e-15, 1.6876e-15, 5.8725e-15, 4.9316e-15, 4.9532e-15,\n",
       "            1.2537e-14, 6.4922e-15, 3.0812e-15, 2.8304e-15, 1.1629e-14, 3.7397e-15,\n",
       "            1.4987e-14, 9.4589e-15, 1.5129e-14, 2.7374e-15, 3.9585e-15, 1.2457e-14,\n",
       "            6.6828e-15, 4.5765e-16, 1.8526e-15, 6.0005e-15, 2.9522e-15, 3.0404e-15,\n",
       "            1.4245e-14, 6.3453e-15, 1.4388e-14, 1.1779e-14, 3.0046e-16, 6.7714e-15,\n",
       "            1.8387e-15, 6.7164e-15, 1.9209e-14, 2.4510e-16, 3.3294e-15, 7.7611e-15,\n",
       "            2.7580e-15, 1.1857e-14, 7.2110e-15, 1.7588e-15, 2.6154e-15, 2.3518e-15,\n",
       "            2.2223e-15, 8.0259e-17])},\n",
       "   63: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-1.1173e-07, -1.2438e-07, -2.4487e-08,  ..., -6.5064e-09,\n",
       "             -1.4837e-08,  2.0477e-09],\n",
       "            [-8.5136e-08, -1.1251e-07, -1.0350e-07,  ...,  3.5818e-09,\n",
       "              1.3375e-08,  2.3222e-08],\n",
       "            [-1.3348e-07, -1.9693e-07, -1.3671e-07,  ...,  1.7141e-08,\n",
       "              1.2729e-07,  6.3931e-08],\n",
       "            ...,\n",
       "            [-1.5431e-07, -2.3526e-07, -5.7663e-08,  ...,  5.3450e-09,\n",
       "              9.9372e-08,  3.9053e-08],\n",
       "            [-2.2952e-07, -2.6944e-07, -1.2238e-07,  ..., -8.1732e-09,\n",
       "             -8.1709e-08,  1.1902e-08],\n",
       "            [ 6.5471e-08,  1.3050e-07,  4.2828e-08,  ...,  9.1373e-09,\n",
       "              1.6727e-08,  3.3253e-10]]),\n",
       "    'exp_avg_sq': tensor([[2.1286e-14, 4.4813e-14, 7.0022e-15,  ..., 1.6789e-16, 1.8288e-15,\n",
       "             2.2758e-16],\n",
       "            [1.3232e-13, 2.5221e-13, 4.1839e-14,  ..., 3.9782e-16, 4.1538e-15,\n",
       "             1.2332e-15],\n",
       "            [1.9134e-13, 3.8691e-13, 5.6047e-14,  ..., 7.7283e-16, 9.3739e-15,\n",
       "             1.5031e-15],\n",
       "            ...,\n",
       "            [5.4648e-14, 1.6199e-13, 1.3382e-14,  ..., 4.3206e-16, 6.5192e-15,\n",
       "             1.0623e-15],\n",
       "            [1.2202e-13, 2.7707e-13, 3.1081e-14,  ..., 2.1125e-16, 2.9390e-15,\n",
       "             1.6140e-15],\n",
       "            [5.4681e-14, 8.9183e-14, 2.0010e-14,  ..., 6.3610e-16, 4.8026e-15,\n",
       "             7.3090e-16]])},\n",
       "   64: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([-1.2742e-07,  9.7382e-09,  5.8159e-08, -3.2967e-08,  3.1309e-07,\n",
       "             3.8280e-07, -1.8369e-07, -1.1118e-08,  1.1666e-07,  2.9225e-07,\n",
       "             1.6155e-07,  1.8939e-07,  2.2031e-08,  1.1347e-07, -1.0875e-08,\n",
       "            -3.2864e-07, -1.0559e-07, -2.9356e-07, -1.0360e-07, -1.8153e-08,\n",
       "             1.3872e-07, -8.2574e-08, -4.1260e-07,  1.4745e-07, -2.7741e-07,\n",
       "            -1.8724e-07,  1.7969e-07, -5.6970e-08,  1.5879e-07,  6.1261e-08,\n",
       "             2.0379e-08,  1.9052e-07, -9.0921e-08, -1.6046e-07,  1.2549e-07,\n",
       "            -8.4451e-08, -5.5718e-08,  4.0760e-08,  8.7458e-08, -2.4572e-08,\n",
       "             4.9941e-08, -7.6901e-08,  3.3855e-07,  1.8842e-07,  2.6027e-07,\n",
       "             4.4558e-07,  1.7269e-07, -4.7539e-07,  1.4328e-07, -2.2627e-07,\n",
       "            -2.6140e-07,  2.4450e-07,  2.4496e-07,  4.3832e-08, -5.3963e-08,\n",
       "            -3.4055e-08, -1.7881e-07, -1.8853e-08,  8.2433e-10,  1.0616e-07,\n",
       "            -1.2089e-07, -3.6745e-07,  2.1937e-07,  3.1197e-07, -1.6555e-07,\n",
       "            -2.9140e-07,  3.0491e-07,  2.1519e-08, -1.5994e-07, -2.2062e-07,\n",
       "            -7.3613e-08, -5.8529e-08,  7.4776e-08,  1.9186e-07, -7.5695e-08,\n",
       "             1.7671e-08, -2.6002e-07, -4.7128e-08,  1.1308e-07,  1.0999e-07,\n",
       "            -6.5117e-08,  1.5080e-07, -3.7359e-08,  1.9155e-07, -4.7057e-08,\n",
       "             8.3920e-08,  2.0848e-07, -1.9647e-07, -1.8335e-07,  7.1795e-08,\n",
       "            -1.8402e-07,  1.1390e-07, -1.9840e-07,  2.2879e-07,  1.7796e-07,\n",
       "            -9.8293e-08, -1.0005e-07,  1.8339e-07,  1.6192e-07, -1.9939e-07,\n",
       "             2.5288e-07,  8.5687e-08,  2.6558e-07,  1.1797e-07,  9.5255e-08,\n",
       "            -2.7356e-07, -1.5491e-07, -9.7361e-08, -3.1821e-08,  1.2293e-07,\n",
       "             3.4439e-07,  8.8001e-08,  1.8382e-07,  7.1528e-08, -3.3504e-07,\n",
       "            -1.6403e-07,  3.2199e-08, -1.8452e-07, -1.7961e-07,  5.6729e-09,\n",
       "            -2.5350e-07, -3.7252e-07, -9.5956e-08, -3.1089e-07, -6.0851e-08,\n",
       "            -3.6459e-07,  7.7646e-08, -2.2482e-07, -2.9088e-07, -3.2243e-07,\n",
       "             6.6919e-09,  9.5506e-08, -4.1441e-08,  2.6755e-07,  2.3169e-08,\n",
       "            -3.7231e-07,  6.7715e-08,  1.8984e-07, -8.8535e-08,  2.4557e-07,\n",
       "            -3.9203e-08, -8.8240e-08,  1.4962e-07, -1.5824e-07,  1.1272e-07,\n",
       "             2.2364e-07,  2.7934e-07,  1.1071e-07, -1.3985e-07,  7.0328e-08,\n",
       "            -3.0456e-07, -6.5871e-08, -3.4329e-08,  3.1071e-08,  1.9491e-07,\n",
       "             6.2176e-13,  2.5257e-07, -1.9380e-07,  3.1316e-09, -6.9890e-08,\n",
       "            -1.1959e-07, -3.5138e-07,  1.0021e-07, -1.3246e-07, -1.1908e-07,\n",
       "            -2.8925e-08,  1.1206e-07,  1.8691e-07, -1.7908e-07, -1.4483e-07,\n",
       "             2.9830e-07,  3.2306e-09,  1.0545e-07,  2.6594e-07, -1.2027e-07,\n",
       "            -5.0205e-08,  3.3788e-08,  1.6147e-07,  1.0715e-07,  2.1302e-08,\n",
       "            -1.3086e-07,  3.2592e-08, -1.0666e-07,  6.9932e-08,  1.2780e-07,\n",
       "             1.0628e-07, -1.3791e-07,  1.2408e-07, -3.7623e-08, -1.3572e-07,\n",
       "            -2.6533e-07, -1.8000e-07,  3.1356e-07,  4.6216e-07,  2.8592e-07,\n",
       "            -4.6527e-08,  8.4302e-08, -1.7540e-07, -2.6272e-07,  1.0601e-07]),\n",
       "    'exp_avg_sq': tensor([2.7584e-14, 1.0969e-13, 1.7356e-13, 1.5740e-13, 4.2359e-14, 7.0335e-14,\n",
       "            3.8248e-14, 5.3527e-14, 2.3779e-13, 4.0929e-14, 4.9006e-14, 3.6720e-14,\n",
       "            1.7950e-13, 7.2412e-14, 1.3187e-13, 1.1632e-13, 5.0509e-14, 1.0191e-13,\n",
       "            1.1570e-13, 6.9965e-14, 9.1325e-14, 7.1569e-14, 8.4614e-14, 5.5003e-14,\n",
       "            1.0966e-13, 8.4727e-14, 5.1328e-14, 7.4144e-14, 9.6169e-14, 2.7046e-14,\n",
       "            6.5125e-14, 3.0781e-14, 1.0649e-13, 3.8966e-14, 6.6265e-14, 2.5277e-13,\n",
       "            5.0202e-14, 3.0315e-14, 4.8762e-14, 4.7202e-14, 1.1459e-13, 1.5445e-13,\n",
       "            2.1467e-13, 1.5321e-13, 6.7060e-14, 1.5192e-13, 7.7348e-14, 1.6798e-13,\n",
       "            8.8814e-14, 1.0545e-13, 1.3516e-13, 1.5637e-13, 1.1353e-13, 1.4534e-13,\n",
       "            9.9939e-14, 2.1391e-13, 1.3697e-13, 7.3860e-14, 9.1699e-14, 1.2507e-13,\n",
       "            1.6844e-13, 9.7526e-14, 8.5783e-14, 6.2062e-14, 8.5660e-14, 2.6693e-13,\n",
       "            7.4351e-14, 3.9793e-14, 1.0551e-13, 1.7564e-13, 2.1835e-13, 6.9116e-14,\n",
       "            5.8334e-14, 5.1884e-14, 8.6090e-14, 5.5272e-14, 1.1691e-13, 1.5238e-13,\n",
       "            1.8491e-13, 5.7382e-14, 3.0930e-14, 1.8092e-13, 3.8718e-14, 5.9807e-14,\n",
       "            5.4726e-14, 2.5538e-14, 1.7969e-13, 1.7722e-14, 6.2911e-14, 1.2905e-13,\n",
       "            8.8685e-14, 1.3122e-13, 1.3079e-13, 9.6278e-14, 6.5552e-14, 1.3064e-13,\n",
       "            6.5016e-14, 7.8758e-14, 1.3110e-13, 1.0021e-13, 1.7086e-13, 3.9659e-14,\n",
       "            8.4656e-14, 1.2596e-13, 7.3820e-14, 4.6343e-14, 6.1755e-14, 8.4968e-14,\n",
       "            1.3771e-13, 1.7155e-13, 1.2699e-13, 9.2060e-14, 1.6661e-13, 2.5150e-14,\n",
       "            1.7771e-13, 1.0099e-13, 1.5652e-13, 7.5111e-14, 5.5933e-14, 1.6384e-13,\n",
       "            7.8455e-14, 1.1595e-13, 5.9065e-14, 9.6940e-14, 8.0873e-14, 4.1506e-14,\n",
       "            4.7602e-14, 1.0313e-13, 7.8078e-14, 5.9926e-14, 1.3258e-13, 7.8930e-14,\n",
       "            1.1831e-13, 7.9708e-14, 4.3199e-14, 1.7763e-13, 7.9873e-14, 2.3740e-13,\n",
       "            7.6519e-14, 9.7489e-14, 5.1102e-14, 4.7972e-14, 6.3239e-14, 1.1447e-13,\n",
       "            4.1298e-14, 6.2576e-14, 1.0533e-13, 5.4313e-14, 7.5138e-14, 6.8067e-14,\n",
       "            1.1887e-13, 4.4726e-14, 2.0245e-13, 4.5070e-14, 9.4029e-14, 1.1618e-13,\n",
       "            1.3768e-13, 8.5931e-14, 4.9738e-14, 1.3751e-13, 8.4269e-14, 7.4349e-14,\n",
       "            6.0000e-14, 1.5344e-13, 1.3741e-13, 6.8332e-14, 5.9928e-14, 1.6550e-13,\n",
       "            1.3968e-13, 4.8161e-14, 3.0530e-13, 9.4295e-14, 8.7404e-14, 7.3416e-14,\n",
       "            4.9173e-14, 1.1218e-13, 4.2809e-14, 1.7104e-13, 4.7808e-14, 7.5482e-14,\n",
       "            6.4288e-14, 3.7312e-14, 1.3636e-13, 1.0586e-13, 8.5407e-14, 6.4404e-14,\n",
       "            2.2980e-13, 9.3169e-14, 4.3634e-14, 2.4814e-14, 5.6586e-14, 5.9625e-14,\n",
       "            1.8590e-13, 1.1113e-13, 1.6818e-13, 6.3649e-14, 8.1729e-14, 1.0099e-13,\n",
       "            1.6784e-13, 5.1648e-14])},\n",
       "   78: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 3.0789e-08, -9.3355e-08,  9.4233e-08,  ..., -4.6837e-08,\n",
       "              1.2006e-07,  4.4967e-08],\n",
       "            [ 3.3033e-08,  1.1863e-07, -3.9215e-08,  ..., -3.8845e-07,\n",
       "              3.6091e-07, -6.2789e-08],\n",
       "            [ 1.7480e-07,  1.9784e-07,  1.9245e-07,  ..., -2.1580e-07,\n",
       "              3.0141e-07,  5.0199e-09],\n",
       "            ...,\n",
       "            [ 1.6618e-07,  3.3341e-07,  1.8562e-07,  ...,  1.2601e-07,\n",
       "              2.2334e-07, -9.3234e-08],\n",
       "            [-2.5415e-07,  4.1142e-07, -2.6449e-07,  ...,  5.7630e-07,\n",
       "             -3.7926e-07, -2.8867e-07],\n",
       "            [-2.1120e-07,  6.8370e-09, -2.9887e-07,  ...,  1.1941e-07,\n",
       "             -3.2642e-07, -1.4767e-08]]),\n",
       "    'exp_avg_sq': tensor([[3.9510e-14, 8.5242e-14, 9.7782e-14,  ..., 1.8009e-13, 7.3150e-14,\n",
       "             3.1790e-14],\n",
       "            [5.0558e-14, 2.3002e-13, 1.6528e-13,  ..., 2.4583e-13, 1.6149e-13,\n",
       "             4.3361e-14],\n",
       "            [3.3431e-14, 1.5538e-13, 9.1687e-14,  ..., 2.4462e-13, 1.3343e-13,\n",
       "             2.1225e-14],\n",
       "            ...,\n",
       "            [9.7275e-14, 1.8871e-13, 1.7116e-13,  ..., 2.8295e-13, 1.9133e-13,\n",
       "             9.5904e-14],\n",
       "            [1.5520e-13, 7.6005e-14, 3.7074e-13,  ..., 1.1915e-13, 9.1386e-14,\n",
       "             7.9408e-14],\n",
       "            [3.8581e-14, 5.3912e-14, 1.1045e-13,  ..., 1.2340e-13, 4.6052e-14,\n",
       "             1.5806e-14]])},\n",
       "   79: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 6.3383e-08, -4.6503e-07, -2.4543e-07, -9.5637e-08,  1.9634e-07,\n",
       "             2.1936e-07, -3.1215e-08, -5.3771e-08,  1.5885e-08, -4.7726e-07,\n",
       "            -2.9167e-08,  6.1245e-08, -7.3796e-08,  2.4237e-07, -2.4139e-07,\n",
       "             2.3744e-07,  8.8736e-08, -3.1746e-07,  9.1911e-08, -1.4136e-08,\n",
       "             2.0239e-07, -7.6148e-08,  1.1746e-07, -5.3624e-07, -8.3543e-08,\n",
       "             2.3655e-07, -4.3271e-08, -3.4144e-07, -1.3689e-07, -2.5303e-08,\n",
       "             5.7629e-09,  2.4162e-07,  1.3720e-07,  1.4291e-07, -1.3982e-09,\n",
       "             7.8044e-08, -1.8616e-07,  3.0926e-07,  3.0066e-08,  1.1707e-07,\n",
       "            -3.6560e-08, -2.5628e-07, -1.6230e-07, -3.3520e-08,  1.6956e-07,\n",
       "            -1.1164e-07,  3.4118e-08, -2.1828e-07, -1.6724e-07,  2.2100e-07,\n",
       "             1.2051e-07,  1.1364e-08, -5.4208e-08, -9.8751e-08, -2.0559e-07,\n",
       "             8.3062e-08,  2.5558e-07, -2.2777e-08,  1.9984e-07, -5.4356e-08,\n",
       "            -3.4099e-08,  1.4737e-07,  2.4435e-07,  1.8090e-08, -1.0111e-08,\n",
       "             5.4220e-08,  3.4675e-07,  1.3479e-07,  3.5426e-08, -2.3404e-08,\n",
       "             7.7902e-08,  5.1081e-07, -6.1011e-08,  2.2324e-07, -1.5926e-07,\n",
       "             3.8800e-08,  3.3940e-07,  2.5310e-07,  2.8613e-07, -2.9432e-08,\n",
       "             3.5979e-08,  2.2985e-08, -1.4163e-07, -9.4883e-08, -7.6391e-08,\n",
       "             2.4676e-07,  2.1303e-08,  2.3370e-07, -1.5264e-07,  2.9570e-09,\n",
       "            -1.3118e-07,  3.9157e-08,  1.5477e-07,  2.2980e-07,  2.8272e-07,\n",
       "             1.7189e-07,  1.2334e-08, -3.2286e-07,  1.5280e-07, -1.0920e-07,\n",
       "             3.1469e-07, -1.8336e-07,  2.3372e-08,  3.1413e-09, -2.1516e-08,\n",
       "             3.0129e-07, -3.3294e-08,  6.2219e-08, -1.4228e-07,  8.4301e-08,\n",
       "             2.0093e-07, -1.6616e-07, -2.1792e-07, -3.7750e-08,  8.2714e-08,\n",
       "             3.3632e-07,  2.5540e-08, -1.5214e-07, -5.5948e-08, -5.7983e-08,\n",
       "            -1.5242e-08,  7.9123e-08, -6.1815e-08,  2.1754e-07, -4.6364e-07,\n",
       "            -2.3290e-07,  1.4664e-07, -5.4894e-08, -3.2571e-07, -3.7355e-08,\n",
       "            -1.2403e-07,  2.8247e-07,  1.0904e-07,  1.3085e-07,  1.9281e-07,\n",
       "            -2.9442e-09,  1.1415e-07, -9.1842e-09, -1.2557e-07,  6.2276e-08,\n",
       "            -1.6975e-07, -6.0332e-09, -4.2827e-07, -1.9377e-07, -1.5177e-07,\n",
       "            -1.8315e-07, -5.7941e-08,  7.3712e-08,  9.1550e-08, -1.2330e-09,\n",
       "             1.5999e-07,  3.3688e-07,  3.2983e-07,  8.1841e-08,  2.9135e-08,\n",
       "            -1.4148e-08,  1.1024e-07, -9.6684e-08, -1.1838e-07, -1.0190e-07,\n",
       "             1.4159e-07, -1.3978e-07, -6.1302e-08, -1.8147e-07, -4.0537e-08,\n",
       "             1.6235e-07,  2.9643e-08,  5.8196e-08,  1.3440e-07, -5.8688e-08,\n",
       "             2.5236e-09,  8.5777e-08, -3.2733e-07, -2.5049e-08,  2.2609e-09,\n",
       "            -5.6013e-08,  7.9230e-08, -9.9931e-08, -1.1816e-07, -1.4678e-07,\n",
       "             4.7533e-07,  3.5550e-08, -8.4848e-08, -1.1252e-07,  3.3136e-07,\n",
       "             6.7361e-08, -1.6989e-07,  6.3845e-08, -1.2803e-07,  2.0863e-07,\n",
       "             3.4758e-08, -5.6223e-08, -1.2623e-08, -3.3850e-07,  3.0823e-09,\n",
       "             3.6462e-07, -3.5133e-07,  1.8542e-07, -1.6900e-07, -1.1249e-07,\n",
       "            -4.9868e-08, -2.3538e-07, -5.9743e-08, -1.2109e-07,  2.6218e-07,\n",
       "            -2.2104e-07, -1.9795e-07, -1.5879e-08, -4.3164e-08,  1.4241e-07,\n",
       "             3.2155e-08, -2.3314e-07, -1.5087e-07,  1.7044e-08, -7.6674e-08,\n",
       "            -5.3133e-08, -1.7174e-08, -1.4050e-07, -6.7974e-08, -1.0545e-07,\n",
       "             1.3691e-07,  2.6168e-07,  2.7002e-08, -1.3093e-07, -2.7966e-07,\n",
       "             1.8109e-07,  5.6466e-08,  9.8831e-08,  2.9142e-07, -1.0839e-07,\n",
       "            -1.2544e-07,  8.0388e-08,  2.5744e-07, -1.3779e-07, -1.8958e-07,\n",
       "             3.7638e-07,  1.4089e-07,  2.7068e-07,  1.4128e-07,  2.6843e-07,\n",
       "            -2.7043e-08,  6.4028e-08,  1.6708e-07, -1.2279e-07, -1.4718e-07,\n",
       "             2.8220e-07, -4.2919e-07, -2.5194e-07,  3.0792e-09,  7.6225e-08,\n",
       "            -5.4850e-08,  3.6428e-07,  1.1756e-07, -2.3824e-07, -1.4556e-07,\n",
       "             2.9068e-08]),\n",
       "    'exp_avg_sq': tensor([5.1436e-14, 6.2464e-14, 9.2700e-14, 8.4994e-14, 9.9346e-14, 1.1206e-13,\n",
       "            6.4498e-14, 5.2774e-14, 4.5104e-14, 9.9432e-14, 7.6744e-14, 4.2168e-14,\n",
       "            5.6855e-14, 7.2713e-14, 3.8314e-14, 8.1252e-14, 6.5803e-14, 4.9209e-14,\n",
       "            5.1466e-14, 7.3956e-14, 5.1504e-14, 6.0686e-14, 5.4828e-14, 1.0018e-13,\n",
       "            5.7332e-14, 6.0277e-14, 4.0573e-14, 9.3771e-14, 4.7589e-14, 9.8525e-14,\n",
       "            4.4919e-14, 4.1524e-14, 4.9124e-14, 5.3557e-14, 7.2050e-14, 8.9582e-14,\n",
       "            7.5938e-14, 1.0629e-13, 5.1434e-14, 1.5283e-13, 3.9801e-14, 5.4736e-14,\n",
       "            5.8745e-14, 5.6630e-14, 8.5097e-14, 1.1041e-13, 1.3568e-13, 1.3002e-13,\n",
       "            7.3046e-14, 3.8757e-14, 2.8484e-14, 8.0323e-14, 7.9717e-14, 5.3495e-14,\n",
       "            4.3057e-14, 3.5646e-14, 9.8837e-14, 3.3719e-14, 8.1848e-14, 4.2715e-14,\n",
       "            1.0371e-13, 4.2256e-14, 5.7012e-14, 4.3193e-14, 8.0894e-14, 4.9053e-14,\n",
       "            1.4868e-13, 3.0671e-14, 4.5415e-14, 4.0280e-14, 8.2178e-14, 8.0477e-14,\n",
       "            8.4714e-14, 5.3992e-14, 5.6926e-14, 4.7249e-14, 7.2087e-14, 9.9113e-14,\n",
       "            7.1042e-14, 6.2659e-14, 7.3848e-14, 1.0785e-13, 6.3664e-14, 4.8417e-14,\n",
       "            2.8371e-14, 6.2139e-14, 9.4169e-14, 4.4455e-14, 7.6597e-14, 4.8751e-14,\n",
       "            1.3022e-13, 7.7951e-14, 6.8913e-14, 3.7634e-14, 5.6279e-14, 2.1998e-14,\n",
       "            4.5488e-14, 9.4234e-14, 6.2376e-14, 1.8219e-14, 5.6582e-14, 3.5766e-14,\n",
       "            6.2952e-14, 6.1615e-14, 5.3763e-14, 5.0509e-14, 7.0892e-14, 2.7515e-14,\n",
       "            7.8483e-14, 4.9185e-14, 4.3354e-14, 7.5285e-14, 7.4518e-14, 5.7505e-14,\n",
       "            4.3585e-14, 7.3101e-14, 3.5753e-14, 5.0128e-14, 1.0071e-13, 3.8366e-14,\n",
       "            8.8575e-14, 6.8174e-14, 6.9820e-14, 1.2693e-13, 6.2405e-14, 6.5199e-14,\n",
       "            7.6213e-14, 9.3194e-14, 4.3258e-14, 8.5599e-14, 9.2481e-14, 5.2157e-14,\n",
       "            1.3688e-13, 7.2266e-14, 4.7153e-14, 1.5828e-13, 4.5910e-14, 1.0704e-13,\n",
       "            1.1009e-13, 8.4666e-14, 1.0023e-13, 1.0054e-13, 1.0845e-13, 5.9839e-14,\n",
       "            4.9067e-14, 3.1818e-14, 9.4402e-14, 1.9383e-13, 7.9335e-14, 3.7219e-14,\n",
       "            6.4026e-14, 1.2725e-13, 6.3025e-14, 7.1013e-14, 3.8767e-14, 6.4961e-14,\n",
       "            1.6209e-13, 3.8028e-14, 6.0102e-14, 5.9849e-14, 3.2320e-14, 5.5656e-14,\n",
       "            9.8204e-14, 9.4699e-14, 4.9106e-14, 4.6414e-14, 7.0185e-14, 8.5199e-14,\n",
       "            6.7964e-14, 8.5458e-14, 1.5406e-13, 4.1048e-14, 4.6724e-14, 5.2307e-14,\n",
       "            5.8629e-14, 9.7984e-14, 1.4424e-13, 8.4517e-14, 7.8545e-14, 1.3276e-13,\n",
       "            6.2967e-14, 8.4062e-14, 5.3955e-14, 6.9507e-14, 1.2745e-13, 5.4570e-14,\n",
       "            8.5919e-14, 4.3251e-14, 4.9307e-14, 1.2104e-13, 8.2913e-14, 5.2329e-14,\n",
       "            2.2836e-14, 8.1670e-14, 9.9551e-14, 7.9407e-14, 4.9716e-14, 7.0676e-14,\n",
       "            4.6623e-14, 1.1158e-13, 2.0621e-14, 7.5236e-14, 9.9109e-14, 1.0288e-13,\n",
       "            4.3723e-14, 5.1261e-14, 5.0991e-14, 6.1490e-14, 3.2198e-14, 2.1964e-14,\n",
       "            4.9171e-14, 2.8815e-14, 4.2986e-14, 7.4792e-14, 6.1033e-14, 6.2058e-14,\n",
       "            6.3018e-14, 3.3264e-14, 3.9658e-14, 2.0050e-14, 4.1606e-14, 3.8382e-14,\n",
       "            3.5563e-14, 1.0366e-13, 8.7036e-14, 5.5249e-14, 5.7499e-14, 6.9132e-14,\n",
       "            2.5800e-14, 6.3196e-14, 1.1802e-13, 3.1861e-14, 5.7876e-14, 7.4243e-14,\n",
       "            6.4650e-14, 1.2926e-13, 7.1385e-14, 6.7849e-14, 1.3597e-13, 5.9318e-14,\n",
       "            3.1859e-14, 4.5463e-14, 4.6606e-14, 4.1384e-14, 5.0774e-14, 1.5921e-13,\n",
       "            6.6072e-14, 9.1303e-14, 1.1348e-13, 5.9491e-14, 2.6208e-14, 7.1400e-14,\n",
       "            6.8978e-14, 1.4609e-13, 1.3668e-13, 6.0787e-14])},\n",
       "   80: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[[ 2.0220e-08,  3.7160e-08,  3.0219e-08],\n",
       "             [ 4.3576e-08,  5.7273e-08,  4.7887e-08],\n",
       "             [-3.3488e-08, -1.9657e-08, -2.8214e-08],\n",
       "             ...,\n",
       "             [-3.4397e-08, -4.1320e-08, -3.8589e-08],\n",
       "             [-4.9629e-08, -5.4451e-08, -5.5952e-08],\n",
       "             [-5.3976e-08, -4.8153e-08, -4.7166e-08]],\n",
       "    \n",
       "            [[ 1.1479e-08, -8.5790e-08, -3.8359e-08],\n",
       "             [-3.1942e-08, -1.4665e-07, -9.7409e-08],\n",
       "             [ 3.5300e-08, -1.0681e-07, -3.8804e-08],\n",
       "             ...,\n",
       "             [-1.3201e-08,  2.3772e-08,  6.2345e-09],\n",
       "             [-1.5838e-09, -3.4659e-08, -1.9572e-08],\n",
       "             [ 1.0314e-07,  6.8862e-08,  8.2405e-08]],\n",
       "    \n",
       "            [[-4.2634e-09,  1.4021e-08,  1.5396e-08],\n",
       "             [-1.1458e-07, -9.6998e-08, -9.1650e-08],\n",
       "             [-1.6136e-07, -1.4292e-07, -1.3607e-07],\n",
       "             ...,\n",
       "             [-9.3369e-08, -1.0083e-07, -1.0248e-07],\n",
       "             [-1.0455e-07, -1.0329e-07, -1.0134e-07],\n",
       "             [-1.4507e-07, -1.4252e-07, -1.4062e-07]],\n",
       "    \n",
       "            ...,\n",
       "    \n",
       "            [[-8.9331e-07, -8.7278e-07, -8.7377e-07],\n",
       "             [-4.4249e-07, -4.1758e-07, -4.0409e-07],\n",
       "             [-1.0847e-06, -1.0381e-06, -1.0302e-06],\n",
       "             ...,\n",
       "             [ 1.1436e-07,  1.1651e-07,  1.1215e-07],\n",
       "             [ 1.7485e-07,  1.9654e-07,  2.0768e-07],\n",
       "             [-1.1152e-06, -1.0992e-06, -1.1052e-06]],\n",
       "    \n",
       "            [[-1.2249e-07, -1.1830e-07, -1.2333e-07],\n",
       "             [-3.9105e-08, -3.1100e-08, -3.7752e-08],\n",
       "             [-3.2298e-08, -1.9715e-08, -2.2663e-08],\n",
       "             ...,\n",
       "             [ 1.2991e-07,  1.3402e-07,  1.3812e-07],\n",
       "             [ 1.0653e-07,  1.1506e-07,  1.1648e-07],\n",
       "             [ 1.4345e-08,  1.5933e-08,  1.5634e-08]],\n",
       "    \n",
       "            [[ 2.8927e-07,  3.6827e-07,  3.1633e-07],\n",
       "             [ 4.8942e-08,  2.0108e-07,  9.7490e-08],\n",
       "             [-1.0500e-07,  5.9469e-08, -5.2395e-08],\n",
       "             ...,\n",
       "             [-3.3325e-07, -3.5884e-07, -3.4450e-07],\n",
       "             [-3.4173e-07, -2.6769e-07, -3.2198e-07],\n",
       "             [-4.1890e-07, -3.9248e-07, -4.0506e-07]]]),\n",
       "    'exp_avg_sq': tensor([[[2.9327e-13, 3.2886e-13, 3.1515e-13],\n",
       "             [5.2259e-14, 6.8296e-14, 5.9879e-14],\n",
       "             [2.4170e-13, 2.9489e-13, 2.7575e-13],\n",
       "             ...,\n",
       "             [8.8983e-14, 9.5159e-14, 9.2193e-14],\n",
       "             [1.2573e-13, 1.1975e-13, 1.2257e-13],\n",
       "             [1.2983e-13, 1.4151e-13, 1.3920e-13]],\n",
       "    \n",
       "            [[1.0418e-13, 9.3141e-14, 9.9599e-14],\n",
       "             [2.4503e-14, 2.0098e-14, 2.2095e-14],\n",
       "             [7.7350e-14, 4.8800e-14, 6.3444e-14],\n",
       "             ...,\n",
       "             [4.4507e-14, 4.5049e-14, 4.5279e-14],\n",
       "             [6.9246e-14, 7.0404e-14, 6.9064e-14],\n",
       "             [5.9965e-14, 5.3304e-14, 5.4782e-14]],\n",
       "    \n",
       "            [[7.4383e-14, 8.0908e-14, 7.9522e-14],\n",
       "             [1.9644e-14, 2.2974e-14, 2.2511e-14],\n",
       "             [1.0580e-13, 1.2162e-13, 1.1996e-13],\n",
       "             ...,\n",
       "             [2.5899e-14, 2.6447e-14, 2.6551e-14],\n",
       "             [3.7292e-14, 3.9524e-14, 3.9078e-14],\n",
       "             [8.4427e-14, 8.9755e-14, 9.1078e-14]],\n",
       "    \n",
       "            ...,\n",
       "    \n",
       "            [[1.0024e-12, 1.0113e-12, 9.9444e-13],\n",
       "             [4.3807e-13, 4.3612e-13, 4.4181e-13],\n",
       "             [2.1985e-12, 2.1371e-12, 2.1414e-12],\n",
       "             ...,\n",
       "             [5.6911e-13, 5.5531e-13, 5.4678e-13],\n",
       "             [8.0643e-13, 7.7194e-13, 7.7823e-13],\n",
       "             [1.7885e-12, 1.7612e-12, 1.7737e-12]],\n",
       "    \n",
       "            [[7.3337e-14, 7.4648e-14, 7.6179e-14],\n",
       "             [1.4222e-14, 1.5877e-14, 1.8045e-14],\n",
       "             [6.1247e-14, 7.3358e-14, 8.0535e-14],\n",
       "             ...,\n",
       "             [9.2720e-14, 9.7076e-14, 9.6558e-14],\n",
       "             [1.3847e-13, 1.4411e-13, 1.4533e-13],\n",
       "             [1.0324e-13, 1.1249e-13, 1.1527e-13]],\n",
       "    \n",
       "            [[4.3347e-13, 4.3896e-13, 4.3141e-13],\n",
       "             [1.0419e-13, 1.0726e-13, 1.0098e-13],\n",
       "             [5.0702e-13, 4.4154e-13, 4.7622e-13],\n",
       "             ...,\n",
       "             [1.8933e-13, 1.8875e-13, 1.9155e-13],\n",
       "             [2.5281e-13, 2.1344e-13, 2.4123e-13],\n",
       "             [4.7077e-13, 4.1624e-13, 4.5605e-13]]])},\n",
       "   81: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 6.0504e-08,  1.1441e-07,  9.8470e-08, -4.7368e-07, -2.3398e-08,\n",
       "            -1.2212e-07,  2.0978e-07, -3.3779e-07, -3.7035e-08, -1.4006e-08,\n",
       "             1.4384e-07, -2.4245e-07,  3.8756e-07,  9.1247e-08, -3.0232e-07,\n",
       "             2.1734e-07, -5.3614e-08,  3.7158e-07,  1.0012e-07,  2.1316e-07,\n",
       "             2.4747e-07, -3.8615e-07, -2.0771e-07,  3.6057e-07,  1.1658e-07,\n",
       "            -2.4539e-07,  3.3010e-07, -4.2255e-07, -1.3987e-07, -5.6972e-08,\n",
       "             1.1048e-07, -1.7287e-07, -2.2177e-07, -1.8487e-08,  7.3902e-08,\n",
       "             2.2037e-07,  2.1808e-07,  3.1206e-08,  2.5810e-08,  3.7565e-08,\n",
       "             7.9536e-07,  2.3493e-08,  2.0735e-07, -1.3530e-07, -4.3965e-08,\n",
       "             4.5422e-07,  3.2708e-07, -9.3576e-08, -2.4940e-07,  2.9330e-07,\n",
       "             1.3474e-07, -3.4623e-07,  3.5582e-08, -9.4650e-07,  1.3094e-07,\n",
       "             3.7589e-08, -7.9484e-08, -3.2930e-07,  6.3792e-07, -7.4817e-08,\n",
       "             3.1937e-07, -1.3168e-07, -3.7315e-07,  1.2381e-07,  5.9688e-08,\n",
       "            -4.2087e-07,  4.3903e-07,  2.1860e-07,  2.0762e-07,  2.3965e-07,\n",
       "             3.7314e-07, -2.4880e-07,  4.9339e-07, -1.6047e-08, -1.7528e-07,\n",
       "            -1.8848e-07, -6.6182e-08,  3.6126e-08,  1.2205e-07, -2.4792e-07,\n",
       "             1.5153e-07,  1.5440e-07,  1.3890e-07, -1.6373e-07,  2.0709e-07,\n",
       "            -1.6869e-07,  4.3269e-07,  2.0554e-07,  7.2475e-08,  4.4486e-07,\n",
       "            -6.5239e-07, -1.7980e-07, -1.4663e-09,  7.6049e-08, -6.8320e-07,\n",
       "             2.0124e-07,  1.8444e-07, -8.9945e-08,  8.3890e-08,  5.4575e-08,\n",
       "            -3.0047e-07,  5.2844e-07,  3.1963e-08,  3.2911e-07, -5.5995e-08,\n",
       "             7.6326e-08, -1.6338e-07, -1.9859e-07, -2.3723e-07, -9.2487e-07,\n",
       "            -3.4970e-08, -1.4689e-07, -8.4224e-08, -7.7597e-07, -2.3890e-07,\n",
       "             4.4646e-07,  1.7225e-07, -1.1768e-08,  6.9204e-08,  1.6135e-07,\n",
       "             3.4607e-07, -4.7766e-07, -9.9006e-08,  7.2899e-08, -4.5203e-07,\n",
       "             9.3910e-09,  4.1281e-08,  8.4301e-07,  1.8038e-07, -2.9751e-07,\n",
       "            -5.9079e-08, -9.4850e-08, -1.4200e-07, -7.1854e-07,  3.7770e-07,\n",
       "            -9.2907e-09, -1.3209e-07, -1.4991e-07,  6.3736e-07, -3.5649e-07,\n",
       "             1.5262e-07,  3.2289e-07,  2.0215e-07,  1.4989e-07,  2.0971e-07,\n",
       "             5.8861e-08, -2.1103e-08, -2.2878e-07,  1.6580e-08, -2.8259e-07,\n",
       "             2.9330e-07, -4.3818e-07, -1.2096e-06, -2.4335e-07,  1.5182e-07,\n",
       "             4.5936e-07, -4.7014e-07,  2.3725e-07, -2.5794e-07,  8.8433e-08,\n",
       "            -2.0452e-07,  6.1188e-08, -2.0562e-07, -2.8604e-07,  2.3869e-07,\n",
       "             1.3151e-07,  1.0330e-07,  2.9831e-07, -3.4348e-08, -4.7978e-07,\n",
       "             1.0030e-07, -9.3313e-08, -3.7932e-07, -2.0247e-07,  8.2880e-08,\n",
       "             1.7243e-07, -4.5502e-07, -2.1003e-07,  1.2285e-08, -2.1310e-08,\n",
       "            -4.1160e-08, -4.6654e-07, -1.9714e-07,  3.7791e-08,  1.9208e-07,\n",
       "             3.3010e-07,  5.2082e-07,  1.0713e-08, -3.7735e-08,  6.2338e-08,\n",
       "            -4.2897e-08,  2.2522e-09,  2.0805e-08,  2.1948e-07, -3.3358e-07,\n",
       "             3.5287e-07, -2.5918e-07, -3.3724e-09, -1.0962e-07,  1.5463e-08,\n",
       "             1.2299e-08,  8.2708e-08,  3.3378e-07,  7.6542e-08,  1.8271e-07,\n",
       "             7.1487e-08,  1.3930e-07, -1.2790e-07,  1.0207e-07,  5.7327e-07,\n",
       "            -1.6928e-07,  3.7688e-08, -1.3046e-07, -2.9743e-07, -4.1218e-07,\n",
       "            -4.8671e-08,  1.3355e-07,  1.0902e-07,  1.2212e-07,  1.6441e-07,\n",
       "             1.5004e-08, -2.7320e-07, -1.1205e-07, -2.1561e-07,  2.3678e-07,\n",
       "            -2.6495e-07,  5.6753e-08,  1.6524e-07,  2.0164e-07,  4.2503e-08,\n",
       "             9.4216e-08,  9.9548e-08,  1.0985e-07, -3.0677e-07, -4.0111e-08,\n",
       "            -6.4208e-08, -3.3540e-08,  1.7286e-07, -6.5972e-08, -6.7628e-07,\n",
       "             9.1129e-08, -2.5672e-07,  6.6287e-08, -9.3113e-08,  3.5410e-07,\n",
       "             2.2614e-08,  1.0961e-07, -4.7684e-07,  5.6678e-07, -1.2890e-08,\n",
       "             1.2458e-07,  3.2286e-07,  2.5645e-07,  7.5126e-07, -2.3391e-08,\n",
       "             6.9595e-08]),\n",
       "    'exp_avg_sq': tensor([3.6180e-13, 8.2437e-14, 1.0785e-13, 1.3714e-13, 1.1620e-13, 4.0726e-14,\n",
       "            1.1061e-13, 1.0494e-13, 2.3478e-13, 4.7598e-14, 2.9196e-13, 2.8627e-13,\n",
       "            3.4645e-13, 5.7132e-14, 9.2398e-14, 2.3586e-13, 1.3136e-14, 5.8980e-13,\n",
       "            1.0314e-13, 7.9482e-14, 1.6063e-13, 1.7253e-13, 1.8428e-13, 1.3525e-13,\n",
       "            3.2269e-13, 1.6520e-13, 1.0876e-13, 1.8003e-13, 1.2173e-13, 2.9999e-14,\n",
       "            5.0132e-14, 7.4310e-14, 2.2674e-13, 5.0623e-13, 6.4238e-14, 2.4400e-14,\n",
       "            1.5521e-13, 2.2153e-13, 1.3307e-13, 6.2326e-14, 2.1423e-13, 1.4865e-13,\n",
       "            9.8348e-14, 2.3993e-13, 8.2513e-14, 3.1037e-13, 3.5576e-13, 4.3744e-14,\n",
       "            3.3441e-13, 2.0891e-13, 2.0936e-13, 3.6523e-13, 8.0029e-13, 2.0777e-13,\n",
       "            7.8369e-14, 1.6436e-13, 4.3215e-13, 2.0177e-13, 5.6798e-13, 3.5613e-14,\n",
       "            1.6909e-13, 3.0051e-14, 2.1686e-13, 1.1748e-13, 6.1924e-14, 2.8954e-13,\n",
       "            2.9863e-13, 1.3959e-13, 4.5954e-13, 1.7721e-13, 2.1643e-13, 4.6844e-14,\n",
       "            3.3074e-13, 2.2033e-13, 1.2108e-13, 1.0558e-13, 1.1655e-13, 2.1459e-13,\n",
       "            2.3943e-13, 1.2929e-13, 2.4104e-13, 3.8784e-14, 2.5370e-13, 7.4461e-14,\n",
       "            2.8445e-13, 2.1798e-14, 2.7982e-13, 5.9338e-14, 2.2931e-13, 2.2579e-13,\n",
       "            1.2023e-13, 1.8985e-13, 7.2599e-14, 6.1372e-14, 2.5591e-13, 7.8659e-14,\n",
       "            1.3510e-13, 9.0959e-14, 6.4746e-14, 2.4323e-14, 3.3860e-13, 4.9957e-13,\n",
       "            5.5743e-13, 1.9510e-13, 3.5661e-14, 4.1777e-14, 2.1092e-13, 9.2634e-13,\n",
       "            8.5106e-14, 6.3524e-13, 1.8229e-13, 9.5003e-14, 1.2862e-13, 3.0890e-13,\n",
       "            1.7946e-13, 4.1262e-13, 1.4766e-13, 8.3568e-14, 2.0410e-13, 8.2856e-14,\n",
       "            1.5668e-13, 2.1679e-13, 2.1812e-13, 3.3275e-14, 1.0324e-13, 3.6299e-13,\n",
       "            9.8546e-14, 1.1708e-12, 3.5290e-13, 8.9755e-14, 1.5355e-13, 1.0598e-13,\n",
       "            3.1981e-13, 1.0250e-13, 6.4944e-14, 8.6586e-14, 6.4532e-14, 2.5974e-14,\n",
       "            5.1728e-13, 2.3230e-13, 4.6888e-13, 8.2683e-14, 1.3429e-13, 2.0241e-13,\n",
       "            3.5298e-13, 3.6540e-13, 2.2927e-13, 4.5549e-13, 5.0374e-14, 7.6739e-14,\n",
       "            2.0727e-13, 9.7399e-14, 2.2559e-13, 2.1782e-13, 1.1548e-13, 5.5632e-13,\n",
       "            3.7057e-13, 1.2719e-13, 3.9653e-14, 9.3168e-14, 2.5316e-13, 6.8005e-13,\n",
       "            1.0054e-13, 8.1398e-14, 8.4963e-14, 2.7175e-13, 6.9713e-14, 1.8381e-13,\n",
       "            3.1978e-13, 6.0152e-13, 1.2994e-13, 1.5726e-13, 1.6943e-13, 8.7858e-14,\n",
       "            2.2534e-13, 1.4460e-14, 2.2156e-13, 1.0513e-13, 1.0035e-13, 5.6600e-14,\n",
       "            4.9107e-13, 9.7270e-14, 1.0095e-13, 1.3234e-13, 2.5996e-13, 2.6601e-13,\n",
       "            4.5253e-13, 3.4119e-14, 1.0652e-13, 2.9482e-14, 2.7448e-14, 3.3170e-14,\n",
       "            1.1034e-13, 7.6126e-14, 1.8056e-13, 4.8977e-14, 7.1359e-14, 1.6156e-13,\n",
       "            1.2718e-13, 2.1165e-13, 1.0476e-13, 5.8388e-14, 8.4327e-14, 7.6234e-14,\n",
       "            1.8731e-13, 3.4643e-13, 1.2034e-13, 8.2580e-14, 7.8986e-14, 1.2850e-12,\n",
       "            1.6795e-13, 1.7414e-13, 4.6699e-13, 3.0208e-13, 2.4466e-13, 1.2035e-13,\n",
       "            1.6010e-13, 7.6288e-14, 2.0817e-13, 3.0871e-13, 1.5847e-14, 3.8404e-14,\n",
       "            5.8059e-14, 2.4323e-13, 1.4064e-13, 2.3821e-13, 1.3166e-13, 2.0845e-13,\n",
       "            4.1551e-13, 9.2114e-14, 1.5057e-13, 1.4973e-13, 2.8755e-13, 1.8643e-13,\n",
       "            9.4432e-14, 5.9406e-14, 1.7543e-13, 6.9678e-14, 1.8924e-13, 3.0777e-13,\n",
       "            4.1524e-13, 4.4197e-13, 1.7633e-13, 9.2944e-14, 1.3934e-13, 5.9135e-14,\n",
       "            9.4780e-14, 4.1085e-13, 1.4491e-13, 1.7955e-13, 2.2319e-13, 1.7791e-13,\n",
       "            4.9462e-13, 1.1399e-12, 9.7485e-14, 5.4161e-13])},\n",
       "   82: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 3.3684e-12,  8.1551e-12,  1.2084e-12,  ...,  6.9758e-12,\n",
       "              1.1902e-11,  2.8344e-13],\n",
       "            [ 6.9090e-12,  5.8063e-12, -3.9661e-11,  ..., -3.3279e-12,\n",
       "              6.6602e-12, -1.1043e-12],\n",
       "            [ 8.0759e-13,  1.0980e-12, -2.7463e-12,  ..., -7.8275e-13,\n",
       "             -1.9623e-12,  7.6721e-13],\n",
       "            ...,\n",
       "            [ 1.2297e-11,  4.6831e-11, -1.7723e-10,  ...,  5.2335e-11,\n",
       "              3.1128e-11,  4.7937e-12],\n",
       "            [-7.0582e-13, -2.6214e-12,  4.3472e-11,  ..., -2.4438e-12,\n",
       "             -2.7591e-12, -1.0349e-12],\n",
       "            [ 2.5968e-12, -4.3063e-11, -7.8998e-10,  ...,  6.4876e-11,\n",
       "              4.3141e-11,  5.7928e-11]]),\n",
       "    'exp_avg_sq': tensor([[1.1761e-22, 4.9957e-22, 3.3695e-22,  ..., 5.1481e-22, 4.5863e-22,\n",
       "             1.9010e-22],\n",
       "            [2.4940e-22, 2.2133e-22, 2.3692e-22,  ..., 2.1866e-22, 2.6981e-22,\n",
       "             1.4328e-22],\n",
       "            [4.8348e-23, 7.7497e-23, 1.7434e-22,  ..., 3.6726e-23, 2.3735e-23,\n",
       "             3.2042e-23],\n",
       "            ...,\n",
       "            [1.0933e-21, 2.1028e-21, 2.5465e-21,  ..., 1.3259e-21, 9.6512e-22,\n",
       "             2.1780e-22],\n",
       "            [1.0464e-21, 1.4478e-21, 2.5098e-21,  ..., 4.9069e-22, 5.5991e-22,\n",
       "             1.7887e-22],\n",
       "            [1.5034e-21, 4.9949e-21, 5.1691e-20,  ..., 3.4141e-20, 1.4165e-20,\n",
       "             5.7553e-21]])},\n",
       "   83: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-2.7517e-13, -2.7517e-13, -2.7517e-13,  ..., -1.7854e-12,\n",
       "             -1.7854e-12, -1.7854e-12],\n",
       "            [-6.2838e-12, -6.2838e-12, -6.2838e-12,  ...,  4.4578e-12,\n",
       "              4.4578e-12,  4.4578e-12],\n",
       "            [ 2.8131e-12,  2.8131e-12,  2.8131e-12,  ..., -9.7086e-13,\n",
       "             -9.7086e-13, -9.7086e-13],\n",
       "            ...,\n",
       "            [ 2.0986e-11,  2.0986e-11,  2.0986e-11,  ...,  1.8141e-11,\n",
       "              1.8141e-11,  1.8141e-11],\n",
       "            [-7.4251e-14, -7.4251e-14, -7.4251e-14,  ...,  1.9178e-12,\n",
       "              1.9178e-12,  1.9178e-12],\n",
       "            [-4.3832e-12, -4.3832e-12, -4.3832e-12,  ...,  2.9468e-12,\n",
       "              2.9468e-12,  2.9468e-12]]),\n",
       "    'exp_avg_sq': tensor([[1.0406e-22, 1.0406e-22, 1.0406e-22,  ..., 1.1327e-22, 1.1327e-22,\n",
       "             1.1327e-22],\n",
       "            [1.7251e-22, 1.7251e-22, 1.7251e-22,  ..., 1.5282e-22, 1.5282e-22,\n",
       "             1.5282e-22],\n",
       "            [3.0133e-22, 3.0133e-22, 3.0133e-22,  ..., 7.1543e-23, 7.1543e-23,\n",
       "             7.1543e-23],\n",
       "            ...,\n",
       "            [1.1539e-21, 1.1539e-21, 1.1539e-21,  ..., 7.0204e-22, 7.0204e-22,\n",
       "             7.0204e-22],\n",
       "            [3.4646e-21, 3.4646e-21, 3.4646e-21,  ..., 7.5250e-22, 7.5250e-22,\n",
       "             7.5250e-22],\n",
       "            [3.5708e-22, 3.5708e-22, 3.5708e-22,  ..., 6.8368e-22, 6.8368e-22,\n",
       "             6.8368e-22]])},\n",
       "   84: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([-3.6136e-12, -2.3327e-12, -6.5827e-12,  3.7453e-12, -1.8081e-12,\n",
       "             2.0885e-13, -2.7496e-12,  4.3407e-12,  5.1066e-12, -7.2057e-12,\n",
       "             1.2622e-12,  2.3212e-12, -7.6052e-12, -4.9021e-12, -5.1382e-12,\n",
       "            -3.3817e-12,  6.5359e-12,  3.1895e-12,  2.5509e-12,  2.6893e-12,\n",
       "            -1.6628e-12, -8.4266e-12,  8.9532e-12,  2.5890e-12, -1.9689e-12,\n",
       "            -1.7080e-12, -1.0809e-11, -7.3273e-12,  4.8646e-12, -7.5450e-12,\n",
       "            -2.9995e-12,  3.5132e-12,  8.0845e-12, -2.4307e-12,  5.0201e-13,\n",
       "             9.4328e-13,  5.3160e-13,  3.4269e-12,  6.2351e-13, -1.3076e-12,\n",
       "            -5.0407e-12,  5.0860e-13, -2.3824e-12,  2.8818e-12,  4.8209e-12,\n",
       "            -7.8465e-12,  1.3232e-11, -6.3759e-12, -3.4223e-12,  9.1488e-13,\n",
       "            -7.6510e-12, -6.2557e-12,  2.1443e-12, -2.7188e-12, -5.6826e-12,\n",
       "            -5.9231e-12,  6.1606e-12,  9.8988e-12,  8.1842e-12, -5.5177e-12,\n",
       "             9.7519e-13, -8.7892e-12,  5.3453e-12,  5.5180e-14, -2.1328e-12,\n",
       "            -1.3373e-12,  3.9001e-12,  2.4249e-11, -6.2469e-13,  1.5789e-12,\n",
       "            -7.4706e-12, -6.6053e-12,  1.0083e-12, -2.1853e-12,  2.3036e-12,\n",
       "             1.3566e-12, -2.5860e-12, -6.7952e-14,  1.0141e-12, -5.4835e-13,\n",
       "             3.6208e-12,  1.7224e-12,  4.3085e-13,  7.5818e-12, -8.1645e-12,\n",
       "             7.2177e-12,  2.8685e-13, -1.8671e-12,  3.8467e-12,  3.5739e-12,\n",
       "            -1.4900e-11, -6.0631e-12,  7.2047e-12, -6.3421e-12,  5.6949e-14,\n",
       "             2.3881e-12,  1.1385e-11,  1.3076e-12, -7.6253e-12, -1.2985e-11,\n",
       "             4.2772e-12,  4.7942e-12,  1.9217e-11, -1.7708e-12, -1.1082e-11,\n",
       "            -3.2740e-12, -2.4622e-12,  6.1355e-13,  3.7138e-12,  2.7384e-12,\n",
       "             1.0403e-11, -1.0989e-12,  7.0291e-13,  2.0280e-12,  1.3967e-11,\n",
       "             5.8522e-12, -7.7689e-12, -6.1230e-12,  7.7521e-12,  5.5567e-12,\n",
       "            -4.0283e-13, -6.6681e-12,  2.1015e-12,  3.6686e-12,  5.2985e-12,\n",
       "            -1.3328e-11, -1.3169e-11, -4.0367e-12, -1.1031e-11, -1.2647e-11,\n",
       "             5.5688e-12,  5.9081e-12,  1.9442e-12, -1.3318e-14,  1.4954e-12,\n",
       "            -2.0980e-12,  5.5155e-14, -1.3864e-12,  1.2507e-11, -5.3102e-12,\n",
       "            -1.7373e-12, -1.9031e-12, -4.8742e-12,  1.9432e-12, -3.3912e-12,\n",
       "             4.9730e-13, -5.8260e-13,  1.0656e-11, -4.4491e-12,  6.8251e-12,\n",
       "             1.9055e-12,  7.9771e-12, -2.3322e-12,  1.3860e-12, -4.1449e-12,\n",
       "            -6.1835e-12,  2.2634e-12, -4.8534e-12,  6.3705e-13, -3.4664e-12,\n",
       "             4.5619e-12, -7.0173e-12,  1.3747e-11, -8.6348e-12,  4.7248e-12,\n",
       "            -8.5287e-12,  4.2819e-12, -8.9035e-12,  1.3143e-12,  7.2281e-12,\n",
       "             7.9277e-12, -3.8251e-12,  2.5713e-12, -1.1236e-11,  5.7247e-13,\n",
       "            -2.3462e-12,  2.3564e-12, -5.2445e-12,  1.8596e-12,  1.2809e-12,\n",
       "             4.6711e-12, -7.1406e-12, -8.2859e-12,  1.1702e-11, -2.0186e-13,\n",
       "             2.0978e-12, -9.5528e-12, -2.6925e-12, -5.2876e-12, -4.4567e-12,\n",
       "             5.0933e-13,  3.9484e-12, -1.0947e-11, -2.9234e-12, -6.3805e-13,\n",
       "            -2.6146e-13,  6.6765e-13,  4.0709e-12,  1.9777e-12, -6.5604e-13,\n",
       "            -1.4169e-11,  1.1809e-11,  3.4616e-12, -7.1214e-12,  5.2850e-12,\n",
       "             1.0289e-11,  8.4869e-12,  2.0587e-12,  3.9481e-12, -1.1821e-11,\n",
       "             1.5266e-11,  1.1617e-12, -1.0476e-11,  5.8548e-13, -6.7856e-12,\n",
       "             9.7320e-12, -2.5434e-12,  3.0172e-13,  3.5325e-12,  3.1258e-12,\n",
       "             6.4229e-12,  2.0066e-12,  1.6695e-13, -4.9827e-12,  4.5516e-12,\n",
       "            -7.0773e-12, -7.6708e-12, -4.8913e-12, -8.7661e-12,  4.2938e-12,\n",
       "             6.9475e-12,  1.3397e-11,  8.8959e-13,  2.7676e-12, -1.8767e-12,\n",
       "            -2.5646e-12,  1.1281e-11, -1.5111e-12, -2.2147e-12,  6.9259e-12,\n",
       "            -8.3101e-12, -7.1147e-12, -1.4000e-12, -2.2100e-12, -5.9474e-12,\n",
       "             4.2943e-12,  4.3426e-12,  6.8665e-13, -7.9021e-12, -8.6272e-14,\n",
       "            -2.9967e-12, -4.4553e-12, -1.4472e-12,  2.8038e-12, -5.0193e-12,\n",
       "            -1.2458e-12,  6.5209e-12,  4.0959e-12, -3.5455e-12, -4.2045e-12,\n",
       "             6.7391e-13,  6.6250e-12, -9.7605e-12, -1.0827e-11,  2.6950e-12,\n",
       "            -8.2190e-12,  9.2478e-12,  3.7090e-12,  5.8942e-13,  8.8401e-12,\n",
       "             2.7568e-12,  8.3402e-12, -4.6649e-13,  2.6277e-12,  3.5502e-12,\n",
       "             4.0539e-12, -2.2280e-13, -4.9544e-12,  5.0622e-12, -1.9011e-12,\n",
       "            -1.3272e-12, -1.3452e-11,  5.5243e-12, -9.1256e-12, -1.4747e-12,\n",
       "             7.5273e-12, -7.4156e-12,  3.9460e-12, -1.4605e-12,  3.0372e-12,\n",
       "            -1.6099e-12, -1.6039e-13,  9.2111e-12, -2.5311e-13,  7.8643e-12,\n",
       "             6.3482e-12, -8.4162e-12,  3.9712e-12,  1.1900e-12, -4.5847e-12,\n",
       "            -4.2232e-13,  4.7141e-12, -4.4374e-12,  2.6347e-12, -9.0650e-13,\n",
       "            -1.9080e-11,  5.5973e-12, -1.3327e-12, -1.0556e-11, -5.0508e-12,\n",
       "             1.4770e-11,  7.3292e-12, -7.7366e-12,  5.9439e-12,  8.0210e-12,\n",
       "            -1.7923e-12, -8.4963e-12, -6.2831e-12, -3.4073e-12,  5.0115e-12,\n",
       "            -8.3414e-13,  3.7165e-12, -6.0988e-12, -3.0194e-12,  1.0579e-11,\n",
       "             5.2581e-12, -2.8924e-13, -3.6741e-12, -1.3747e-13, -6.7188e-12,\n",
       "            -7.2034e-12,  2.3711e-12,  2.7973e-12, -8.2762e-12, -5.8563e-12,\n",
       "             7.2284e-12, -5.4194e-12, -5.4393e-12, -2.5972e-12,  8.4473e-13,\n",
       "             2.5557e-12,  4.3636e-12,  6.1340e-12,  2.4947e-12,  5.3109e-13,\n",
       "             7.4461e-12, -7.3458e-12, -6.7054e-13, -1.5280e-12, -1.3689e-12,\n",
       "             5.7516e-12,  8.2451e-12, -6.0211e-13,  8.6471e-12, -4.8228e-12,\n",
       "             2.6504e-15, -7.3669e-13,  5.5841e-12, -8.9061e-12, -1.0840e-12,\n",
       "             8.3129e-13,  1.8221e-13, -3.0022e-12,  1.4566e-12,  9.2586e-12,\n",
       "            -5.9941e-13,  3.3533e-12, -2.3350e-12, -3.1295e-12,  9.3755e-12,\n",
       "             1.9150e-11, -5.0981e-12, -4.1465e-12, -2.1483e-12,  4.5003e-12,\n",
       "             1.0002e-11, -4.1460e-12, -7.9255e-12, -1.2096e-11,  1.8059e-12,\n",
       "            -6.5772e-13, -8.5466e-13,  7.0805e-12, -7.4253e-12, -5.6753e-12,\n",
       "            -1.4558e-13, -5.0248e-13,  7.9598e-13, -3.7138e-12, -8.0958e-12,\n",
       "            -3.6789e-13,  1.1431e-11,  3.0563e-12,  6.6909e-12,  8.8702e-13,\n",
       "            -3.1380e-12,  4.5559e-12, -7.0773e-13,  3.7778e-12,  2.8805e-12,\n",
       "             3.9466e-12, -2.9131e-12, -1.0085e-11, -5.2307e-12, -9.7243e-12,\n",
       "             5.4248e-12, -2.6572e-12,  2.4342e-12,  2.4434e-12, -7.6262e-12,\n",
       "             6.6877e-12, -7.6178e-12,  3.6023e-12, -7.2498e-12,  1.3765e-12,\n",
       "             2.7753e-12, -6.4932e-12, -2.5257e-12,  1.0576e-11,  1.9798e-12,\n",
       "             3.4221e-12, -5.1112e-12, -9.5889e-13, -6.3088e-13, -7.3500e-12,\n",
       "             2.5608e-12,  3.1613e-12, -6.8822e-12, -8.8718e-12,  1.8714e-12,\n",
       "             8.7192e-12,  1.0763e-12, -5.7803e-12,  8.5189e-13,  4.4904e-12,\n",
       "            -8.1792e-12,  7.2943e-12,  3.9051e-12,  3.3447e-13, -1.2749e-12,\n",
       "            -9.3558e-12,  1.1750e-12, -4.3553e-12, -1.1348e-11,  6.4513e-13,\n",
       "            -4.1551e-12,  6.6621e-12,  5.0403e-12,  1.0612e-11, -4.3141e-12,\n",
       "             8.3092e-12,  7.8635e-13, -2.1011e-12,  9.0038e-12,  1.1888e-12,\n",
       "            -3.2019e-12,  3.7439e-12,  2.3792e-12, -2.1577e-12, -5.6231e-12,\n",
       "             4.8305e-12,  2.8104e-12, -7.3527e-12, -1.0068e-12,  6.1686e-12,\n",
       "             5.7093e-12,  2.0415e-12, -5.0169e-12, -5.6737e-12, -1.7416e-13,\n",
       "             2.1819e-12, -6.1901e-12,  1.4619e-12,  5.8430e-12,  8.8264e-13,\n",
       "            -6.9459e-13,  7.2418e-12, -1.2824e-11, -1.4088e-12,  3.5287e-12,\n",
       "             7.1186e-13,  5.3919e-12,  4.4758e-12,  4.7419e-12,  5.1769e-12,\n",
       "             3.4347e-12,  6.2045e-12, -1.1491e-12, -8.7802e-12, -3.9356e-12,\n",
       "            -1.0339e-11, -4.2315e-12, -2.5373e-12,  5.7957e-12,  9.7113e-12,\n",
       "            -5.6527e-13, -7.2322e-12, -5.2945e-12,  8.7902e-12, -5.7913e-12,\n",
       "            -2.3488e-12, -2.4835e-12,  1.5059e-12, -4.7368e-12, -5.1950e-12,\n",
       "             8.7908e-12, -7.9076e-13, -2.5780e-12,  1.6899e-12,  1.6677e-12,\n",
       "            -3.0210e-12,  1.3325e-12]),\n",
       "    'exp_avg_sq': tensor([2.2135e-22, 1.4135e-22, 1.4505e-22, 2.1507e-22, 1.4145e-22, 1.5206e-22,\n",
       "            1.7805e-22, 1.4910e-22, 1.6368e-22, 1.4486e-22, 2.1783e-22, 2.4932e-22,\n",
       "            1.3175e-22, 1.3520e-22, 1.3754e-22, 1.1223e-22, 1.4771e-22, 2.0167e-22,\n",
       "            3.7297e-22, 1.4003e-22, 1.4543e-22, 1.4735e-22, 1.7629e-22, 1.9770e-22,\n",
       "            1.3815e-22, 3.1701e-22, 1.7738e-22, 1.8807e-22, 1.4145e-22, 2.2321e-22,\n",
       "            1.3866e-22, 8.8528e-23, 1.7539e-22, 3.8802e-22, 1.7201e-22, 9.9879e-23,\n",
       "            1.5839e-22, 2.2626e-22, 2.1658e-22, 1.1794e-22, 2.2796e-22, 1.0746e-22,\n",
       "            3.2583e-22, 2.8893e-22, 1.1401e-22, 1.3930e-22, 2.4027e-22, 1.7324e-22,\n",
       "            8.9467e-23, 1.5838e-22, 2.0481e-22, 1.6322e-22, 2.3990e-22, 1.7347e-22,\n",
       "            1.4219e-22, 1.4403e-22, 1.4575e-22, 1.4691e-22, 1.8265e-22, 1.7608e-22,\n",
       "            1.6097e-22, 2.5194e-22, 1.3731e-22, 1.6194e-22, 1.7645e-22, 1.4088e-22,\n",
       "            1.8848e-22, 2.2467e-22, 1.7182e-22, 2.1397e-22, 2.8561e-22, 4.3748e-22,\n",
       "            1.5900e-22, 2.2721e-22, 2.0935e-22, 1.3617e-22, 1.2171e-22, 1.5078e-22,\n",
       "            1.0990e-22, 1.7201e-22, 1.8150e-22, 1.7781e-22, 1.6341e-22, 2.3606e-22,\n",
       "            1.2085e-22, 1.6693e-22, 2.7128e-22, 1.5903e-22, 1.9571e-22, 1.7600e-22,\n",
       "            3.4646e-22, 1.8576e-22, 1.2137e-22, 1.1059e-22, 1.0407e-22, 2.6195e-22,\n",
       "            1.3559e-22, 1.7583e-22, 1.8727e-22, 1.6613e-22, 5.4847e-22, 1.2795e-22,\n",
       "            2.6136e-22, 1.4772e-22, 1.4613e-22, 1.4135e-22, 8.8076e-23, 1.3932e-22,\n",
       "            1.0919e-22, 1.1035e-22, 1.7422e-22, 1.9332e-22, 9.1452e-23, 1.0037e-22,\n",
       "            4.1332e-22, 3.2724e-22, 3.2292e-22, 1.6178e-22, 1.4081e-22, 1.1575e-22,\n",
       "            1.3246e-22, 1.4790e-22, 1.7485e-22, 1.2687e-22, 1.4703e-22, 2.0131e-22,\n",
       "            1.8030e-22, 3.2292e-22, 1.5148e-22, 2.1082e-22, 1.7414e-22, 1.2676e-22,\n",
       "            1.4942e-22, 1.2637e-22, 1.9414e-22, 1.7263e-22, 1.4038e-22, 1.1355e-22,\n",
       "            1.1878e-22, 1.8163e-22, 2.9309e-22, 1.3101e-22, 3.0980e-22, 1.2568e-22,\n",
       "            1.1654e-22, 1.6014e-22, 1.3121e-22, 2.3640e-22, 1.6936e-22, 1.3190e-22,\n",
       "            1.1224e-22, 3.0361e-22, 2.0326e-22, 1.2901e-22, 3.5675e-22, 1.8012e-22,\n",
       "            2.2239e-22, 1.6826e-22, 1.2849e-22, 2.7848e-22, 1.9788e-22, 1.4615e-22,\n",
       "            1.6208e-22, 1.2896e-22, 1.6519e-22, 1.5478e-22, 2.0513e-22, 2.5287e-22,\n",
       "            2.1073e-22, 2.2051e-22, 1.3994e-22, 1.9759e-22, 1.2429e-22, 1.5976e-22,\n",
       "            1.5417e-22, 1.8360e-22, 1.3797e-22, 2.1657e-22, 6.4784e-22, 1.2436e-22,\n",
       "            1.3245e-22, 1.0265e-22, 2.2901e-22, 1.3650e-22, 5.9079e-22, 2.7141e-22,\n",
       "            1.8642e-22, 1.4292e-22, 1.5837e-22, 1.6632e-22, 5.0398e-22, 1.7273e-22,\n",
       "            3.0634e-22, 1.5649e-22, 2.3513e-22, 1.5782e-22, 1.2631e-22, 2.4835e-22,\n",
       "            1.8842e-22, 1.5721e-22, 1.9222e-22, 2.4015e-22, 1.9331e-22, 2.2605e-22,\n",
       "            1.9348e-22, 2.9813e-22, 2.5454e-22, 1.7060e-22, 3.1541e-22, 2.2447e-22,\n",
       "            2.1951e-22, 4.0344e-22, 1.7982e-22, 2.0168e-22, 9.0446e-23, 1.9024e-22,\n",
       "            1.0952e-22, 2.6502e-22, 2.7754e-22, 1.6553e-22, 1.2750e-22, 1.0281e-22,\n",
       "            1.6227e-22, 1.8356e-22, 2.5259e-22, 1.7090e-22, 1.2935e-22, 1.4197e-22,\n",
       "            2.4545e-22, 1.6614e-22, 2.4123e-22, 2.4496e-22, 1.7145e-22, 1.6534e-22,\n",
       "            1.5401e-22, 1.2289e-22, 2.3282e-22, 1.9841e-22, 1.8086e-22, 1.9734e-22,\n",
       "            1.7595e-22, 1.7387e-22, 3.0269e-22, 1.7669e-22, 1.8107e-22, 4.6449e-22,\n",
       "            2.0387e-22, 2.2573e-22, 1.4494e-22, 1.2120e-22, 1.0118e-22, 3.3237e-22,\n",
       "            1.3212e-22, 1.8630e-22, 1.7611e-22, 1.4913e-22, 2.0239e-22, 1.4752e-22,\n",
       "            2.0798e-22, 1.5435e-22, 2.1067e-22, 1.2439e-22, 1.6330e-22, 1.4265e-22,\n",
       "            1.5088e-22, 1.8951e-22, 1.3943e-22, 2.6460e-22, 1.7188e-22, 2.2016e-22,\n",
       "            3.7309e-22, 2.7234e-22, 2.0639e-22, 1.9609e-22, 1.4002e-22, 1.2137e-22,\n",
       "            2.0954e-22, 5.7963e-22, 1.3099e-22, 1.4419e-22, 1.6273e-22, 1.3120e-22,\n",
       "            2.0804e-22, 1.8857e-22, 1.3025e-22, 1.4474e-22, 3.0717e-22, 1.8643e-22,\n",
       "            1.0982e-22, 1.7066e-22, 1.4270e-22, 2.2284e-22, 1.9062e-22, 1.6667e-22,\n",
       "            2.2028e-22, 1.5893e-22, 1.3427e-22, 1.3954e-22, 1.3661e-22, 1.7448e-22,\n",
       "            3.0225e-22, 9.4316e-23, 2.1376e-22, 1.2672e-22, 2.0763e-22, 1.6742e-22,\n",
       "            1.4205e-22, 2.0539e-22, 2.0646e-22, 2.7142e-22, 1.4894e-22, 1.4890e-22,\n",
       "            1.8485e-22, 2.3630e-22, 1.4668e-22, 1.3937e-22, 1.3597e-22, 1.5611e-22,\n",
       "            1.4399e-22, 2.5075e-22, 1.8181e-22, 1.7628e-22, 1.7091e-22, 1.8815e-22,\n",
       "            1.6856e-22, 2.0093e-22, 1.7019e-22, 2.0512e-22, 1.0172e-22, 1.6052e-22,\n",
       "            1.4454e-22, 1.2815e-22, 2.6466e-22, 1.3423e-22, 2.3921e-22, 1.3138e-22,\n",
       "            1.5385e-22, 1.6100e-22, 2.0066e-22, 1.1950e-22, 1.5429e-22, 1.4676e-22,\n",
       "            2.2066e-22, 1.8115e-22, 1.4365e-22, 1.3474e-22, 1.1418e-22, 1.4495e-22,\n",
       "            2.0459e-22, 1.9067e-22, 2.2392e-22, 1.6554e-22, 1.6227e-22, 2.2485e-22,\n",
       "            1.3344e-22, 1.3598e-22, 1.4027e-22, 1.0456e-22, 1.2952e-22, 1.1611e-22,\n",
       "            2.0887e-22, 2.5863e-22, 1.7542e-22, 2.1639e-22, 1.5040e-22, 2.1478e-22,\n",
       "            1.2088e-22, 1.5779e-22, 2.3688e-22, 4.1263e-22, 4.4341e-22, 3.9487e-22,\n",
       "            1.7873e-22, 2.2724e-22, 1.1960e-22, 3.6178e-22, 1.2601e-22, 1.5327e-22,\n",
       "            1.7981e-22, 1.6216e-22, 1.4611e-22, 1.8395e-22, 2.9954e-22, 1.5595e-22,\n",
       "            1.9238e-22, 3.1230e-22, 1.9009e-22, 1.6268e-22, 1.6972e-22, 1.3650e-22,\n",
       "            2.1763e-22, 2.3087e-22, 1.7195e-22, 1.3501e-22, 1.4075e-22, 2.1224e-22,\n",
       "            1.3931e-22, 1.7663e-22, 2.1086e-22, 2.1193e-22, 1.6068e-22, 1.5895e-22,\n",
       "            2.2656e-22, 1.0184e-22, 1.7972e-22, 1.9960e-22, 1.7023e-22, 1.7215e-22,\n",
       "            2.4222e-22, 2.1131e-22, 1.8932e-22, 1.5905e-22, 2.5932e-22, 1.9242e-22,\n",
       "            9.4810e-23, 1.8039e-22, 1.3225e-22, 1.4642e-22, 1.7426e-22, 1.6309e-22,\n",
       "            1.6102e-22, 1.6824e-22, 1.1699e-22, 9.3131e-23, 1.3793e-22, 1.2111e-22,\n",
       "            1.4458e-22, 1.6588e-22, 1.2552e-22, 6.9444e-22, 1.9463e-22, 9.5382e-23,\n",
       "            2.1151e-22, 1.2844e-22, 1.0030e-22, 1.6629e-22, 1.7935e-22, 1.7761e-22,\n",
       "            2.0692e-22, 1.6667e-22, 1.7512e-22, 1.6929e-22, 1.7464e-22, 1.5842e-22,\n",
       "            1.1397e-22, 1.0287e-22, 9.7065e-23, 1.7874e-22, 2.4039e-22, 1.2261e-22,\n",
       "            1.5107e-22, 1.7217e-22, 3.4520e-22, 1.4047e-22, 1.8773e-22, 1.6078e-22,\n",
       "            2.4737e-22, 1.8817e-22, 1.5726e-22, 2.0183e-22, 1.6940e-22, 1.2074e-22,\n",
       "            2.5303e-22, 1.2882e-22, 2.1265e-22, 1.3821e-22, 3.6823e-22, 1.1056e-22,\n",
       "            3.1380e-22, 1.8544e-22, 1.5457e-22, 2.2369e-22, 1.3222e-22, 1.5124e-22,\n",
       "            1.7578e-22, 2.1433e-22, 2.3012e-22, 1.8854e-22, 1.3272e-22, 1.5505e-22,\n",
       "            1.7791e-22, 1.5155e-22, 1.2051e-22, 1.5238e-22, 3.0120e-22, 1.3822e-22,\n",
       "            2.8229e-22, 1.9917e-22, 1.0219e-22, 1.4809e-22, 2.0277e-22, 1.3082e-22,\n",
       "            1.8153e-22, 1.1951e-22, 1.3429e-22, 1.1906e-22, 1.2451e-22, 2.1551e-22,\n",
       "            1.5256e-22, 8.7752e-23, 1.2892e-22, 1.7345e-22, 1.8402e-22, 1.6812e-22,\n",
       "            1.3061e-22, 1.5933e-22, 1.8183e-22, 1.2091e-22, 1.8870e-22, 1.2821e-22,\n",
       "            1.4387e-22, 2.0734e-22])},\n",
       "   85: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-1.6304e-08,  2.4242e-09, -4.3724e-09,  ..., -3.4849e-09,\n",
       "             -1.3350e-08,  5.7304e-09],\n",
       "            [-7.9326e-07, -6.3598e-08, -1.2911e-07,  ...,  2.1041e-07,\n",
       "             -9.8629e-08,  2.8058e-07],\n",
       "            [ 1.7927e-07,  6.0845e-07,  3.2274e-07,  ..., -1.2535e-07,\n",
       "              4.8244e-07, -1.8554e-06],\n",
       "            ...,\n",
       "            [ 1.1410e-10, -5.9312e-11, -3.5650e-11,  ...,  3.9123e-11,\n",
       "             -2.2835e-11,  2.1932e-10],\n",
       "            [ 4.8658e-07, -9.7976e-08,  1.3007e-07,  ...,  1.4116e-07,\n",
       "             -1.8075e-08,  4.4311e-07],\n",
       "            [-6.6004e-07,  1.0182e-07, -6.5558e-08,  ...,  1.0626e-07,\n",
       "             -1.2699e-08, -2.7555e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.3912e-14, 8.4656e-16, 1.9841e-15,  ..., 1.0468e-15, 1.0921e-14,\n",
       "             2.4576e-15],\n",
       "            [7.3602e-13, 1.7831e-13, 9.2437e-14,  ..., 1.2884e-13, 1.5422e-13,\n",
       "             1.6693e-12],\n",
       "            [1.3143e-12, 2.3303e-13, 9.0067e-14,  ..., 6.3434e-13, 1.5341e-13,\n",
       "             3.1999e-12],\n",
       "            ...,\n",
       "            [1.4624e-17, 3.8887e-18, 1.4068e-18,  ..., 1.6644e-18, 5.8153e-19,\n",
       "             5.2916e-17],\n",
       "            [5.8002e-13, 1.1908e-13, 4.3825e-14,  ..., 8.7312e-14, 9.7634e-14,\n",
       "             1.3337e-12],\n",
       "            [2.2197e-13, 1.0999e-13, 3.3870e-14,  ..., 5.7491e-14, 8.0434e-14,\n",
       "             1.2173e-12]])},\n",
       "   86: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 1.6081e-08,  2.7960e-08, -7.6202e-07,  3.9606e-08, -2.4408e-07,\n",
       "            -3.5818e-07,  7.7978e-10, -4.5334e-07, -2.3720e-07, -3.5519e-09,\n",
       "             1.6735e-07,  5.3075e-07, -4.0659e-07,  6.4202e-09,  0.0000e+00,\n",
       "            -3.4940e-07,  2.3172e-08, -1.7614e-07,  9.1987e-10,  6.8093e-10,\n",
       "             6.6637e-08,  1.0616e-07,  9.2894e-08,  4.3951e-07, -2.0772e-08,\n",
       "             3.8776e-08, -1.4450e-07, -4.1905e-08,  1.0484e-08,  0.0000e+00,\n",
       "             6.3308e-08,  2.6600e-07,  9.0732e-08,  1.1764e-08, -1.4661e-07,\n",
       "            -1.1749e-07,  0.0000e+00, -5.2765e-07,  8.2973e-08, -7.4828e-09,\n",
       "             8.6219e-08,  7.7612e-08,  3.5136e-07,  3.1844e-08, -4.5052e-08,\n",
       "            -3.7627e-07, -4.7843e-08,  3.0393e-07,  1.1098e-07,  3.2403e-07,\n",
       "             6.9189e-08,  3.4667e-07, -4.5945e-07, -7.4449e-07, -1.2038e-07,\n",
       "             1.9731e-08, -1.6844e-07,  1.2958e-08,  0.0000e+00,  6.1600e-08,\n",
       "            -1.2562e-07,  6.2099e-11,  2.7691e-08, -4.9601e-08]),\n",
       "    'exp_avg_sq': tensor([1.5315e-14, 3.2386e-13, 2.1081e-13, 1.0983e-13, 6.4805e-14, 6.7428e-14,\n",
       "            5.5780e-15, 2.6155e-13, 1.1653e-13, 8.7781e-16, 4.7018e-14, 9.5428e-14,\n",
       "            2.6731e-13, 1.5266e-14, 0.0000e+00, 1.7478e-13, 6.5219e-14, 1.6015e-13,\n",
       "            5.2412e-15, 1.9167e-16, 4.2220e-14, 2.4531e-13, 3.9249e-13, 5.2204e-13,\n",
       "            5.9934e-13, 1.6114e-13, 1.3574e-13, 3.7545e-14, 4.8217e-14, 0.0000e+00,\n",
       "            1.5986e-13, 5.3833e-14, 1.8075e-13, 2.3917e-13, 1.5727e-13, 9.9017e-14,\n",
       "            0.0000e+00, 9.1844e-14, 2.4957e-13, 2.7768e-13, 6.9831e-14, 4.5783e-14,\n",
       "            2.3074e-13, 4.9346e-14, 9.3560e-15, 1.0888e-13, 2.8201e-13, 6.1523e-13,\n",
       "            5.0694e-13, 2.8874e-13, 2.9243e-13, 2.7857e-13, 1.7229e-13, 3.8812e-13,\n",
       "            3.6192e-13, 2.0470e-13, 1.0452e-13, 3.0350e-15, 0.0000e+00, 1.5340e-13,\n",
       "            2.0025e-13, 4.2648e-18, 2.1271e-13, 1.8419e-13])},\n",
       "   87: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-1.0123e-09,  1.8500e-07,  1.2421e-07,  ..., -6.8761e-13,\n",
       "              1.2070e-07,  4.5237e-08],\n",
       "            [ 2.9977e-10, -3.1041e-09, -6.5927e-08,  ...,  1.1092e-13,\n",
       "             -5.7686e-08,  9.8254e-08],\n",
       "            [-1.3233e-10,  8.4786e-08,  6.5747e-08,  ...,  1.4811e-13,\n",
       "              6.9133e-08,  3.0144e-09],\n",
       "            ...,\n",
       "            [-1.8467e-10,  2.3565e-07,  2.5666e-07,  ..., -3.6965e-13,\n",
       "              1.6504e-07,  1.2998e-07],\n",
       "            [-5.1079e-10,  4.5873e-08, -1.1294e-08,  ..., -1.0962e-13,\n",
       "              3.2110e-08,  3.9812e-08],\n",
       "            [-3.1093e-10,  1.2172e-07,  2.3739e-07,  ...,  1.4589e-12,\n",
       "             -7.5213e-09,  3.1878e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.9913e-16, 3.5289e-13, 1.5914e-12,  ..., 5.0021e-22, 4.4829e-13,\n",
       "             8.4088e-14],\n",
       "            [1.4337e-17, 1.1983e-14, 2.7595e-14,  ..., 1.3166e-23, 6.3157e-15,\n",
       "             1.1210e-14],\n",
       "            [1.1157e-17, 1.1321e-14, 9.2462e-15,  ..., 2.7707e-23, 6.6716e-15,\n",
       "             2.0563e-15],\n",
       "            ...,\n",
       "            [2.3794e-17, 9.9968e-14, 2.4083e-13,  ..., 1.1967e-22, 6.3852e-14,\n",
       "             3.2587e-14],\n",
       "            [1.8077e-16, 5.8094e-14, 5.9666e-14,  ..., 8.9751e-24, 2.5390e-14,\n",
       "             3.4124e-14],\n",
       "            [4.6523e-18, 1.4103e-13, 2.9408e-13,  ..., 1.7609e-21, 5.1111e-14,\n",
       "             6.5769e-14]])},\n",
       "   88: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 1.4098e-07, -9.3068e-08,  5.3426e-08,  2.4842e-07,  1.7684e-08,\n",
       "            -4.3864e-08,  1.0672e-07, -1.4378e-07, -5.4573e-08,  7.8536e-08,\n",
       "            -1.2175e-07,  4.9225e-07, -2.7941e-07,  3.0115e-08,  1.3871e-07,\n",
       "            -1.4269e-07, -1.8595e-09,  3.7072e-07,  1.0771e-07, -7.2949e-08,\n",
       "             5.8355e-09, -6.4582e-08, -8.0003e-08, -2.2998e-08,  2.1193e-07,\n",
       "            -3.0371e-07,  4.3753e-08,  7.1337e-07, -1.2776e-07, -2.0536e-07,\n",
       "            -7.6544e-08, -1.6468e-07, -4.0238e-07, -1.1324e-07, -1.0135e-07,\n",
       "            -1.8114e-08,  1.1354e-07,  3.5008e-07, -1.4827e-07,  8.5319e-08,\n",
       "            -2.7383e-09, -1.2914e-07, -8.8617e-08,  2.9886e-07,  1.9674e-08,\n",
       "            -1.4686e-07, -1.7680e-07,  1.2682e-07, -5.9116e-07,  9.6586e-08,\n",
       "            -1.7030e-07,  1.3506e-07,  1.0642e-07,  9.6783e-07, -4.0076e-08,\n",
       "            -1.1776e-07, -4.6732e-08, -1.1279e-07, -1.6405e-07,  4.0169e-08,\n",
       "            -6.0399e-08,  1.7255e-07, -2.9645e-08, -4.6386e-08, -3.8124e-08,\n",
       "            -5.1537e-07,  6.4772e-07,  6.9354e-07,  4.6843e-08,  3.3857e-07,\n",
       "            -9.5488e-09, -2.1343e-07,  5.1060e-08,  2.3211e-08,  9.6240e-08,\n",
       "             7.4315e-08, -1.7868e-08,  4.6622e-08,  2.8805e-08, -6.8570e-08,\n",
       "            -2.4455e-07, -2.7810e-09,  3.9527e-07,  1.0653e-07, -3.4947e-08,\n",
       "            -5.9625e-08, -2.3746e-07,  3.1985e-08, -1.8570e-08,  2.1623e-08,\n",
       "             6.4272e-07,  2.3218e-07,  9.1627e-08,  4.4529e-08, -1.7014e-07,\n",
       "             1.3824e-08,  4.1957e-09,  3.2486e-08, -2.0571e-07,  1.0807e-07,\n",
       "            -7.1622e-07, -2.1035e-09, -3.5909e-07, -1.4858e-07,  2.3547e-07,\n",
       "             2.7282e-08,  1.3959e-07,  5.7109e-07,  4.2441e-09,  1.6368e-06,\n",
       "            -1.5993e-07,  2.2886e-08,  6.9412e-09, -1.5151e-07,  4.4125e-08,\n",
       "             2.0352e-07, -1.1392e-07,  2.7364e-08,  1.0589e-07, -5.5187e-08,\n",
       "             1.6629e-07,  7.4912e-09, -2.0594e-08,  2.3673e-07, -3.3969e-07,\n",
       "             1.8167e-07, -6.2524e-08,  1.2417e-06, -3.1121e-07, -1.0771e-07,\n",
       "             1.0565e-08, -4.9013e-08,  7.9971e-07,  5.7857e-07,  2.8357e-07,\n",
       "             5.1979e-08,  1.8741e-07,  4.7199e-08,  3.8275e-07,  1.2427e-07,\n",
       "            -8.2689e-08,  8.0561e-08,  4.6030e-08, -1.7879e-08, -2.6307e-08,\n",
       "             4.2206e-07,  2.0073e-08, -7.1552e-08, -4.3165e-08,  1.9085e-07,\n",
       "             2.9916e-07,  3.7105e-07, -1.4376e-06,  3.2689e-08, -2.0366e-08,\n",
       "            -8.0595e-08, -2.7870e-07, -1.2699e-07,  2.4236e-07,  3.1970e-08,\n",
       "            -1.5532e-07,  1.0029e-06, -3.3263e-07, -1.5343e-07,  1.3014e-08,\n",
       "             5.9278e-09, -1.5710e-07, -8.5477e-08, -2.2490e-07,  5.9508e-07,\n",
       "            -9.4698e-08,  9.4547e-08, -7.7740e-08,  2.5801e-08,  1.3336e-07,\n",
       "             1.1839e-07,  1.3050e-08, -9.1691e-08, -6.0142e-08,  1.6395e-07,\n",
       "             1.3978e-07, -4.5514e-08,  9.7374e-08,  9.4720e-08, -3.9610e-07,\n",
       "             1.8748e-07, -7.4649e-08, -6.7681e-08, -7.8444e-08,  7.1967e-08,\n",
       "            -1.0886e-07,  1.4448e-07, -3.3872e-08,  4.1772e-08, -3.3104e-07,\n",
       "             2.6728e-08, -1.3067e-08,  1.9884e-07,  7.6264e-08,  3.1663e-08,\n",
       "             2.2067e-08, -2.8296e-08,  9.3743e-09,  3.6910e-08,  4.7333e-08,\n",
       "             1.2357e-07,  2.9455e-09, -1.5873e-07,  5.0982e-08, -6.1358e-08,\n",
       "            -7.7740e-08, -6.4003e-08, -3.9261e-07, -4.5670e-07, -1.7737e-07,\n",
       "            -5.1291e-08,  3.2758e-08,  2.5948e-08,  2.3544e-07,  1.4850e-07,\n",
       "            -3.9271e-08,  3.0636e-07, -1.0069e-07, -1.1589e-07,  1.7982e-07,\n",
       "             1.9905e-07,  1.4274e-07, -1.0106e-07,  2.0654e-07, -1.4604e-07,\n",
       "            -1.7139e-07,  1.2357e-07,  1.8744e-07, -4.9575e-08, -2.0886e-07,\n",
       "            -2.7821e-07, -2.1423e-07, -9.8652e-08,  3.1739e-07, -6.6839e-07,\n",
       "            -1.2589e-07,  5.3037e-08, -4.7600e-08, -8.0962e-08, -3.3018e-08,\n",
       "             1.9495e-08, -4.1713e-09, -2.7961e-07, -5.7594e-07,  5.2836e-09,\n",
       "             1.3051e-08,  2.2515e-07, -1.9370e-07,  1.5705e-07,  2.6383e-08,\n",
       "            -7.4879e-09]),\n",
       "    'exp_avg_sq': tensor([1.0209e-12, 1.7556e-14, 5.9312e-15, 2.9104e-14, 7.4181e-15, 1.8916e-14,\n",
       "            1.7107e-14, 2.4387e-13, 1.9200e-13, 2.1450e-14, 4.2851e-14, 4.8164e-13,\n",
       "            1.8630e-13, 2.5444e-14, 2.0383e-14, 1.0707e-13, 4.5267e-15, 2.9023e-13,\n",
       "            9.8766e-14, 4.9625e-14, 4.5815e-15, 2.6650e-14, 1.5381e-14, 1.6545e-14,\n",
       "            7.0385e-14, 1.0191e-13, 4.3882e-15, 7.4238e-14, 2.4806e-14, 4.2111e-14,\n",
       "            6.4261e-14, 3.5571e-14, 1.1895e-13, 8.4950e-14, 6.3694e-14, 7.0440e-15,\n",
       "            8.3818e-14, 5.2795e-13, 1.1266e-13, 1.1274e-14, 1.8096e-13, 4.8924e-14,\n",
       "            3.9044e-14, 2.0536e-13, 1.5827e-14, 7.1175e-13, 3.6799e-13, 5.9120e-15,\n",
       "            1.4587e-13, 4.1294e-14, 4.0228e-13, 1.7954e-13, 2.8788e-13, 1.8796e-13,\n",
       "            4.4815e-14, 2.2500e-13, 8.4241e-14, 3.6480e-14, 1.3293e-13, 8.9565e-15,\n",
       "            1.3148e-13, 3.2260e-14, 7.1429e-14, 1.0747e-14, 1.4556e-14, 1.0638e-13,\n",
       "            2.2377e-13, 1.2137e-12, 8.3960e-14, 2.8465e-13, 1.2336e-13, 1.3139e-14,\n",
       "            1.0776e-13, 5.8612e-14, 4.8784e-14, 3.2733e-14, 6.5362e-14, 1.8783e-14,\n",
       "            1.5491e-14, 2.8027e-14, 7.8691e-14, 4.1114e-15, 3.5890e-13, 1.8730e-14,\n",
       "            7.7539e-14, 3.6474e-15, 4.6179e-13, 1.5932e-14, 1.5979e-13, 1.5297e-14,\n",
       "            1.8810e-13, 1.5447e-13, 2.6818e-14, 5.6434e-15, 8.2454e-14, 1.5624e-14,\n",
       "            4.0381e-14, 1.5498e-14, 2.0747e-14, 1.9773e-14, 1.6944e-13, 2.7266e-14,\n",
       "            4.1113e-13, 6.1148e-14, 1.9747e-14, 6.2829e-15, 1.1834e-14, 3.1759e-13,\n",
       "            3.5730e-15, 4.1530e-13, 3.0823e-14, 1.4078e-14, 6.5756e-14, 6.7193e-14,\n",
       "            3.4014e-13, 1.0586e-13, 5.8421e-14, 2.9417e-14, 7.0855e-14, 4.2524e-14,\n",
       "            5.4162e-14, 2.0759e-13, 4.7219e-14, 1.0816e-13, 1.2870e-13, 6.5253e-14,\n",
       "            5.5224e-14, 1.3907e-12, 6.7684e-13, 1.5732e-14, 1.0866e-13, 1.0707e-13,\n",
       "            1.5518e-13, 6.8135e-14, 4.3213e-14, 2.1762e-14, 8.2156e-15, 3.5344e-14,\n",
       "            1.7862e-12, 1.2820e-14, 3.3844e-14, 1.4574e-14, 1.5344e-14, 1.7785e-13,\n",
       "            3.6434e-14, 5.4965e-13, 3.2607e-14, 1.5862e-13, 4.0356e-14, 4.5466e-14,\n",
       "            1.6489e-13, 4.5358e-14, 4.3374e-13, 1.1118e-13, 5.4032e-14, 5.1684e-13,\n",
       "            7.2324e-14, 4.9846e-14, 2.5416e-14, 7.5743e-14, 1.2764e-13, 1.2307e-12,\n",
       "            6.0995e-14, 1.7714e-13, 4.2651e-15, 5.1434e-14, 8.3719e-14, 3.9650e-14,\n",
       "            1.0093e-13, 1.2151e-13, 5.7319e-15, 6.2736e-13, 5.8998e-14, 2.8379e-14,\n",
       "            5.6283e-14, 1.8155e-14, 1.8945e-13, 2.5047e-14, 9.8874e-14, 2.0725e-13,\n",
       "            1.7593e-13, 1.3008e-14, 1.6970e-14, 8.7451e-14, 1.6022e-13, 1.8943e-14,\n",
       "            7.9795e-14, 9.2048e-15, 1.4214e-14, 1.0960e-14, 4.3490e-14, 8.7904e-14,\n",
       "            1.9849e-14, 4.2303e-14, 3.8141e-14, 3.0539e-15, 8.1194e-14, 2.3288e-14,\n",
       "            3.9763e-14, 5.1356e-14, 9.9720e-14, 1.4664e-15, 4.4242e-15, 1.3489e-14,\n",
       "            5.2354e-14, 9.6037e-14, 5.0558e-14, 1.5045e-14, 4.7743e-14, 2.7333e-13,\n",
       "            2.5516e-14, 2.7928e-13, 4.1034e-13, 4.1090e-13, 3.3330e-13, 3.9540e-14,\n",
       "            2.7094e-14, 2.4262e-14, 1.1357e-13, 2.6511e-13, 7.2074e-15, 3.1239e-14,\n",
       "            3.0843e-14, 3.9723e-14, 5.7117e-14, 2.1446e-13, 7.6335e-14, 9.9416e-15,\n",
       "            3.0189e-13, 1.3674e-13, 3.0757e-13, 1.9135e-13, 7.6669e-14, 4.7760e-14,\n",
       "            1.9946e-14, 3.8084e-14, 1.2048e-14, 2.6684e-14, 1.5893e-13, 1.7437e-13,\n",
       "            2.8577e-13, 1.4966e-14, 4.7459e-14, 2.1603e-14, 3.8015e-14, 9.5805e-15,\n",
       "            5.5907e-14, 2.9793e-13, 2.5853e-13, 7.7529e-14, 6.5631e-14, 2.4730e-14,\n",
       "            1.3958e-13, 1.3294e-13, 2.5683e-14, 1.0946e-13])},\n",
       "   89: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[-2.7052e-10, -1.5945e-10, -5.5017e-11,  ...,  6.3279e-09,\n",
       "              1.4533e-08,  1.0623e-08],\n",
       "            [ 1.7258e-09,  2.6450e-09,  2.1898e-09,  ...,  1.1179e-08,\n",
       "              1.6833e-08,  2.7661e-08],\n",
       "            [-1.9726e-09, -2.0167e-09, -1.8230e-09,  ..., -1.0874e-09,\n",
       "              4.8157e-10,  4.1445e-09],\n",
       "            ...,\n",
       "            [ 5.8962e-10,  7.2432e-10, -2.2984e-10,  ..., -1.1195e-08,\n",
       "             -2.3616e-08, -1.3187e-08],\n",
       "            [ 1.0289e-09,  9.9429e-10,  1.0323e-09,  ...,  1.4162e-08,\n",
       "              6.6610e-10, -4.3465e-09],\n",
       "            [ 3.7339e-10,  3.6426e-10,  2.6467e-10,  ...,  1.0100e-08,\n",
       "              4.7584e-09,  5.1684e-09]]),\n",
       "    'exp_avg_sq': tensor([[1.6295e-17, 1.6866e-17, 1.5951e-17,  ..., 8.6056e-16, 1.0966e-15,\n",
       "             6.9944e-16],\n",
       "            [2.1501e-17, 2.0192e-17, 2.2827e-17,  ..., 4.2165e-15, 4.2857e-15,\n",
       "             2.3306e-15],\n",
       "            [2.6862e-17, 2.7931e-17, 3.0475e-17,  ..., 2.3404e-15, 2.3966e-15,\n",
       "             1.5561e-15],\n",
       "            ...,\n",
       "            [2.9129e-17, 2.8227e-17, 2.9885e-17,  ..., 2.8423e-15, 2.6865e-15,\n",
       "             1.4456e-15],\n",
       "            [3.9781e-17, 3.9638e-17, 4.2767e-17,  ..., 2.5123e-15, 2.5983e-15,\n",
       "             1.5193e-15],\n",
       "            [1.0345e-16, 1.1101e-16, 1.1077e-16,  ..., 8.2750e-15, 7.8053e-15,\n",
       "             5.0642e-15]])},\n",
       "   90: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 4.3062e-12,  1.5138e-11, -6.1583e-13,  ...,  9.5422e-12,\n",
       "            -9.8862e-13, -1.1764e-12]),\n",
       "    'exp_avg_sq': tensor([6.0132e-23, 2.4293e-22, 1.8658e-22,  ..., 2.0095e-22, 1.4692e-22,\n",
       "            1.5720e-22])},\n",
       "   91: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 1.9531e-08, -5.8553e-08, -9.8083e-08,  ..., -2.6565e-08,\n",
       "            -3.2148e-08, -1.1493e-07]),\n",
       "    'exp_avg_sq': tensor([3.4611e-15, 5.6231e-15, 4.2518e-15,  ..., 5.9910e-15, 6.3278e-16,\n",
       "            1.6687e-14])},\n",
       "   92: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 2.4981e-08, -2.2040e-08, -9.7137e-08,  ..., -9.0197e-09,\n",
       "            -4.0892e-08, -1.8085e-07]),\n",
       "    'exp_avg_sq': tensor([2.3620e-15, 1.4350e-14, 6.2305e-15,  ..., 2.8022e-15, 1.3969e-15,\n",
       "            2.4441e-14])},\n",
       "   93: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([[ 5.7700e-07,  5.4422e-07,  4.8525e-07,  ...,  4.7146e-07,\n",
       "              4.8607e-07,  9.0012e-07],\n",
       "            [-6.2895e-07, -3.5570e-07, -6.9165e-07,  ..., -1.8667e-06,\n",
       "             -2.2116e-06, -1.4639e-06],\n",
       "            [-5.8337e-07, -1.4828e-06, -2.0154e-06,  ..., -1.9292e-07,\n",
       "              6.4680e-07, -1.4569e-06],\n",
       "            [ 4.3438e-07,  6.7936e-07,  8.4832e-07,  ...,  5.5033e-07,\n",
       "              4.3743e-07,  7.9859e-07],\n",
       "            [-1.3941e-07,  1.6086e-07,  5.2196e-07,  ...,  2.4555e-07,\n",
       "             -1.2600e-07,  5.1633e-07],\n",
       "            [ 3.4025e-07,  4.5410e-07,  8.5159e-07,  ...,  7.9234e-07,\n",
       "              7.6730e-07,  7.0582e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.1140e-12, 2.5629e-12, 2.2823e-12,  ..., 2.1294e-12, 2.0520e-12,\n",
       "             2.3448e-12],\n",
       "            [5.1937e-12, 6.3933e-12, 6.8570e-12,  ..., 4.6418e-12, 6.1880e-12,\n",
       "             8.6736e-12],\n",
       "            [2.1897e-12, 6.9025e-13, 1.0456e-12,  ..., 2.1352e-12, 4.6772e-13,\n",
       "             9.2403e-13],\n",
       "            [1.5284e-12, 1.2538e-12, 1.2077e-12,  ..., 1.4597e-12, 1.2103e-12,\n",
       "             1.3048e-12],\n",
       "            [1.2760e-12, 7.5194e-13, 4.6917e-13,  ..., 9.4904e-13, 9.7101e-13,\n",
       "             3.5392e-13],\n",
       "            [1.0263e-12, 1.0240e-12, 1.1156e-12,  ..., 9.9239e-13, 1.0394e-12,\n",
       "             1.1814e-12]])},\n",
       "   94: {'step': tensor(90.),\n",
       "    'exp_avg': tensor([ 3.2948e-06, -4.6744e-06, -3.2946e-06,  2.3759e-06,  4.3369e-07,\n",
       "             1.8647e-06]),\n",
       "    'exp_avg_sq': tensor([2.5794e-11, 7.3372e-11, 6.6292e-12, 1.7625e-11, 6.5996e-12, 1.2789e-11])}},\n",
       "  'param_groups': [{'lr': 4.000798063863525e-07,\n",
       "    'weight_decay': 0.001,\n",
       "    'betas': (0.9499991686834754, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'amsgrad': False,\n",
       "    'foreach': None,\n",
       "    'maximize': False,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 4.0000000000000003e-07,\n",
       "    'max_lr': 1e-05,\n",
       "    'min_lr': 4.0000000000000004e-11,\n",
       "    'max_momentum': 0.95,\n",
       "    'base_momentum': 0.85,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21,\n",
       "     22,\n",
       "     23,\n",
       "     24,\n",
       "     25,\n",
       "     26,\n",
       "     27,\n",
       "     28,\n",
       "     29,\n",
       "     30,\n",
       "     31,\n",
       "     32,\n",
       "     33,\n",
       "     34,\n",
       "     35,\n",
       "     36,\n",
       "     37,\n",
       "     38,\n",
       "     39,\n",
       "     40,\n",
       "     41,\n",
       "     42,\n",
       "     43,\n",
       "     44,\n",
       "     45,\n",
       "     46,\n",
       "     47,\n",
       "     48,\n",
       "     49,\n",
       "     50,\n",
       "     51,\n",
       "     52,\n",
       "     53,\n",
       "     54,\n",
       "     55,\n",
       "     56,\n",
       "     57,\n",
       "     58,\n",
       "     59,\n",
       "     60,\n",
       "     61,\n",
       "     62,\n",
       "     63,\n",
       "     64,\n",
       "     65,\n",
       "     66,\n",
       "     67,\n",
       "     68,\n",
       "     69,\n",
       "     70,\n",
       "     71,\n",
       "     72,\n",
       "     73,\n",
       "     74,\n",
       "     75,\n",
       "     76,\n",
       "     77]},\n",
       "   {'lr': 4.000798063863529e-05,\n",
       "    'weight_decay': 0.01,\n",
       "    'betas': (0.9499991686834754, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'amsgrad': False,\n",
       "    'foreach': None,\n",
       "    'maximize': False,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 4e-05,\n",
       "    'max_lr': 0.001,\n",
       "    'min_lr': 4e-09,\n",
       "    'max_momentum': 0.95,\n",
       "    'base_momentum': 0.85,\n",
       "    'params': [78,\n",
       "     79,\n",
       "     80,\n",
       "     81,\n",
       "     82,\n",
       "     83,\n",
       "     84,\n",
       "     85,\n",
       "     86,\n",
       "     87,\n",
       "     88,\n",
       "     89,\n",
       "     90,\n",
       "     91,\n",
       "     92,\n",
       "     93,\n",
       "     94]}]},\n",
       " 'scheduler_state_dict': {'total_steps': 1000,\n",
       "  '_schedule_phases': [{'end_step': 199.0,\n",
       "    'start_lr': 'initial_lr',\n",
       "    'end_lr': 'max_lr',\n",
       "    'start_momentum': 'max_momentum',\n",
       "    'end_momentum': 'base_momentum'},\n",
       "   {'end_step': 999,\n",
       "    'start_lr': 'max_lr',\n",
       "    'end_lr': 'min_lr',\n",
       "    'start_momentum': 'base_momentum',\n",
       "    'end_momentum': 'max_momentum'}],\n",
       "  '_anneal_func_type': 'cos',\n",
       "  'cycle_momentum': True,\n",
       "  'use_beta1': True,\n",
       "  'base_lrs': [4.0000000000000003e-07, 4e-05],\n",
       "  'last_epoch': 0.3652725258325956,\n",
       "  'verbose': False,\n",
       "  '_step_count': 15,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [4.000798063863525e-07, 4.000798063863529e-05]},\n",
       " 'losses': 0.29795511776065253}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 9910 × 14878\n",
       "    obs: 'n_genes', 'doublet_score', 'predicted_doublet', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden_res_0.4', 'leiden_res_0.3', 'cell_type', 'main_cell_type', 'compare_type'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, (data, labels) in enumerate(train_loader, 1):\n",
    "    data, labels = data.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算微调前后同一样本的相似度\n",
    "with torch.no_grad():\n",
    "    orig_feat = performer_lm(input_seq)[:, :, :200]  # 原始BERT输出\n",
    "    tuned_feat = model(input_seq)[:, :, :200]  # 微调后特征\n",
    "\n",
    "similarity = F.cosine_similarity(orig_feat, tuned_feat, dim=-1)\n",
    "print(f\"特征相似度均值：{similarity.mean().item():.4f}\")  # 应>0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 累积统计量\u001b[39;00m\n\u001b[1;32m     29\u001b[0m preds \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m GRADIENT_ACCUMULATION\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 优化后的训练循环\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_epoch_indices = []\n",
    "lr_history = []\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loader.sampler.set_epoch(epoch)\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader, 1):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        # 混合精度前向\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "            logits = model(data)\n",
    "            loss = loss_fn(logits, labels) / GRADIENT_ACCUMULATION\n",
    "        \n",
    "        # 梯度累积\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # 累积统计量\n",
    "        preds = logits.detach().argmax(dim=-1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        running_loss += loss.item() * GRADIENT_ACCUMULATION\n",
    "        \n",
    "        # 参数更新\n",
    "        if batch_idx % GRADIENT_ACCUMULATION == 0 or batch_idx == len(train_loader):\n",
    "            # 梯度裁剪\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "            \n",
    "            # 优化器步进\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 学习率调度\n",
    "            scheduler.step()\n",
    "    \n",
    "    # 计算训练指标\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct_predictions / total_samples\n",
    "    train_loss_history.append(epoch_loss)  # 记录当前epoch训练loss\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lr_history.append(current_lr)\n",
    "    \n",
    "    # 验证阶段\n",
    "    if epoch % VALIDATE_EVERY == 0:\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16, enabled=USE_AMP):\n",
    "            for data_v, labels_v in val_loader:\n",
    "                data_v, labels_v = data_v.to(device), labels_v.to(device)\n",
    "                logits = model(data_v)\n",
    "                \n",
    "                # 损失计算\n",
    "                val_loss += loss_fn(logits, labels_v).item()\n",
    "                \n",
    "                # 预测处理\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                preds = probs.argmax(dim=-1)\n",
    "                mask = probs.max(dim=-1).values >= UNASSIGN_THRES\n",
    "                val_preds.append(preds[mask].cpu())\n",
    "                val_labels.append(labels_v[mask].cpu())\n",
    "                \n",
    "        val_loss1 = val_loss / len(val_loader)\n",
    "        val_loss_history.append(val_loss1)\n",
    "        val_epoch_indices.append(epoch)  # 记录发生验证的epoch序号\n",
    "        \n",
    "        # 合并结果\n",
    "        val_preds = torch.cat(val_preds)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        \n",
    "        if len(val_labels) > 0:\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "            val_acc = accuracy_score(val_labels, val_preds)\n",
    "            print(f\"Epoch {epoch} | Val F1: {val_f1:.4f} | Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # 早停判断与模型保存\n",
    "            if val_f1 > early_stopper.best_f1:\n",
    "                src.utils_BERT.save_best_ckpt(epoch, model, optimizer, scheduler, \n",
    "                                            val_loss, model_name, ckpt_dir)\n",
    "            \n",
    "            if early_stopper(val_f1):\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # 释放显存\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 训练结束后保存并绘制loss曲线 ===\n",
    "def plot_loss_curve(train_loss, val_loss, val_epochs, save_path=\"loss_curve.png\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 绘制训练loss\n",
    "    plt.plot(range(1, len(train_loss)+1), train_loss, \n",
    "             'b-o', label='Training Loss', alpha=0.7)\n",
    "    \n",
    "    # 绘制验证loss（只绘制有记录的epoch）\n",
    "    if len(val_loss) > 0:\n",
    "        plt.plot(val_epochs, val_loss,\n",
    "                 'r-s', label='Validation Loss', markersize=8)\n",
    "    \n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 自动调整Y轴范围\n",
    "    min_loss = min(min(train_loss), min(val_loss)) if val_loss else min(train_loss)\n",
    "    plt.ylim(bottom=min_loss*0.9, top=max(train_loss)*1.1)\n",
    "    \n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# 保存数值数据\n",
    "np.savez(\"loss_data.npz\",\n",
    "         train_loss=np.array(train_loss_history),\n",
    "         val_loss=np.array(val_loss_history),\n",
    "         val_epochs=np.array(val_epoch_indices))\n",
    "\n",
    "# 生成可视化图表\n",
    "plot_loss_curve(train_loss_history, val_loss_history, val_epoch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ==  Epoch: 19 | Training Loss: 0.607123 | Accuracy: 76.221047%  ==\n"
     ]
    }
   ],
   "source": [
    "print(f'    ==  Epoch: {i} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:4f}%  ==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025_PBMC_MainCelltype_scBert'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# 强制触发垃圾回收\n",
    "gc.collect()\n",
    "# 清空 PyTorch 的 CUDA 缓存\n",
    "torch.cuda.empty_cache()\n",
    "from numba import cuda\n",
    "\n",
    "# 释放当前 GPU 的所有资源\n",
    "cuda.select_device(1)\n",
    "cuda.close()\n",
    "cuda.select_device(1)  # 重新激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.utils_BERT.save_best_ckpt(i, model, optimizer, scheduler, val_loss, '2025_PBMC_MainCelltype_scBert_last', ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换为评估模式\n",
    "model.eval()\n",
    " \n",
    "# 在评估模式下进行推断\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 10)  # 随机生成一个测试输入样本\n",
    "    output = model(test_input)\n",
    "    print(\"推断结果:\", output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试代码\n",
    "test_input = torch.randn(24, 16907, 200)  # 模拟真实输入\n",
    "model = BioClassifier()\n",
    "\n",
    "# 逐步检查维度变化\n",
    "x_proj = model.proj(test_input)          # 应得到[24,16907,256]\n",
    "x_perm = x_proj.permute(0, 2, 1)         # → [24,256,16907]\n",
    "conv_out = model.feature_extractor[0](x_perm)  # → [24,256,16907]\n",
    "print(conv_out.shape)  # 应保持通道数256\n",
    "\n",
    "# 完整前向传播验证\n",
    "output = model(test_input)\n",
    "print(output.shape)  # 预期[24,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# second train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 24\n",
    "CLASS = 5+2 #Number of bins.'+2\n",
    "SEQ_LEN = len(gene_names)+1#gene_num\", type=int, default=16906\n",
    "POS_EMBED_USING = True #'Using Gene2vec encoding or not.'\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "GRADIENT_ACCUMULATION = 60\n",
    "VALIDATE_EVERY =1\n",
    "PATIENCE = 10\n",
    "UNASSIGN_THRES = 0.0\n",
    "path = \"/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/scBert_model/scBert_PBMC_10k/2025_finetune_PBMC_MainCelltype_scBert_best.pth\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "POS_EMBED_USING =True\n",
    "model_name = \"2025_finetune_PBMC_MainCelltype_scBert\"\n",
    "ckpt_dir = os.path.join(work_dir,\"scBert_model\",\"scBert_PBMC_10k/\")\n",
    "# world_size = torch.distributed.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1 = []\n",
    "f1w = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "pred_list = pd.Series(['un'] * data_csr.shape[0])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for index_train, index_val in sss.split(data_csr, label):\n",
    "    data_train, label_train = data_csr[index_train], label[index_train]\n",
    "    data_val, label_val = data_csr[index_val], label[index_val]\n",
    "    train_dataset = SCDataset(data_train, label_train,CLASS,device)\n",
    "    val_dataset = SCDataset(data_val, label_val,CLASS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = src.utils_BERT.SimpleSampler(train_dataset)\n",
    "val_sampler = src.utils_BERT.SimpleSampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/src/performer_pytorch/performer_pytorch.py:175: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2416.)\n",
      "  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"
     ]
    }
   ],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")\n",
    "model.to_out = BioClassifier(seq_len=16907, embed_dim=200, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_662379/2976891991.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path,map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ckpt = torch.load(path,map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'losses'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.utils_BERT.save_best_ckpt(i, model, optimizer, scheduler, val_loss, '2025_PBMC_MainCelltype_scBert_v1_last', ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# tree train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3\n",
    "BATCH_SIZE = 24\n",
    "CLASS = 5+2 #Number of bins.'+2\n",
    "SEQ_LEN = len(gene_names)+1#gene_num\", type=int, default=16906\n",
    "POS_EMBED_USING = True #'Using Gene2vec encoding or not.'\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "GRADIENT_ACCUMULATION = 60\n",
    "VALIDATE_EVERY =1\n",
    "PATIENCE = 10\n",
    "UNASSIGN_THRES = 0.0\n",
    "path = \"/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/scBert_model/scBert_PBMC_10k/2025_PBMC_MainCelltype_scBert_v1_best.pth\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "POS_EMBED_USING =True\n",
    "model_name = \"2025_PBMC_MainCelltype_scBert_v2\"\n",
    "ckpt_dir = os.path.join(work_dir,\"scBert_model\",\"scBert_PBMC_10k/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1 = []\n",
    "f1w = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "pred_list = pd.Series(['un'] * data_csr.shape[0])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for index_train, index_val in sss.split(data_csr, label):\n",
    "    data_train, label_train = data_csr[index_train], label[index_train]\n",
    "    data_val, label_val = data_csr[index_val], label[index_val]\n",
    "    train_dataset = SCDataset(data_train, label_train,CLASS,device)\n",
    "    val_dataset = SCDataset(data_val, label_val,CLASS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = src.utils_BERT.SimpleSampler(train_dataset)\n",
    "val_sampler = src.utils_BERT.SimpleSampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/src/performer_pytorch/performer_pytorch.py:175: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2416.)\n",
      "  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"
     ]
    }
   ],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")\n",
    "model.to_out = Identity(dropout=0., h_dim=128, out_dim=label_names.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1413683/2976891991.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path,map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ckpt = torch.load(path,map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'losses'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get attention #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 24\n",
    "CLASS = 5+2 #Number of bins.'+2\n",
    "SEQ_LEN = len(gene_names)+1#gene_num\", type=int, default=16906\n",
    "POS_EMBED_USING = True #'Using Gene2vec encoding or not.'\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "GRADIENT_ACCUMULATION = 60\n",
    "VALIDATE_EVERY =1\n",
    "PATIENCE = 10\n",
    "UNASSIGN_THRES = 0.0\n",
    "path = \"/data/lyx/scCHiP/scATAC/LDA/PBMC_10k/scBert_model/scBert_PBMC_10k/2025_finetune_PBMC_MainCelltype_scBert_0217_best.pth\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "POS_EMBED_USING =True\n",
    "model_name = \"2025_finetune_PBMC_MainCelltype_scBert\"\n",
    "ckpt_dir = os.path.join(work_dir,\"scBert_model\",\"scBert_PBMC_10k/\")\n",
    "# world_size = torch.distributed.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    gene_weight_file='./src/data_BERT/gene2vec_16906.npy',\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING\n",
    ")\n",
    "model.to_out = BioClassifier(seq_len=16907, embed_dim=200, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4106142/2976891991.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(path,map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ckpt = torch.load(path,map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.performer.net.layers[-2].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1 = []\n",
    "f1w = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "pred_list = pd.Series(['un'] * data_csr.shape[0])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for index_train, index_val in sss.split(data_csr, label):\n",
    "    data_train, label_train = data_csr[index_train], label[index_train]\n",
    "    data_val, label_val = data_csr[index_val], label[index_val]\n",
    "    train_dataset = SCDataset(data_train, label_train,CLASS,device)\n",
    "    val_dataset = SCDataset(data_val, label_val,CLASS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = src.utils_BERT.SimpleSampler(train_dataset)\n",
    "val_sampler = src.utils_BERT.SimpleSampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4106142/2988717159.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "USE_AMP = True  # 启用混合精度\n",
    "MAX_GRAD_NORM = 1.0  # 梯度裁剪阈值\n",
    "\n",
    "# 初始化混合精度训练\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "# 改进的参数分组策略\n",
    "param_groups = [\n",
    "    {'params': model.performer.parameters(), 'lr': 1e-5, 'weight_decay': 0.001},\n",
    "    {'params': model.to_out.parameters(), 'lr': 1e-3, 'weight_decay': 0.01}\n",
    "]\n",
    "\n",
    "# 动态调整的优化器配置\n",
    "optimizer = torch.optim.AdamW(param_groups)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=[group['lr'] for group in param_groups],  # 分组学习率峰值\n",
    "    total_steps=1000,\n",
    "    pct_start=0.2\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 在评估模式下进行推断\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[43mtest_input\u001b[49m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m推断结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_input' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    " \n",
    "# 在评估模式下进行推断\n",
    "with torch.no_grad():\n",
    "    output = model(test_input)\n",
    "    print(\"推断结果:\", output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算微调前后同一样本的相似度\n",
    "with torch.no_grad():\n",
    "    orig_feat = performer_lm(input_seq)[:, :, :200]  # 原始BERT输出\n",
    "    tuned_feat = model(input_seq)[:, :, :200]  # 微调后特征\n",
    "\n",
    "similarity = F.cosine_similarity(orig_feat, tuned_feat, dim=-1)\n",
    "print(f\"特征相似度均值：{similarity.mean().item():.4f}\")  # 应>0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gene_attention(sample):\n",
    "    # 获取位置偏置\n",
    "    position_bias = model.to_out.feature_extractor[-1].position_bias\n",
    "    \n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(position_bias.detach().cpu().numpy())\n",
    "    plt.xlabel(\"Gene Position\")\n",
    "    plt.ylabel(\"Bias Value\")\n",
    "    plt.title(\"Genome-wide Positional Bias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_bias = model.to_out.feature_extractor[-1].position_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Genome-wide Positional Bias')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(position_bias.detach().cpu().numpy())\n",
    "plt.xlabel(\"Gene Position\")\n",
    "plt.ylabel(\"Bias Value\")\n",
    "plt.title(\"Genome-wide Positional Bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STED",
   "language": "python",
   "name": "sted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
