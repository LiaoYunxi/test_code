自定义单机多卡分布式训练是深度学习中常见的需求，尤其是在处理大规模数据集或复杂模型时。这种配置可以显著提高训练效率。下面将详细介绍如何配置环境、编写代码以及运行命令来实现单机多卡分布式训练。

### 1. 环境配置

#### 硬件要求
- 一台或多台服务器，每台服务器配备多个GPU（例如，NVIDIA Tesla V100）。
- 确保所有GPU都已正确安装并配置好驱动程序。

#### 软件要求
- **Python**：建议使用Python 3.6或更高版本。
- **PyTorch**：建议使用1.6.0或更高版本，因为这些版本对分布式训练有较好的支持。
- **CUDA**：确保安装了与GPU兼容的CUDA版本。
- **cuDNN**：优化深度学习模型的性能。

#### 安装依赖
```bash
# 安装PyTorch和CUDA
pip install torch torchvision

# 安装其他依赖
pip install numpy matplotlib
```

### 2. 代码编写

#### 导入必要的库
```python
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
```

#### 定义模型
```python
class MyModel(torch.nn.Module):
    def __init__(self):
        super(MyModel, self).__0__(self)
        self.fc = torch.nn.Linear(100, 10)

    def forward(self, x):
        return self.fc(x)
```

#### 定义训练函数
```python
def train(gpu, args):
    rank = args.nr * args.gpus + gpu
    dist.init_process_group(backend='nccl', init_method='env://', world_size=args.world_size, rank=rank)
  
    torch.manual_seed(0)
    model = MyModel().to(gpu)
    ddp_model = DDP(model, device_ids=[gpu])
  
    # 定义数据集和数据加载器
    dataset = ...  # 你的数据集
    sampler = DistributedSampler(dataset, num_replicas=args.world_size, rank=rank)
    dataloader = DataLoader(dataset, batch_size=args.batch_size, sampler=sampler)
  
    optimizer = torch.optim.SGD(ddp_model.parameters(), lr=0.01)
  
    for epoch in range(args.epochs):
        for batch in dataloader:
            inputs, targets = batch
            inputs, targets = inputs.to(gpu), targets.to(gpu)
          
            optimizer.zero_grad()
            outputs = ddp_model(inputs)
            loss = torch.nn.functional.cross_entropy(outputs, targets)
            loss.backward()
            optimizer.step()
      
        print(f"Rank {rank}, Epoch {epoch}, Loss {loss.item()}")
  
    dist.destroy_process_group()
```

#### 主函数
```python
def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N',
                        help='number of data loading workers (default: 1)')
    parser.add_argument('-g', '--gpus', default=1, type=int,
                        help='number of gpus per node')
    parser.add_argument('-nr', '--nr', default=0, type=int,
                        help='ranking within the nodes')
    parser.add_argument('--epochs', default=10, type=int, metavar='N',
                        help='number of total epochs to run')
    parser.add_argument('--batch-size', default=32, type=int, metavar='N',
                        help='mini-batch size (default: 32)')
    args = parser.parse_args()
  
    args.world_size = args.gpus * args.nodes
    mp.spawn(train, nprocs=args.gpus, args=(args,))
```

### 3. 运行命令

#### 设置环境变量
```bash
export MASTER_ADDR=localhost
export MASTER_PORT=12355
```

#### 运行脚本
```bash
python your_script.py -n 1 -g 4 -nr 0 --epochs 10 --batch-size 32
```

### 4. 注意事项
- **数据集和数据加载器**：确保数据集和数据加载器能够正确处理分布式训练中的数据分片。
- **模型保存和加载**：在分布式训练中，模型的保存和加载需要特别注意，通常需要保存和加载模型的`state_dict`。
- **日志和调试**：在多进程环境中，日志和调试信息可能会比较复杂，建议使用日志库（如`logging`）来管理日志输出。

通过以上步骤，你可以在单机多卡环境下配置和运行分布式训练。希望这些信息对你有所帮助！